% IACR Communications in Cryptology template file
% This file shows how to use the iacrcc class to write a paper.

%% Document mode
% [version=xxx] where xxx is preprint, submission, or final. The default is preprint.
%               version=submission puts line numbers into the document and makes it
%               anonymous (which can be overridden).
%               version=final is for submitting the final version. This requires a license
%               to be specified and must be compiled with lualatex.
% [notanonymous]  Keep author names in submission mode
%% Package options
% [floatrow]      Load floatrow package with correct captions
% [biblatex]      Use the biblatex package instead of bibtex. Note that options
%                 may not be passed to biblatex at this time.

% Uncomment the next line if you have TeX Live 2021 or later
% and want to produce a PDF which complies with the PDF/A-2U standard
% \DocumentMetadata{pdfstandard=a-2u}
\documentclass{iacrcc}

% When the *final* document mode is used
% the authors need to provide a supported license.
% In all other modes this information is ignored.
% The currently provided ones are { CC-by }
\license{CC-by}

% Include LaTeX packages required by your paper

\newif\ifhidetodos
%\hidetodosfalse
\hidetodostrue
\input{common}

% Hide original text from specifications document
\newif\ifshoworiginal
%\showoriginaltrue
\showoriginalfalse

% Provide the title of the paper
% This should look like:
\title[running  = {FrodoKEM: A CCA-Secure Learning With Errors Key Encapsulation Mechanism}]
                  {FrodoKEM: A CCA-Secure Learning With Errors Key Encapsulation Mechanism}
% Where the options in square brackets “[ ]” are optional and control the following:
% running: the running title displayed in the headers

% Define authors and affiliations
% Authors are listed individually using the \addauthor tag followed by a list of affiliations.
% The idea is that every author makes a separate call to this command.
% This should look like:
% \addauthor[inst      = {1,2},
%            orcid     = 0000-0000-0000-0000,
%            footnote  = {Thanks to my supervisor for the support.},
%            onclick   = {https://www.mypersonalwebpage.com}
%           ]{Alice Accomplished}
% Where the options in square brackets “[ ]” are optional 
% and control the following:
% inst:     a numerical list pointing to the index of the institution 
%           in the affiliation array.
% orcid:    create a small clickable orcid logo next to the authors name 
%           linking to the authors ORCID iD see: orcid.org.
% footnote: create an author-specific footnote.
% onclick:  define what to do when clicking on the external link logo
%           next to the author name: e.g., can point to the academic webpage.
% email:    define the e-mail address of this author.
\addauthor[inst     = {1},
%           footnote = {This is an example footnote.},
           email    = {myself@myself.com},
           surname  = {Lastname}
          ]{Firstname Lastname}

%\addauthor[inst    = {2},
%           email   = {mccurley@digicrime.com},
%           surname = {McCurley},
%          ]{Kevin S. McCurley}

% The following command controls the running header for authors
% This is optional for <= 4 authors and mandatory for > 4 authors
% \authorrunning{Joppe W. Bos and Kevin S. McCurley}

% Affiliations are listed individually using the \addaffiliation command 
% *after* the (list of) authors using \addauthor
% This should look like (full example):
% \addaffiliation[ror        = 05f950310,
%                 department = {Computer Security and Industrial Cryptography},              
%                 street     = {Kasteelpark Arenberg 10, box 2452},
%                 city       = {Leuven},
%                 state      = {Vlaams-Brabant},
%                 postcode   = {3001},
%                 country    = {Belgium}
%                ]{KU Leuven}
% Where the options in square brackets “[ ]” are optional and control 
% the following (optional information is mainly used for meta-data collection):
% ror:        provide the Research Organization Registry (ROR) identifier 
%             for this affiliation (see: ror.org). This is used for meta-data 
%             collection only.
% department: department or suborganization name
% street:     street address
% city:       city name
% state:      state or province name
% postcode:   zip or postal code
% country:    country name

\addaffiliation[ 
%                ror     = 031v4g827,
%                street  = {Interleuvenlaan 80},
                city    = {city},
%                postcode= {3001},
                country = {country}
               ]{Institution}

% Authors should use the \addfunding macro to make sure that funding agencies
% can find papers published under their sponsorship.
% You can use the online tool at
% https://publish.iacr.org/funding
% to help you find fundref and ror identifiers.
% Note that \addfunding *does not* automatically create footnotes or
% an acknowledgements section to identify funding - it only collects the
% metadata for indexing.
% An example is:

% \addfunding[country  = {europe},
%             grantid  = {1234},
%             fundref = {100010661}
%            ]{Horizon 2020 Framework Programme}

% A footnote can be placed on the front page without a symbol / numbering using:
%\genericfootnote{This is the full version of our paper published at XX}

\begin{document}

\maketitle

% Provide the keywords *before* the abstract
% When keywords contain macros provide the text version as the optional argument
\newcommand{\Dirac}{Dirac}
\keywords[Dirac delta function, unit impulse]{\Dirac~$\delta$ function, unit impulse}

% Provide the abstract of your paper
\begin{abstract}
  The abstract goes here. You may use mathematics and macros
  in your abstract, but do not use \texttt{\textbackslash cite}
  or footnotes. The abstract should be self-contained.
\end{abstract}

% A separate text-only abstract must be supplied in your final version.
% This will be used for web pages and indexing and should not contain macros.
\begin{textabstract}
  For the final version of your paper, you will need a text-only abstract. Do
  not use LaTeX macros inside this abstract.
\end{textabstract}

% The content of the paper starts here
\section{Introduction}
This is the template showing how to use the IACR Communications in Cryptology \LaTeX{} class. 
See the ``How to Use the IACR Communications in Cryptology Class'' for more details.


\section{Background}
\label{sec:background}

This section defines the cryptographic primitives and security notions that
are relevant to \FrodoPKE and \FrodoKEM, as well as the mathematical
background required to analyze their security.

\subsection{Notation}
\label{sec:notation}

\ifshoworiginal
We use the following notation:

\begin{itemize}
\item Vectors are denoted with bold lower-case letters (e.g.,
  $\bfa, \bfb, \bfv$), and matrices are denoted with bold upper-case
  letters (e.g., $\bfA, \bfB, \bfS$). For a set~$D$, the set of
  $m$-dimensional vectors with entries in~$D$ is denoted by~$D^{m}$,
  and the set of $m$-by-$n$ matrices with entries
  in~$D$ is denoted by $D^{m \times n}$.
\item For an $n$-dimensional vector $\bfv$, its $i$th entry for
  $0\leq i < n$ is denoted by~$\bfv_i$.
\item For an $m$-by-$n$ matrix~$\bfA$, its $(i,j)$th entry (i.e., the
  entry in the $i$th row and $j$th column) for $0 \leq i <m$ and
  $0 \leq j < n$ is denoted by~$\bfA_{i,j}$, and its $i$th row is
  denoted by~$\bfA_i = (\bfA_{i,0},\bfA_{i,1},\ldots,\bfA_{i,n-1})$.
\item The transpose of a matrix~$\bfA$ is denoted by $\bfA^\text{T}$.  
\item An $m$-bit string $\bfk\in \set{0,1}^m$ is written as a vector over
  the set $\{0,1\}$ and its $i$th bit for
  $0 \leq i < m$ is denoted by~$\bfk_i$. 
\item The ring of integers is denoted by $\bbZ$, and, for a positive
  integer~$q$, the quotient ring of integers modulo~$q$ is denoted by
  $\bbZ_q = \bbZ/q\bbZ$.
\item For a probability distribution~$\chi$, the notation
  $e \getsr \chi$ denotes drawing a value~$e$ according to~$\chi$.
  The $n$-fold product distribution of~$\chi$ with itself is denoted
  by~$\chi^{n}$.
\item For a finite set~$S$, the uniform
  distribution on~$S$ is denoted by~$U(S)$.
\item The floor of a real number~$a$, i.e., the largest integer less
  than or equal to $a$, is denoted by~$\floor{a}$.
\item The closest integer to a real number~$a$ (with ties broken
  upward) is denoted by $\round{a} = \floor{a+1/2}$.
\item For a real vector $\bfv\in \bbR^n$, its Euclidean (i.e.,
  $\ell_{2}$) norm is denoted by~$\length{\bfv}$.
\item For two $n$-dimensional vectors $\bfa, \bfb$ over a common
  ring~$R$, their inner product is denoted by
  $\inner{\bfa, \bfb} = \sum_{i=0}^{n-1} \bfa_{i} \bfb_{i} \in
  R$.
\end{itemize}

\else

Vectors are denoted with bold lower-case letters (e.g., $\bfa, \bfb, \bfv$),
and matrices are denoted with bold upper-case letters (e.g., $\bfA, \bfB, \bfS$).
For a set~$D$, the set of $m$-dimensional vectors with entries in~$D$ is denoted by~$D^{m}$,
and the set of $m$-by-$n$ matrices with entries in~$D$ is denoted by $D^{m \times n}$.
For an $n$-dimensional vector $\bfv$, its $i$th entry for $0\leq i < n$ is denoted by~$\bfv_i$.
For an $m$-by-$n$ matrix~$\bfA$, its $(i,j)$th entry (i.e., the entry in the $i$th row and $j$th
column) for $0 \leq i <m$ and $0 \leq j < n$ is denoted by~$\bfA_{i,j}$, and its $i$th row is
denoted by~$\bfA_i = (\bfA_{i,0},\bfA_{i,1},\ldots,\bfA_{i,n-1})$.
The transpose of a matrix~$\bfA$ is denoted by $\bfA^\text{T}$.  

An $m$-bit string $\bfk\in \set{0,1}^m$ is written as a vector over the set $\{0,1\}$ and
its $i$th bit for $0 \leq i < m$ is denoted by~$\bfk_i$. 
The ring of integers is denoted by $\bbZ$, and, for a positive integer~$q$, the quotient ring
of integers modulo~$q$ is denoted by $\bbZ_q = \bbZ/q\bbZ$.
For a probability distribution~$\chi$, the notation $e \getsr \chi$ denotes drawing a value~$e$
according to~$\chi$.
The $n$-fold product distribution of~$\chi$ with itself is denoted by~$\chi^{n}$.
For a finite set~$S$, the uniform distribution on~$S$ is denoted by~$U(S)$.
The floor of a real number~$a$, i.e., the largest integer less than or equal to $a$,
is denoted by~$\floor{a}$.
The closest integer to a real number~$a$ (with ties broken upward) is denoted by
$\round{a} = \floor{a+1/2}$.
For a real vector $\bfv\in \bbR^n$, its Euclidean (i.e., $\ell_{2}$) norm is denoted
by~$\length{\bfv}$.
For two $n$-dimensional vectors $\bfa, \bfb$ over a common ring~$R$, their inner product
is denoted by $\inner{\bfa, \bfb} = \sum_{i=0}^{n-1} \bfa_{i} \bfb_{i} \in R$.

\fi

\subsection{Cryptographic definitions}
\label{sec:background:crypto}

This section states definitions of the cryptographic primitives that are specified in this document, along with their correctness and security notions.
This document specifies a key encapsulation mechanism (KEM), formally defined by three algorithms as follows.

\begin{definition}[Key encapsulation mechanism]
A \emph{key encapsulation mechanism} $\KEM$ is a tuple of algorithms
$(\KeyGen,\Encaps,\Decaps)$ along with a finite keyspace $\KeySp$:
\begin{itemize}
\item $\KeyGen() \tor (\pk, \sk)$: A probabilistic \emph{key generation algorithm} that outputs a public key $\pk$ and a secret key $\sk$.
\item $\Encaps(\pk) \tor (c, \ssk)$: A probabilistic \emph{encapsulation algorithm} that takes as input a public key $\pk$, and outputs an encapsulation $c$ and a shared secret $\ssk \in \KeySp$.  The encapsulation is sometimes called a ciphertext.
\item $\Decaps(c, \sk) \to \ssk'$: A (usually deterministic) \emph{decapsulation algorithm} that takes as input an encapsulation $c$ and a secret key $\sk$, and outputs a shared secret $\ssk' \in \KeySp$.
\end{itemize}
\end{definition}

The notion of $\delta$-correctness gives a bound on the probability of a legitimate protocol execution producing different keys in encapsulation and decapsulation. 

\begin{definition}[$\delta$-correctness for KEMs]
A key encapsulation mechanism $\KEM$ is \emph{$\delta$-correct} if
\[ \Pr\left[ \ssk' \ne \ssk : (\pk, \sk) \getsr \KEM.\KeyGen(); (c, \ssk) \getsr \KEM.\Encaps(\pk);  \ssk' \gets \KEM.\Decaps(c, \sk) \right] \le \delta\enspace . \]
\end{definition}

The following defines \INDCCA security for a key encapsulation mechanism.

\begin{definition}[$\INDCCA$ for KEMs]
  Let $\KEM$ be a key encapsulation mechanism with keyspace $\KeySp$,
  and let~$\Adversary$ be an algorithm.  The security experiment for
  \emph{indistinguishability under adaptive chosen ciphertext attack
    (\INDCCATwo, or just \INDCCA)} of $\KEM$ is
  $\Exp{\indcca}{\KEM}(\Adversary)$ shown in \autoref{fig:kem-indcca}.
  The advantage of~$\Adversary$ in the experiment is
\[ \Adv{\indcca}{\KEM}(\Adversary) := \left| \Pr\left[ \Exp{\indcca}{\KEM}(\Adversary) \Rightarrow 1 \right] - \frac{1}{2} \right| \enspace . \]
\end{definition}

Note that $\Adversary$ can be a classical or quantum algorithm.  If
$\Adversary$ is a quantum algorithm, then we only consider the model
in which the adversary makes classical queries to its $\ODecaps$ oracle.

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.4\textwidth}
\underline{Experiment $\Exp{\indcca}{\KEM}(\Adversary)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $(\pk, \sk) \getsr \KEM.\KeyGen()$
\STATE $b \getsr \{0,1\}$
\STATE $(c^*, \ssk_0) \getsr \KEM.\Encaps(\pk)$
\STATE $\ssk_1 \getsr U(\KeySp)$
\STATE $b' \getsr \Adversary^{\ODecaps(\cdot)}(\pk,\ssk_b, c^*)$
\IF {$b'=b$}
  \RETURN $1$
\ELSE
  \RETURN $0$
\ENDIF
\end{algorithmic}
\end{minipage}
~
\begin{minipage}[t]{0.4\textwidth}
\underline{Oracle $\ODecaps(c)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\IF {$c = c^*$}
  \RETURN $\bot$
\ELSE
  \RETURN $\KEM.\Decaps(c, \sk)$
\ENDIF
\end{algorithmic}
\end{minipage}
}
\caption{Security experiment for indistinguishability under adaptive
  chosen ciphertext attack (\INDCCATwo, or just \INDCCA) of a key
  encapsulation mechanism $\KEM$ for an adversary $\Adversary$.}
\label{fig:kem-indcca}
\end{figure}

The key encapsulation mechanism specified in this document is obtained by a transformation from a public-key encryption (PKE) scheme; a PKE scheme is formally defined as follows.

\begin{definition}[Public-key encryption scheme]
  A \emph{public-key encryption scheme} $\PKE$ is a tuple of
  algorithms $(\KeyGen,\Enc,\Dec)$ along with a message space
  $\MsgSp$:
\begin{itemize}
\item $\KeyGen() \tor (\pk, \sk)$: A probabilistic \emph{key generation algorithm} that outputs a public key $\pk$ and a secret key $\sk$.
\item $\Enc(m, \pk) \tor c$: A probabilistic \emph{encryption
    algorithm} that takes as input a message $m \in \MsgSp$ and public
  key $\pk$, and outputs a ciphertext $c$.  The deterministic form is
  denoted $\Enc(m, \pk; r) \to c$, where the randomness
  $r \in \RandSp$ is passed as an explicit input; $\RandSp$ is called
  the \emph{randomness space} of the encryption algorithm.
\item $\Dec(c, \sk) \to m'$ or $\bot$: A deterministic
  \emph{decryption algorithm} that takes as input a ciphertext $c$ and
  secret key $\sk$, and outputs a message $m' \in \MsgSp$ or a
  special error symbol $\bot \notin \MsgSp$.
\end{itemize}
\end{definition}

The notion of $\delta$-correctness captures an upper bound on the
probability of decryption failure in a legitimate execution of the
scheme.
\begin{definition}[$\delta$-correctness for PKEs~\cite{TCC:HofHovKil17}]
  \label{def:delta-correct}
  A public-key encryption scheme $\PKE$ with message space $\MsgSp$ is
  \emph{$\delta$-correct} if
  \begin{equation}
    \label{eq:delta-correct}
    \mathbb{E}\left[ \max_{m \in \MsgSp} \Pr\left[ \PKE.\Dec(c, \sk)
        \neq m : c \getsr \PKE.\Enc(m, \pk) \right] \right] \leq
    \delta \enspace,
  \end{equation}
  where the expectation is taken over
  $(\pk, \sk) \getsr \PKE.\KeyGen()$.
\end{definition}
In our PKE, the probability expression in
Equation~\eqref{eq:delta-correct} has no dependence on~$m$, so the
condition simplifies to
\begin{equation}
  \label{eq:simpler-delta-correct}
  \Pr\left[ \PKE.\Dec(c, \sk)
    \neq m : (\pk, \sk) \gets \PKE.\KeyGen(); c \getsr \PKE.\Enc(m,
    \pk) \right]  \leq \delta \enspace ,
\end{equation}
which is what we analyze when calculating the probability of
decryption failure (see \autoref{sec:cpa-pke-correctness}).

The PKE scheme we use as the basis for the KEM transformation in
\autoref{sec:cca-transform} is required to satisfy the
notion of \INDCPA security, which is defined as follows.

\begin{definition}[$\INDCPA$ for PKE]
  Let $\PKE$ be a public-key encryption scheme, and let $\Adversary$
  be an algorithm.  The security experiment for
  \emph{indistinguishability under chosen plaintext attack (\INDCPA)}
  of $\PKE$ is $\Exp{\indcpa}{\PKE}(\Adversary)$ shown in
  \autoref{fig:pke-indcpa}.  The advantage of~$\Adversary$ in the
  experiment is
\[ \Adv{\indcpa}{\PKE}(\Adversary) := \left| \Pr\left[ \Exp{\indcpa}{\PKE}(\Adversary) \Rightarrow 1 \right] - \frac{1}{2} \right| . \]
\end{definition}
Note that $\Adversary$ can be a classical or quantum algorithm.

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.4\textwidth}
\underline{Experiment $\Exp{\indcpa}{\PKE}(\Adversary)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $(\pk, \sk) \getsr \PKE.\KeyGen()$
\STATE $(m_0, m_1, st) \getsr \Adversary(\pk)$
\STATE $b \getsr \{0,1\}$
\STATE $c^* \getsr \PKE.\Enc(m_b, \pk)$
\STATE $b' \getsr \Adversary(\pk, c^*, st)$
\IF {$b'=b$}
  \RETURN $1$
\ELSE
  \RETURN $0$
\ENDIF
\end{algorithmic}
\end{minipage}
}
\caption{Security experiment for indistinguishability under chosen plaintext attack (\INDCPA) of a public-key encryption scheme $\PKE$ against an adversary $\Adversary$.}
\label{fig:pke-indcpa}
\end{figure}

\subsection{Learning With Errors}
\label{sec:lwe}

The security of our proposed PKE and KEM relies on the hardness of the
\emph{Learning With Errors} (LWE) problem, a generalization of the
classic Learning Parities with Noise problem (see,
e.g.,~\cite{C:BFKL93}) first defined by Regev~\cite{Reg09}. This
section defines the LWE probability distributions and computational
problems.

\begin{definition}[LWE distribution]
  \label{def:lwe-distrib}
  Let $n, q$ be positive integers, and let $\chi$ be a distribution
  over $\bbZ$.  For an $\bfs \in \bbZ_q^n$, the \emph{LWE
    distribution} $A_{\bfs, \chi}$ is the distribution over
  $\bbZ_q^n \times \bbZ_q$ obtained by choosing $\bfa \in \bbZ_q^n$
  uniformly at random and an integer error $e \in \bbZ$ from~$\chi$,
  and outputting the pair
  $(\bfa, \inner{\bfa, \bfs} + e \bmod q) \in \bbZ_q^n \times \bbZ_q$.
\end{definition}

There are two main kinds of computational LWE problem: \emph{search},
which is to recover the secret~$\bfs \in \bbZ_{q}^{n}$ given a certain
number of samples drawn from the LWE distribution~$A_{\bfs, \chi}$;
and \emph{decision}, which is to distinguish a certain number of
samples drawn from the LWE distribution from uniformly random samples.
For both variants, one often considers two distributions of the
secret~$\bfs \in \bbZ_{q}^{n}$: the uniform distribution, and the
distribution~$\chi^{n} \bmod{q}$ where each coordinate is drawn from
the error distribution~$\chi$ and reduced modulo~$q$. The latter is
often called the ``normal form'' of LWE.

\begin{definition}[LWE Search Problem]
  \label{def:slweproblem}
  Let $n, m, q$ be positive integers, and let $\chi$ be a distribution
  over~$\bbZ$.  The \emph{uniform-secret} (respectively,
  \emph{normal-form}) learning with errors \emph{search} problem with
  parameters $(n, m, q, \chi)$, denoted by $\SLWE_{n,m,q,\chi}$
  (respectively, $\nfSLWE_{n,m,q,\chi}$), is as follows: given~$m$
  samples from the LWE distribution $A_{\bfs, \chi}$ for uniformly
  random~$\bfs$ (resp, $\bfs \getsr \chi^{n} \bmod q$), find $\bfs$.
  More formally, for an adversary~$\Adversary$, define (for the
  uniform-secret case)
  \[ \Adv{\slwe}{n,m,q,\chi}(\Adversary) = \Pr \bracks*{
      \Adversary(((\bfa_i, b_{i}))_{i=1,\ldots,m}) \Rightarrow \bfs
      : \bfs \getsr U(\bbZ_q^n), (\bfa_{i}, b_{i}) \getsr A_{\bfs,
        \chi} \text{ for } i=1,\ldots,m } \enspace . \] Similarly,
  define (for the normal-form case)
  $\Adv{\nfslwe}{n,m,q,\chi}(\Adversary)$, where
  $\bfs \getsr \chi^{n} \bmod q$ instead of
  $\bfs \getsr U(\bbZ_{q}^{n})$.
\end{definition}

\begin{definition}[LWE Decision Problem]
  \label{def:dlweproblem}
  Let $n, m, q$ be positive integers, and let~$\chi$ be a distribution
  over~$\bbZ$.  The \emph{uniform-secret} (respectively,
  \emph{normal-form}) \emph{learning with errors decision problem}
  with parameters $(n, m, q, \chi)$, denoted $\DLWE_{n,m,q,\chi}$ 
  (respectively, $\nfDLWE_{n,m,q,\chi}$), is as follows: distinguish~$m$
  samples drawn from the LWE distribution $A_{\bfs, \chi}$ from~$m$
  samples drawn from the uniform distribution
  $U(\bbZ_q^n \times \bbZ_q)$.  More formally, for an adversary
  $\Adversary$, define (for the uniform-secret case)
  \begin{align*}
    \Adv{\dlwe}{n,m,q,\chi}(\Adversary) = \Big|
      &\Pr \bracks*{
      \Adversary((\bfa_{i}, b_{i})_{i=1,\ldots,m}) \Rightarrow 1 :
      \bfs \getsr U(\bbZ_q^n), (\bfa_{i}, b_{i}) \getsr
      A_{\bfs,\chi} \text{ for } i=1,\ldots, m } \\
    - &\Pr \bracks*{
      \Adversary((\bfa_{i}, b_{i})_{i=1,\ldots,m}) \Rightarrow 1 :
      (\bfa_{i}, b_{i}) \getsr U(\bbZ_{q}^{n} \times \bbZ_{q})
      \text{ for } i=1,\ldots, m } \Big| \enspace .
  \end{align*}
  %
  Similarly, define (for the normal-form case)
  $\Adv{\nfdlwe}{n,m,q,\chi}(\Adversary)$,  where
  $\bfs \getsr \chi^{n} \bmod q$ instead of
  $\bfs \getsr U(\bbZ_{q}^{n})$.
\end{definition}

For all of the above problems, when~$\chi = \Psi_{\alpha q}$ is the
continuous Gaussian of parameter~$\alpha q$, rounded to the nearest
integer (see \autoref{def:rounded-gaussian} below), we sometimes
replace the subscript~$\chi$ by~$\alpha$.

\subsection{Gaussians}
\label{sec:gaussians}

For any real $s > 0$, the (one-dimensional) \emph{Gaussian function}
with parameter (or width)~$s$ is the function
$\rho_{s} \colon \bbR \to \bbR^{+}$, defined as
\[ \rho_s(\bfx) := \exp(-\pi \norm{\bfx}^2/s^2) \enspace .\]

\begin{definition}[Gaussian distribution]
  \label{def:gaussian}
  For any real $s > 0$, the (one-dimensional) \emph{Gaussian
    distribution} with parameter (or width)~$s$, denoted~$D_{s}$, is
  the distribution over~$\bbR$ having probability density function
  $D_{s}(x) = \rho_{s}(x)/s$.
\end{definition}
Note that $D_{s}$ has standard deviation $\sigma = s / \sqrt{2 \pi}$.

\begin{definition}[Rounded Gaussian distribution]
  \label{def:rounded-gaussian}
  For any real $s > 0$, the \emph{rounded Gaussian distribution} with
  parameter (or width)~$s$, denoted $\Psi_s$, is the distribution
  over~$\bbZ$ obtained by rounding a sample from~$D_{s}$ to the
  nearest integer:
  \begin{equation*}
    \Psi_s(x) = \int_{\{z\colon \lfloor z \rceil =
      x\}} D_s(z) \, dz \enspace .
  \end{equation*}
\end{definition}

\subsection{Lattices}
\label{sec:lattices}

Here we recall some background on lattices that will be used when
relating LWE to lattice problems.

\begin{definition}[Lattice]
  \label{def:lattice}
  A (full-rank) \emph{$n$-dimensional lattice} $\calL$ is a discrete
  additive subset of $\bbR^n$ for which
  $\text{span}_{\bbR}(\calL) = \bbR^{n}$. Any such lattice can be
  generated by a (non-unique) \emph{basis}
  $\bfB = \set{ \bfb_1, \dots, \bfb_n } \subset \bbR^n$ of linearly
  independent vectors, as
  \[ \calL = \calL(\bfB) := \bfB \cdot \bbZ^n = \set[\Big]{ \sum_{i =
        1}^n z_i \cdot \bfb_i\colon z_i \in \bbZ } \enspace . \] The
  \emph{volume}, or \emph{determinant}, of~$\calL$ is defined as
  $\vol(\calL) := \abs{\det(\bfB)}$. An \emph{integer lattice} is a
  lattice that is a subset of~$\bbZ^{n}$. For an integer $q$, a
  \emph{$q$-ary lattice} is an integer lattice that
  contains~$q\bbZ^{n}$.
\end{definition}

\begin{definition}[Minimum distance]
  \label{def:minimum-dist}
  For a lattice~$\calL$, its \emph{minimum distance} is the length (in
  the Euclidean norm) of a shortest non-zero lattice vector:
  \[ \lambda_1(\calL) = \min_{\bfv \in \calL \setminus \set{
        \mathbf{0} }} \length{ \bfv } \enspace . \]
  More generally, its \emph{$i$th successive minimum}
  $\lambda_i(\calL)$ is the smallest real $r > 0$ such that~$\calL$
  has~$i$ linearly independent vectors of length at most~$r$.
\end{definition}

\begin{definition}[Discrete Gaussian]
  \label{def:discrete-gaussian}
  For a lattice $\calL \subset \bbR^{n}$, the \emph{discrete Gaussian
    distribution} over~$\calL$ with parameter~$s$, denoted
  $D_{\calL,s}$, is defined as
  $D_s(\bfx) = \rho_s(\bfx) / \rho_s(\calL)$ for $\bfx \in \calL$ (and
  $D_{s}(\bfx)=0$ otherwise), where
  $\rho_s(\calL) = \sum_{\bfv \in \calL}\rho_s(\bfv)$ is a
  normalization factor.
\end{definition}

We now recall various computational problems on lattices. We stress
that these are \emph{worst-case} problems, i.e., to solve such a
problem an algorithm must succeed on \emph{every} input. The following
two problems are parameterized by an \emph{approximation factor}
$\gamma = \gamma(n)$, which is a function of the lattice dimension $n$.

\begin{definition}[Decisional approximate shortest vector problem
  ($\GapSVP_\gamma$)]
  \label{def:GapSVP}
  Given a basis $\bfB$ of an $n$-dimensional lattice
  $\calL = \calL(\bfB)$, where $\lambda_1(\calL) \leq 1$ or
  $\lambda_1(\calL) > \gamma(n)$, determine which is the case.
\end{definition}

\begin{definition}[Approximate shortest independent vectors problem
  ($\SIVP_\gamma$)]
  \label{def:SIVP}
  Given a basis $\bfB$ of an $n$-dimensional lattice
  $\calL = \calL(\bfB)$, output a set
  $\set{ \bfv_{1}, \ldots, \bfv_{n} } \subset \calL$ of~$n$ linearly
  independent lattice vectors where
  $\length{ \bfv_i } \leq \gamma(n) \cdot \lambda_n(\calL)$ for all~$i$.
\end{definition}

The following problem is parameterized by a function~$\varphi$ from
lattices to positive real numbers.

\begin{definition}[Discrete Gaussian Sampling ($\DGS_{\varphi}$)]
  \label{def:DGS}
  Given a basis~$\bfB$ of an $n$-dimensional lattice $\calL =
  \calL(\bfB)$ and a real number $s \geq \varphi(L)$, output a sample
  from the discrete Gaussian distribution $D_{L,s}$.
\end{definition}

\section{Algorithm description}\label{sec:algs}

This section specifies the algorithms comprising the $\FrodoKEM$ key encapsulation mechanism.  $\FrodoKEM$ is built from a public-key encryption scheme, $\FrodoPKE$, as well as several other components.

\paragraph{Notation.}
The algorithms in this document are described in terms of the following parameters:
\begin{itemize}
\item $\chi$, a probability distribution on $\bbZ$;
\item $q=2^D$, a power-of-two integer modulus with exponent $D\leq 16$;
\item $n,\mbar,\nbar$, integer matrix dimensions with $n \equiv 0
  \pmod 8$;
\item $B\leq D$, the number of bits encoded in each matrix entry;
\item $\ell=B\cdot \mbar\cdot\nbar$, the length of bit strings that are encoded as $\mbar$-by-$\nbar$ matrices;
\item $\lengthseedA$, the bit length of seeds used for pseudorandom matrix generation;
\item $\lengthseedSE$, the bit length of seeds used for pseudorandom bit generation for error sampling.
\end{itemize}

Additional parameters for specific algorithms accompany the algorithm description.

\subsection{Matrix encoding of bit strings}
\label{sec:matrix-encoding}

This subsection describes how bit strings are encoded as mod-$q$ integer matrices.
Recall that $2^B \leq q$. The encoding function $\encode(\cdot)$ encodes an integer $0 \leq k < 2^B$ as an element in $\bbZ_q$ by multiplying it by $q/2^B=2^{D-B}$:
\[ \encode(k) := k\cdot  q/2^B \enspace . \]
This encoding function can be found in early works on LWE-based encryption, for example \cite{PKC:KawTanXag07,STOC:PeiWat08,C:PeiVaiWat08}.
Using this function, the function $\Frodo.\Encode$ encodes bit strings of
length $\ell=B\cdot \mbar\cdot\nbar$ as  $\mbar$-by-$\nbar$-matrices with
entries in $\bbZ_q$ by applying $\encode(\cdot)$ to $B$-bit sub-strings sequentially and filling the matrix row by row entry-wise. The function $\Frodo.\Encode$ is shown in \autoref{alg:encode}.
Each $B$-bit sub-string is interpreted as an integer $0 \leq k < 2^B$ and then encoded by $\encode(k)$, which means that $B$-bit values are placed into the $B$ most significant bits of the corresponding entry modulo $q$.  

The corresponding decoding function $\Frodo.\Decode$ is defined as shown in
\autoref{alg:decode}. It decodes the $\mbar$-by-$\nbar$ matrix $\bfK$ into a
bit string of length $\ell=B\cdot\mbar\cdot\nbar$. It extracts $B$ bits from
each entry by applying the function $\decode(\cdot)$:
\[ \decode(c) = \round{c \cdot 2^B/q} \bmod 2^B \enspace . \]
That is, the $\bbZ_{q}$-entry is interpreted as an integer, then
divided by $q/2^B$ and rounded. This amounts to rounding to the $B$
most significant bits of each entry. With these definitions, it is the case that $\decode(\encode(k)) = k$ for all $0\leq k < 2^B$.

\begin{figure}[h!]
\centering
\begin{minipage}[t]{0.45\textwidth}
\begin{algorithm}[H]
\caption{\label{alg:encode} $\Frodo.\Encode$}
% Ananth: I use phantom to make sure that the two Algorithm margins align in
% the final multicol
{\bf Input:} Bit string $\bfk\in \{0,1\}^\ell$, $\ell = B\cdot\mbar\cdot\nbar$.\phantom{$\bbZ_q^{\mbar\times\nbar}$}\\
{\bf Output:} Matrix $\bfK \in \bbZ_q^{\mbar \times \nbar}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \FOR{($i = 0$; $i < \mbar$;  $i\gets i + 1$)}   
    \FOR{($j = 0$; $j < \nbar$;  $j\gets j+1$)}
    \STATE $k \gets \sum_{l=0}^{B-1}\bfk_{(i\cdot \nbar + j)B+l}\cdot 2^l$
    \STATE $\bfK_{i,j} \gets \encode(k)= k\cdot q/2^B$
    \ENDFOR
    \ENDFOR
    \RETURN$\bfK = (\bfK_{i,j})_{0\leq i < \mbar, 0 \leq j < \nbar}$
\end{algorithmic}
\end{algorithm}
\end{minipage}
~
\begin{minipage}[t]{0.45\textwidth}
\begin{algorithm}[H]
\caption{\label{alg:decode} $\Frodo.\Decode$}
{\bf Input:} Matrix $\bfK \in \bbZ_q^{\mbar\times\nbar}$.\\
{\bf Output:} Bit string $\bfk \in \{0,1\}^\ell$, $\ell = B\cdot\mbar\cdot\nbar$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \FOR{($i = 0$; $i < \mbar$;  $i\gets i+1$)}   
    \FOR{($j = 0$; $j < \nbar$;  $j\gets j+1$)}
    \STATE $k \gets \decode(\bfK_{i,j})= \round{\bfK_{i,j}\cdot 2^B/q} \bmod 2^B$
    \STATE $k = \sum_{l=0}^{B-1}k_l \cdot 2^l$ \text{ where } $k_l\in \{0,1\}$
    \FOR{($l = 0$; $l < B$; $l\gets l+1$)}
    \STATE $\bfk_{(i\cdot \nbar + j)B+l} \gets k_l$ 
    \ENDFOR
    \ENDFOR
    \ENDFOR
    \RETURN$\bfk$
\end{algorithmic}
\end{algorithm}
\vspace{-0.5em}
\textit{Note to implementers: recall $\round{x} = \lfloor x + \frac{1}{2} \rfloor$.}
\end{minipage}
\end{figure}

\subsection{Packing matrices modulo $q$}
\label{sec:pack}

This section specifies packing and unpacking algorithms to transform
matrices with entries in $\bbZ_q$ to bit strings and vice versa. The
algorithm $\Frodo.\Pack$ packs a matrix into a bit string by simply
concatenating the $D$-bit matrix coefficients, as shown in
\autoref{alg:frodopack}. Note that in the software implementation, the
resulting bit string is stored as a byte array, padding with zero bits
to make the length a multiple of~$8$. The reverse operation
$\Frodo.\Unpack$ is shown in \autoref{alg:frodounpack}.

\begin{figure}[h!]
\centering
\begin{minipage}[t]{0.45\textwidth}
\begin{algorithm}[H]
\caption{\label{alg:frodopack} $\Frodo.\Pack$}
{\bf Input:} Matrix $\bfC \in \bbZ_q^{n_1\times n_2}$.\\
{\bf Output:} Bit string $\bfb \in \{0,1\}^{D\cdot n_1\cdot n_2}$.\phantom{$\bbZ_q^{\mbar\times\nbar}$}\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \FOR{($i = 0$; $i < n_1$;  $i\gets i+1$)}   
    \FOR{($j = 0$; $j < n_2$;  $j\gets j+1$)}
    \STATE $\bfC_{i,j} = \sum_{l=0}^{D-1}c_l \cdot 2^l$ \text{ where } $c_l\in \{0,1\}$
    \FOR{($l = 0$; $l < D$; $l\gets l+1$)}
    \STATE $\bfb_{(i\cdot n_2  + j)D+l} \gets c_{D-1-l}$ 
    \ENDFOR
    \ENDFOR
    \ENDFOR
    %\FOR{($i = 0$; $i < D\cdot n_1\cdot n_2/8$;  $i\gets i+1$)}
    %\STATE $b_\bfC[i] \gets \sum_{l=0}^{7} \bfb_{8i + l} \cdot 2^{7-l}$
    %\ENDFOR
    \RETURN $\bfb$
\end{algorithmic}
\end{algorithm}
\end{minipage}
~
\begin{minipage}[t]{0.5\textwidth}
\begin{algorithm}[H]
\caption{\label{alg:frodounpack} $\Frodo.\Unpack$}
{\bf Input:}  Bit string $\bfb \in \{0,1\}^{D\cdot n_1\cdot n_2}$, $n_1$, $n_2$.\phantom{$\bbZ_q^{\mbar\times\nbar}$}\\
{\bf Output:} Matrix $\bfC \in \bbZ_q^{n_1\times n_2}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    %\FOR{($i = 0$; $i < D\cdot n_1\cdot n_2/8$;  $i\gets i+1$)}
    %\STATE $b_\bfC[i] = \sum_{l=0}^{7} c_l 2^l$, $c_l\in \{0,1\}$
    %\FOR{($l = 0$; $l < 8$; $l\gets l+1$)}
    %\STATE $\bfb_{8i+l} \gets c_{7-l}$
    %\ENDFOR
    %\ENDFOR
    \FOR{($i = 0$; $i < n_1$;  $i\gets i+1$)}   
    \FOR{($j = 0$; $j < n_2$;  $j\gets j+1$)}
    \STATE $\bfC_{i,j} \gets \sum_{l=0}^{D-1}\bfb_{(i\cdot n_2  + j)D+l}\cdot 2^{D-1-l}$
    \ENDFOR
    \ENDFOR
    \RETURN $\bfC$
\end{algorithmic}
\end{algorithm}
\end{minipage}
\end{figure}

\subsection{Deterministic random bit generation}\label{sec:rbg}

$\FrodoKEM$ requires the deterministic generation of random bit
sequences from a random seed value. This is done using the
SHA-3-derived extendable output function
$\SHAKE$~\cite{dworkin2015sha}. The function $\SHAKE$ is taken as
either $\SHAKE128$ or $\SHAKE256$ (indicated below for each
parameter set of $\FrodoKEM$), and takes as input a bit string $X$ and a
requested output bit length $L$.

\subsection{Sampling from the error distribution}\label{sec:sampling}

The error distribution~$\chi$ used in $\FrodoKEM$ is a discrete,
symmetric distribution on $\bbZ$, centered at zero and with small
support, which approximates a rounded continuous Gaussian
distribution.

The support of~$\chi$ is
$S_{\chi}=\set{-s, -s+1, \dots, -1, 0, 1, \dots, s-1, s}$ for a
positive integer $s$. The probabilities $\chi(z) = \chi(-z)$ for
$z \in S_{\chi}$ are given by a discrete probability density function,
which is described by a table
\[ T_{\chi} = (T_{\chi}(0), T_{\chi}(1), \dots, T_{\chi}(s)) \] of
$s+1$ positive integers related to the cumulative distribution function.  For a
certain positive integer $\lengthchi$, the table entries satisfy the
following conditions:
\[ T_{\chi}(0) = 2^{\lengthchi-1}\cdot \chi(0)-1 \quad\quad \textrm{and} \quad\quad
  T_{\chi}(z) = T_{\chi}(0) + 2^{\lengthchi}\sum_{i=1}^z\chi(i) \enspace \textrm{ for
  } 1 \leq z \leq s. \]

Since the distribution $\chi$ is symmetric and centered at zero, it is easy to verify that
$T_{\chi}(s) = 2^{\lengthchi-1}-1$.

Sampling from~$\chi$ via inversion sampling is done as shown in
\autoref{alg:samplechi}.  Given a string of~$\lengthchi$ uniformly
random bits~$\bfr \in \bit^{\lengthchi}$ and a distribution table
$T_{\chi}$, the algorithm $\Frodo.\Samp$ returns a sample~$e$ from the
distribution $\chi$. (Note that $T_\chi(s)$ is never accessed.)
We emphasize that it is important to perform
this sampling in constant time to avoid exposing timing side-channels,
which is why Step~\ref{alg:sample:loop} of the algorithm does a complete loop through the
entire table~$T_{\chi}$. The comparison in Step~\ref{alg:sample:cmp} needs
to be implemented in a constant-time manner.

\begin{algorithm}[H]
\caption{\label{alg:samplechi} $\Frodo.\Samp$}
{\bf Input:} A (random) bit string $\bfr = (\bfr_0, \bfr_1, \dots,
\bfr_{\lengthchi-1}) \in \bit^{\lengthchi}$, the table $T_{\chi} = (T_{\chi}(0), T_{\chi}(1), \dots, T_{\chi}(s))$.\\
{\bf Output:} A sample $e \in \bbZ$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE $t \gets \sum_{i=1}^{\lengthchi-1} \bfr_i\cdot 2^{i-1}$
    \STATE $e\gets 0$
    \FOR{($z = 0$; $z < s$;  $z\gets z+1$)}\label{alg:sample:loop}
    \IF{$t > T_\chi(z)$}\label{alg:sample:cmp}
    \STATE $e\gets e+1$
    \ENDIF
    \ENDFOR
    \STATE $e\gets (-1)^{\bfr_0}\cdot e$
    \RETURN$e$
\end{algorithmic}
\end{algorithm}

An $n_1$-by-$n_2$ matrix of~$n_1n_2$ samples from the error
distribution is sampled on input of a 
$(n_1n_2 \cdot \lengthchi)$-bit string, here written as a sequence 
$(\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(n_1n_2-1)})$ of
$n_1n_2$ bit vectors of length
$\lengthchi$ each,
by sampling~$n_1n_2$ error terms through calls to $\Frodo.\Samp$ on a
corresponding $\lengthchi$-bit substring~$\bfr^{(i\cdot n_2 + j)}$ and
the distribution table $T_\chi$ to sample the matrix entry
$\bfE_{i,j}$. The algorithm $\Frodo.\SampV$ is shown in
\autoref{alg:samplevecchi}.

\begin{algorithm}[H]
\caption{\label{alg:samplevecchi} $\Frodo.\SampV$}
{\bf Input:} A (random) bit string $(\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(n_1n_2-1)}) \in \{0,1\}^{n_1n_2 \cdot \lengthchi}$ (here, each $\bfr^{(i)}$ is a vector of $\lengthchi$ bits), the
  table $T_{\chi}$.\\
  % = (T_{\chi}(0), T_{\chi}(1), \dots, T_{\chi}(s))$
{\bf Output:} A sample $\bfE \in \bbZ^{n_1\times n_2}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \FOR{($i = 0$; $i < n_1$;  $i\gets i+1$)}
    \FOR{($j = 0$; $j < n_2$;  $j\gets j+1$)}
    \STATE $\bfE_{i,j} \gets \Frodo.\Samp(\bfr^{(i\cdot n_2 + j)}, T_\chi)$
    \ENDFOR
    \ENDFOR
    \RETURN$\bfE$
\end{algorithmic}
\end{algorithm}

\subsection{Pseudorandom matrix generation}
\label{sec:genA}

The algorithm $\Frodo.\gen$ takes as input a seed
$\seedA\in\{0,1\}^\lengthseedA$ and a dimension $n\in\bbZ$, and outputs
a pseudorandom matrix $\bfA\in \bbZ_q^{n\times n}$. There are two
options for instantiating $\Frodo.\gen$. The first one uses
$\AESOneTwoEight$ and is shown in	 \autoref{alg:genA_AES}; the second
uses $\SHAKE128$ and is shown in \autoref{alg:genA_SHAKE}.

\paragraph{Using $\AESOneTwoEight$.}

\autoref{alg:genA_AES} generates a matrix
$\bfA \in \bbZ_{q}^{n\times n}$ as follows.  For each row
index $i=0,1,\ldots,n-1$ and column index $j=0,8,\ldots,n-8$, the
algorithm generates a 128-bit block, which it uses to set the matrix
entries $\bfA_{i,j}, \bfA_{i,j+1}, \ldots, \bfA_{i,j+7}$ as follows.  It
applies $\AESOneTwoEight$ with key $\seedA$ to the input block
$\inner{i} \| \inner{j} \| 0 \cdots 0 \in \bit^{128}$, where $i,j$ are
encoded as 16-bit strings, represented in little-endian byte order. It then splits the 128-bit AES output block
into eight 16-bit strings, which it interprets as nonnegative
integers~$c_{i,j+k}$ for $k=0,1,\ldots,7$ in little-endian byte order.  Finally, it sets
$\bfA_{i,j+k}= c_{i,j+k} \bmod q$ for all~$k$.

\begin{algorithm}[H]
\caption{\label{alg:genA_AES} $\Frodo.\gen$ using $\AESOneTwoEight$}
{\bf Input:} Seed $\seedA \in \{0,1\}^\lengthseedA$.\\
{\bf Output:} Matrix $\bfA \in \bbZ_q^{n\times n}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \FOR{($i = 0$; $i < n$;  $i\gets i+1$)}
    \FOR{($j = 0$; $j < n$;  $j\gets j+8$)}
    \STATE $\bfb \gets \inner{i} \| \inner{j} \|0 \cdots 0 \in
    \bit^{128}$ where $\inner{i}, \inner{j} \in \bit^{16}$
    \STATE $\inner{c_{i,j}} \| \inner{c_{i,j+1}} \| \cdots \| \inner{c_{i,j+7}} \gets
    \AESOneTwoEight_{\seedA}(\bfb)$ where each $\inner{c_{i,k}} \in \bit^{16}$
    \FOR{($k=0$; $k<8$; $k\gets k+1$)}
    \STATE $\bfA_{i,j+k} \gets c_{i,j+k} \bmod q$
    \ENDFOR
    \ENDFOR
    \ENDFOR
    \RETURN $\bfA$
\end{algorithmic}
\end{algorithm}

\paragraph{Using $\SHAKE128$.}

\autoref{alg:genA_SHAKE} generates a matrix
$\bfA \in \bbZ_{q}^{n \times n}$ as follows. For each row index
$i=0,1,\ldots,n-1$, it calls $\SHAKE128$ with a main input
of~$\seedA$, prefixed with a counter (represented as a 16-bit integer in little-endian byte order), to produce a
$16n$-bit output string. It splits this output into 16-bit integers (in little-endian byte order)
$c_{i,j}$ for $j=0,1,\ldots, n-1$, and sets
$\bfA_{i,j} = c_{i,j} \bmod q$ for all~$j$.

\begin{algorithm}[H]
\caption{\label{alg:genA_SHAKE} $\Frodo.\gen$ using $\SHAKE128$}
{\bf Input:} Seed $\seedA \in \{0,1\}^\lengthseedA$.\\
{\bf Output:} Pseudorandom matrix $\bfA \in \bbZ_q^{n\times n}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \FOR{($i = 0$; $i < n$;  $i\gets i+1$)}
    \STATE $\bfb \gets \inner{i} \| \seedA \in
    \bit^{16+\lengthseedA}$ where $\inner{i} \in \bit^{16}$
    \STATE $\inner{c_{i,0}} \| \inner{c_{i,1}} \| \cdots \|
    \inner{c_{i,n-1}} \gets \SHAKE128(\bfb, 16n)$
    where each $\inner{c_{i,j}} \in \bit^{16}$
    \FOR{($j = 0$; $j < n$;  $j\gets j+1$)}
    \STATE $\bfA_{i,j} \gets c_{i,j} \bmod q$
    \ENDFOR
    \ENDFOR
    \RETURN$\bfA$
\end{algorithmic}
\end{algorithm}

\paragraph{Using other functions.}
In principle, other functions could be used to pseudorandomly generate the matrix $\bfA$, such as a lightweight stream cipher for platforms without the hardware instructions that make fast $\AES$ and $\SHAKE$ implementations possible.  As NIST currently does not standardize such a primitive, and the call for proposals indicated that submissions should use NIST primitives, we do not currently propose such an alternate instantiation.

\section{$\FrodoPKE$: \INDCPA-secure public-key encryption scheme}\label{sec:cpa-pke}

This section describes $\FrodoPKE$, a public-key encryption scheme
with fixed-length message space, targeting \INDCPA security, that will
be used as a building block for $\FrodoKEM$. $\FrodoPKE$ is based on
the public-key encryption scheme presented by Lindner and Peikert
in~\cite{RSA:LinPei11}, with the following adaptations and
specializations:
\begin{itemize}
\item The matrix $\bfA$ is generated from a seed using the function $\Frodo.\gen$ specified in \autoref{sec:genA}.
\item Several ($\mbar$) ciphertexts are generated at once.
\item The same Gaussian-derived error distribution is used for both
  key generation and encryption.
\end{itemize}

The PKE scheme is given by three algorithms
$(\FrodoPKE.\KeyGen, \FrodoPKE.\Enc, \FrodoPKE.\Dec)$, defined
respectively in \autoref{alg:PKE:KeyGen}, \autoref{alg:PKE:Enc}, and
\autoref{alg:PKE:Dec}.  $\FrodoPKE$ is parameterized by the following
parameters:
\begin{itemize}
\item $q=2^D$, a power-of-two integer modulus with exponent $D \leq 16$;
\item $n, \mbar, \nbar$, integer matrix dimensions with $n \equiv 0 \pmod 8$;
\item $B \leq D$, the number of bits encoded in each matrix entry;
\item $\ell=B\cdot \mbar\cdot\nbar$, the length of bit strings that are encoded as $\mbar$-by-$\nbar$ matrices;
\item $\lengthm = \ell$, the bit length of messages;
\item $\MsgSp = \{0,1\}^\lengthm$, the message space;
\item $\lengthseedA$, the bit length of seeds used for pseudorandom matrix generation;
\item $\lengthseedSE$, the bit length of seeds used for pseudorandom bit generation for error sampling;
\item $\Frodo.\gen$, the matrix-generation algorithm, either \autoref{alg:genA_AES} or \autoref{alg:genA_SHAKE};
\item $T_\chi$, the distribution table for sampling.
\end{itemize}
In the notation of~\cite{RSA:LinPei11}, their~$n_1$ and~$n_2$ both
equal~$n$ here, and their dimension~$\ell$ is~$\nbar$ here.

\begin{algorithm}[H]
\caption{\label{alg:PKE:KeyGen} $\FrodoPKE.\KeyGen$.}
{\bf Input:} None.\\
{\bf Output:} Key pair $(\pk, \sk) \in (\{0,1\}^\lengthseedA \times \mathbb{Z}_q^{n \times \nbar})\times \mathbb{Z}_q^{\nbar \times n}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE Choose a uniformly random seed $\seedA \getsr U(\{0,1\}^\lengthseedA)$
    \STATE Generate the matrix $\bfA \in \bbZ_q^{n \times n}$ via $\bfA\gets\Frodo.\gen(\seedA)$
    \STATE Choose a uniformly random seed $\seedSE \getsr U(\{0,1\}^\lengthseedSE)$
    \STATE Generate pseudorandom bit string $ (\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(2n\nbar-1)}) \gets \SHAKE(\mathtt{0x5F} \| \seedSE,$ $2n\nbar \cdot \lengthchi)$
    \STATE Sample error matrix $\bfS^\text{T} \gets \Frodo.\SampV((\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(n\nbar-1)}), \nbar, n, T_\chi)$
    \STATE Sample error matrix $\bfE \gets \Frodo.\SampV((\bfr^{(n\nbar)}, \bfr^{(n\nbar+1)}, \dots, \bfr^{(2n\nbar-1)}), n, \nbar, T_\chi)$
    \STATE Compute $\bfB = \bfA\bfS + \bfE$
    \RETURN public key $\pk \gets (\seedA, \bfB)$ and secret key $\sk \gets \bfS^\text{T}$
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{\label{alg:PKE:Enc} $\FrodoPKE.\Enc$.}
{\bf Input:} Message $\mu \in \calM$ and public key $\pk = (\seedA, \bfB) \in \{0,1\}^\lengthseedA \times \bbZ_q^{n \times \nbar}$.\\
{\bf Output:} Ciphertext $c = (\bfC_1, \bfC_2) \in \bbZ_q^{\mbar\times n}\times \bbZ_q^{\mbar\times\nbar}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE Generate $\bfA\gets \Frodo.\gen(\seedA)$
    \STATE Choose a uniformly random seed $\seedSE \getsr U(\{0,1\}^\lengthseedSE)$
     \STATE Generate pseudorandom bit string $ (\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(2\mbar n+\mbar\nbar-1)}) \gets \SHAKE(\mathtt{0x96} \|$ $\seedSE, (2\mbar n+\mbar\nbar) \cdot \lengthchi)$
    \STATE Sample error matrix $\bfS' \gets \Frodo.\SampV((\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(\mbar n-1)}), \mbar, n, T_\chi)$
    \STATE Sample error matrix $\bfE' \gets \Frodo.\SampV((\bfr^{(\mbar n)}, \bfr^{(\mbar n+1)}, \dots, \bfr^{(2\mbar n-1)}), \mbar, n,$ $T_\chi)$
    \STATE Sample error matrix $\bfE'' \gets \Frodo.\SampV((\bfr^{(2\mbar n)}, \bfr^{(2\mbar n+1)}, \dots, \bfr^{(2\mbar n+\mbar\nbar-1)}),$ $\mbar, \nbar, T_\chi)$
    \STATE Compute $\bfB' = \bfS'\bfA + \bfE'$ and $\bfV = \bfS'\bfB + \bfE''$
    \RETURN ciphertext $c \gets (\bfC_1, \bfC_2)=(\bfB', \bfV + \Frodo.\Encode(\mu))$
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
\caption{\label{alg:PKE:Dec} $\FrodoPKE.\Dec$.}
{\bf Input:} Ciphertext $c=(\bfC_1, \bfC_2)  \in \bbZ_q^{\mbar\times n}\times \bbZ_q^{\mbar\times\nbar}$ and secret key $\sk = \bfS^\text{T} \in \mathbb{Z}_q^{\nbar \times n}$.\\
{\bf Output:} Decrypted message $\mu' \in \calM$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE Compute $\bfM = \bfC_2 - \bfC_1\bfS$
    \RETURN message $\mu' \gets \Frodo.\Decode(\bfM)$
    \end{algorithmic}
\end{algorithm}    

\subsection{Correctness of \INDCPA PKE}\label{sec:cpa-pke-correctness}

The next lemma states bounds on the size of errors that can be handled
by the decoding algorithm.

\begin{lemma}\label{lem:CorrectnessDec}
  Let $q = 2^D$, $B \leq D$. Then $\decode(\encode(k)+e) = k$ for any
  $k,e\in \bbZ$ such that $0\leq k <2^B$ and
  $-q/2^{B+1} \leq e < q/2^{B+1}$.
\end{lemma}

\begin{proof}
  This follows directly from the fact that
  $\decode(\encode(k)+e) = \lfloor k + e2^B/q \rceil \bmod 2^B$.
\end{proof}

\paragraph{Correctness of decryption:}
The decryption algorithm $\FrodoPKE.\Dec$ computes 
\begin{align*}
\bfM 
&= \bfC_2 - \bfC_1\bfS \\
&= \bfV + \Frodo.\Encode(\mu) - (\bfS'\bfA + \bfE')\bfS \\
&= \Frodo.\Encode(\mu) + \bfS'\bfB + \bfE'' - \bfS'\bfA\bfS - \bfE'\bfS \\
&= \Frodo.\Encode(\mu) + \bfS'\bfA\bfS + \bfS'\bfE +  \bfE'' - \bfS'\bfA\bfS - \bfE'\bfS \\
&= \Frodo.\Encode(\mu) + \bfS'\bfE + \bfE''- \bfE'\bfS \\
&= \Frodo.\Encode(\mu) + \bfE'''
\end{align*}
for some error matrix $\bfE''' = \bfS' \bfE + \bfE'' - \bfE'
\bfS$. Therefore, any $B$-bit substring of the message $\mu$
corresponding to an entry of $\bfM$ will be decrypted correctly if the
condition in \autoref{lem:CorrectnessDec} is satisfied for the
corresponding entry of $\bfE'''$.

\paragraph{Failure probability.}

Each entry in the matrix $\bfE'''$ is the sum of~$2n$ products of two
independent samples from $\chi$, and one more independent sample from
$\chi$. Denote the distribution of this sum by $\chi'$. In the case of
a power-of-$2$ modulus $q$, the probability of decryption failure for
any single symbol is therefore the sum
\[ p = \sum_{e \notin [-q/2^{B+1},q/2^{B+1})}\chi'(e) \enspace. \]
The probability of decryption failure for the entire message can then
be obtained using the union bound.

For the distributions~$\chi$ we use, which have rather small
support~$S_{\chi}$, the distribution $\chi'$ can be efficiently
computed exactly. The probability that a product of two independent
samples from~$\chi$ equals~$e$ (modulo~$q$) is simply
\[ \sum_{(a,b)\in S_\chi\times S_\chi\; :\; a b = e \bmod q}
  \chi(a)\cdot \chi(b) \enspace. \] Similarly, the probability that
the sum of two entries assumes a certain value is given by the
standard convolution sum.  \autoref{sec:params:sets} reports the
failure probability for each of the selected parameter sets.

\subsection{Transform from \INDCPA PKE to \INDCCA KEM}\label{sec:cca-transform}

The Fujisaki--Okamoto transform \cite{C:FujOka99} constructs an
\INDCCATwo-secure public-key encryption scheme, in the classical
random oracle model, from a one-way-secure public-key encryption
scheme (assuming the distribution of ciphertexts for each plaintext is
sufficiently close to uniform).  Targhi and Unruh \cite{TCC:TarUnr16}
gave a variant of the Fujisaki--Okamoto transform and showed its
\INDCCATwo security against a quantum adversary in the quantum random
oracle model under similar assumptions.  The results of both FO and TU
proceed under the assumption that the public-key encryption scheme has
perfect correctness, which is often not the case for lattice-based
schemes (including ours).  Hofheinz, H{\" o}velmanns, and Kiltz
(HHK)~\cite{TCC:HofHovKil17} gave a variety of constructions in a
modular fashion.  We apply their $\FOnotperp$ (``FO with implicit
rejection'') transform, which constructs an \INDCCA-secure key
encapsulation mechanism from an \INDCPA public-key encryption scheme
and three hash functions; following~\cite{EuroSP:Kyber}, we make the
following modifications (see \autoref{fig:kem-qfo} for notation),
denoting the resulting transform $\FOnotperpprime$:
\begin{itemize}
\item A single hash function (with longer output) is used to compute $\bfr$ and $\bfk$.
\item The computation of $\bfr$ and $\bfk$ also takes the public key $\pk$ as input.
\item The computation of the shared secret $\ssk$ also takes the encapsulation $c$ as input.
\end{itemize}

\begin{definition}[$\FOnotperpprime$ transform]
  \label{def:qfo}
  Let $\PKE=(\KeyGen,\Enc,\Dec)$ be a public-key encryption scheme
  with message space $\MsgSp$ and ciphertext space $\CtxtSp$, where
  the randomness space of $\Enc$ is $\RandSp$.  Let
  $\lengths, \lengthK, \lengthpkhash, \lengthss$ be parameters.  Let
  $G_1\colon \{0,1\}^* \to \{0,1\}^\lengthpkhash$,
  $G_2\colon \{0,1\}^* \to \RandSp \times \{0,1\}^\lengthK$, and
  $F\colon \{0,1\}^* \to \{0,1\}^\lengthss$ be hash functions.  Define
  $\KEMnotperpprime = \FOnotperpprime[\PKE,G_1,G_2,F]$ to be the key
  encapsulation mechanism as shown in \autoref{fig:kem-qfo}.
\end{definition}

As observed by Guo, Johansson, and Nilsson \cite{C:GuoJohNil20}, a timing side-channel enables key recovery if step 5 of $\KEMnotperpprime.\Decaps$ is not performed in constant time.

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.4\textwidth}
\underline{$\KEMnotperpprime.\KeyGen()$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $(\pk, \sk) \getsr \PKE.\KeyGen()$
\STATE $\bfs \getsr \{0,1\}^\lengths$
\STATE $\pkh \gets G_1(\pk)$
\STATE $\sk' \gets (\sk, \bfs, \pk, \pkh)$
\RETURN $(\pk, \sk')$
\end{algorithmic}

\medskip

\underline{$\KEMnotperpprime.\Encaps(\pk)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu \getsr \MsgSp$, {\color{red} $\salt \getsr \{0,1\}^{\lengthsalt}$}
\STATE $(\bfr, \bfk) \gets G_2(G_1(\pk) \| \mu {\color{red} \| \salt})$
\STATE $c \gets \PKE.\Enc(\mu, \pk; \bfr)$
\STATE $\ssk \gets F(c {\color{red} \| \salt} \| \bfk)$
\RETURN $(c {\color{red} \| \salt}, \ssk)$
\end{algorithmic}
\end{minipage}
~
\begin{minipage}[t]{0.5\textwidth}
\underline{$\KEMnotperpprime.\Decaps(c {\color{red} \| \salt}, (\sk, \bfs, \pk, \pkh))$:}
%\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu' \gets \PKE.\Dec(c, \sk)$
\STATE $(\bfr', \bfk') \gets G_2(\pkh \| \mu' {\color{red} \| \salt})$
\STATE $\ssk_0' \gets F(c {\color{red} \| \salt} \| \bfk')$
\STATE $\ssk_1' \gets F(c {\color{red} \| \salt} \| \bfs)$
\STATE (in constant time) $\ssk' \gets \ssk_0'$ if $c = \PKE.\Enc(\mu', \pk; \bfr')$ else $\ssk' \gets \ssk_1'$
\RETURN $\ssk'$
\end{algorithmic}
\end{minipage}
}
\caption{Construction of an \INDCCA-secure key encapsulation mechanism
  $\KEMnotperpprime=\FOnotperpprime[\PKE,G_1,G_2,F]$ from a public-key
  encryption scheme $\PKE$ and hash functions $G_1$, $G_2$, and $F$.}
\label{fig:kem-qfo}
\end{figure}

\section{$\FrodoKEM$: \INDCCA-secure key encapsulation mechanism}\label{sec:cca-kem}

This section describes $\FrodoKEM$, a key encapsulation mechanism that is derived from $\FrodoPKE$ by applying the $\FOnotperpprime$ transform.  $\FrodoKEM$ is parameterized by the following parameters:
\begin{itemize}
\item $q=2^D$, a power-of-two integer modulus with exponent $D \leq 16$;
\item $n, \mbar, \nbar$, integer matrix dimensions with $n \equiv 0 \pmod {16}$;
\item $B \le D$, the number of bits encoded in each matrix entry;
\item $\ell=B\cdot \mbar\cdot\nbar$, the length of bit strings to be encoded in an $\mbar$-by-$\nbar$ matrix;
\item $\lengthm = \ell$, the bit length of messages;
\item $\MsgSp = \{0,1\}^\lengthm$, the message space;
\item $\lengthseedA$, the bit length of seeds used for pseudorandom matrix generation;
\item $\lengthseedSE$, the bit length of seeds used for pseudorandom bit generation for error sampling;
\item $\Frodo.\gen$, pseudorandom matrix generation algorithm, either \autoref{alg:genA_AES} or \autoref{alg:genA_SHAKE};
\item $T_\chi$, distribution table for sampling;
\item $\lengths$, the length of the bit vector $\bfs$ used for pseudorandom shared secret generation in the event of decapsulation failure in the $\FOnotperpprime$ transform;
\item $\lengthz$, the bit length of seeds used for pseudorandom generation of $\seedA$;
\item {\color{red}$\lengthsalt$, the bit length of $\salt$;}
\item $\lengthK$, the bit length of intermediate shared secret $\bfk$ in the $\FOnotperpprime$ transform;
\item $\lengthpkhash$, the bit length of the hash $G_1(\pk)$ of the public key in the $\FOnotperpprime$ transform;
\item $\lengthss$, the bit length of shared secret $\ssk$ in the $\FOnotperpprime$ transform;
\end{itemize}

\begin{algorithm}[H]
\caption{\label{alg:KEM:KeyGen} $\FrodoKEM.\KeyGen$.}
{\bf Input:} None.\\
{\bf Output:} Key pair $(\pk, \sk')$ with $\pk \in \{0,1\}^{\lengthseedA + D\cdot n \cdot \nbar}$, $\sk' \in \{0,1\}^{\lengths + \lengthseedA + D\cdot n \cdot \nbar}\times \bbZ_q^{\nbar\times n} \times \{0,1\}^{\lengthpkhash}$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE Choose uniformly random seeds $\bfs \| \seedSE\| \bfz \getsr U(\{0,1\}^{\lengths + \lengthseedSE + \lengthz})$
    \STATE Generate pseudorandom seed $\seedA \gets \SHAKE(\bfz, \lengthseedA)$
    \STATE Generate the matrix $\bfA \in \bbZ_q^{n \times n}$ via $\bfA\gets\Frodo.\gen(\seedA)$
    \STATE Generate pseudorandom bit string $ (\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(2n\nbar-1)}) \gets \SHAKE(\mathtt{0x5F} \| \seedSE,$ $2n\nbar \cdot \lengthchi)$
    \STATE Sample error matrix $\bfS^\text{T} \gets \Frodo.\SampV((\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(n\nbar-1)}), \nbar, n, T_\chi)$
    \STATE Sample error matrix $\bfE \gets \Frodo.\SampV((\bfr^{(n\nbar)}, \bfr^{(n\nbar+1)}, \dots, \bfr^{(2n\nbar-1)}), n, \nbar, T_\chi)$
    \STATE Compute $\bfB \gets \bfA\bfS + \bfE$
    \STATE Compute $\bfb \gets \Frodo.\Pack(\bfB)$
    \STATE Compute $\pkh \gets \SHAKE(\seedA\| \bfb, \lengthpkhash)$
    \RETURN public key $\pk \gets \seedA\| \bfb$ and secret key $\sk' \gets (\bfs \| \seedA \| \bfb, \bfS^\text{T}, \pkh)$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{\label{alg:KEM:Encaps} $\FrodoKEM.\Encaps$.}
{\bf Input:} Public key $\pk = \seedA\| \bfb \in \{0,1\}^{\lengthseedA + D\cdot n \cdot \nbar}$.\\
{\bf Output:} Ciphertext $\bfc_1\| \bfc_2{\color{red}\| \salt}\in \{0,1\}^{(\mbar\cdot n +\mbar\cdot\nbar)D{\color{red}+\lengthsalt}}$ and shared secret $\ssk \in \{0,1\}^\lengthss$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE Choose uniformly random values $\mu \getsr U(\{0,1\}^\lengthm)$ {\color{red}and $\salt \getsr U(\{0,1\}^\lengthsalt$)}
    \STATE Compute $\pkh \gets \SHAKE(\pk, \lengthpkhash)$
    \STATE Generate pseudorandom values $\seedSE\| \bfk \gets \SHAKE(\pkh \| \mu{\color{red}\| \salt}, \lengthseedSE + \lengthK)$
    \STATE Generate pseudorandom bit string $ (\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(2\mbar n+\mbar\nbar-1)}) \gets \SHAKE(\mathtt{0x96} \|$ $\seedSE, (2\mbar n+\mbar\nbar) \cdot \lengthchi)$
    \STATE Sample error matrix $\bfS' \gets \Frodo.\SampV((\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(\mbar n-1)}), \mbar, n, T_\chi)$
    \STATE Sample error matrix $\bfE' \gets \Frodo.\SampV((\bfr^{(\mbar n)}, \bfr^{(\mbar n+1)}, \dots, \bfr^{(2\mbar n-1)}), \mbar, n,$ $T_\chi)$
    \STATE Generate $\bfA\gets \Frodo.\gen(\seedA)$
    \STATE Compute $\bfB' \gets \bfS'\bfA + \bfE'$
    \STATE Compute $\bfc_1 \gets \Frodo.\Pack(\bfB')$
    \STATE Sample error matrix $\bfE'' \gets \Frodo.\SampV((\bfr^{(2\mbar n)}, \bfr^{(2\mbar n+1)}, \dots, \bfr^{(2\mbar n+\mbar\nbar-1)}),$ $\mbar, \nbar, T_\chi)$
    \STATE Compute $\bfB \gets \Frodo.\Unpack(\bfb,n,\nbar)$
    \STATE Compute $\bfV \gets \bfS'\bfB + \bfE''$
    \STATE Compute $\bfC \gets \bfV + \Frodo.\Encode(\mu)$
    \STATE Compute $\bfc_2 \gets \Frodo.\Pack(\bfC)$
    \STATE Compute $\ssk \gets \SHAKE(\bfc_1 \| \bfc_2{\color{red}\| \salt} \| \bfk, \lengthss)$
    \RETURN ciphertext $\bfc_1 \| \bfc_2{\color{red}\| \salt}$ and shared secret $\ssk$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{\label{alg:KEM:Decaps} $\FrodoKEM.\Decaps$.}
{\bf Input:} Ciphertext $\bfc_1 \| \bfc_2{\color{red}\| \salt} \in \{0,1\}^{(\mbar\cdot n +\mbar\cdot\nbar)D {\color{red}+\lengthsalt}}$, secret key $\sk' = (\bfs \| \seedA \| \bfb, \bfS^\text{T}, \pkh) \in  \{0,1\}^{\lengths + \lengthseedA +D\cdot n \cdot \nbar}\times \bbZ_q^{\nbar\times n} \times \{0,1\}^{\lengthpkhash}$.\\
{\bf Output:} Shared secret $\ssk \in \{0,1\}^\lengthss$.\\[-1.5ex]
\rule{\linewidth}{.5pt}
\vspace{-0.5cm}
\begin{algorithmic}[1]
    \STATE $\bfB' \gets \Frodo.\Unpack(\bfc_1, \mbar, n)$
    \STATE $\bfC \gets \Frodo.\Unpack(\bfc_2, \mbar, \nbar)$    
    \STATE Compute $\bfM \gets \bfC - \bfB'\bfS$
    \STATE Compute $\mu' \gets \Frodo.\Decode(\bfM)$
    \STATE Parse $\pk \gets \seedA \|\bfb$
    \STATE Generate pseudorandom values $\seedSE'\| \bfk' \gets \SHAKE(\pkh \| \mu'{\color{red}\| \salt}, \lengthseedSE + \lengthK)$
   \STATE Generate pseudorandom bit string $ (\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(2\mbar n+\mbar\nbar-1)}) \gets \SHAKE(\mathtt{0x96} \|$ $\seedSE', (2\mbar n+\mbar\nbar) \cdot \lengthchi)$
    \STATE Sample error matrix $\bfS' \gets \Frodo.\SampV((\bfr^{(0)}, \bfr^{(1)}, \dots, \bfr^{(\mbar n-1)}), \mbar, n, T_\chi)$
    \STATE Sample error matrix $\bfE' \gets \Frodo.\SampV((\bfr^{(\mbar n)}, \bfr^{(\mbar n+1)}, \dots, \bfr^{(2\mbar n-1)}), \mbar, n,$ $T_\chi)$
    \STATE Generate $\bfA\gets \Frodo.\gen(\seedA)$
    \STATE Compute $\bfB'' \gets \bfS'\bfA + \bfE'$
    \STATE Sample error matrix $\bfE'' \gets \Frodo.\SampV((\bfr^{(2\mbar n)}, \bfr^{(2\mbar n+1)}, \dots, \bfr^{(2\mbar n+\mbar\nbar-1)}),$ $\mbar, \nbar, T_\chi)$
    \STATE Compute $\bfB \gets \Frodo.\Unpack(\bfb,n,\nbar)$
    \STATE Compute $\bfV \gets \bfS'\bfB + \bfE''$
    \STATE Compute $\bfC' \gets \bfV + \Frodo.\Encode(\mu')$
    \STATE (in constant time) $\overline{\bfk} \gets \bfk'$ if $(\bfB' \| \bfC = \bfB'' \| \bfC')$ else $\overline{\bfk} \gets \bfs$
    \STATE Compute $\ssk \gets \SHAKE(\bfc_1 \| \bfc_2{\color{red}\| \salt} \| \overline{\bfk}, \lengthss)$
    \RETURN shared secret $\ssk$
    \end{algorithmic}
\end{algorithm}   

\subsection{Correctness of \INDCCA KEM}\label{sec:cca-kem-correctness}

The failure probability $\delta$ of $\FrodoKEM$ is the same as the failure probability of the underlying $\FrodoPKE$ as computed in \autoref{sec:cpa-pke-correctness}.

\subsection{Interconversion to \INDCCA PKE}\label{sec:cca-pke}

\NISTdescription{As the KEM and public-key encryption functionalities can generally be interconverted, unless the submitter specifies otherwise, NIST will apply standard conversion techniques to convert between schemes if necessary.}

$\FrodoKEM$ can be converted to an \INDCCA-secure public-key encryption scheme using standard conversion techniques as specified by NIST.  In particular, shared secret $\ssk$ can be used as the encryption key in an appropriate data encapsulation mechanism in the KEM/DEM (key encapsulation mechanism / data encapsulation mechanism) framework \cite{CraSho03}.

\subsection{Cryptographic primitives}\label{sec:primitives}

\NISTdescription{A complete submission shall specify any padding mechanisms and any uses of NIST-approved cryptographic primitives that are needed in order to achieve security. If the scheme uses a cryptographic primitive that has not been approved by NIST, the submitter shall provide an explanation for why a NIST-approved primitive would not be suitable.}

In $\FrodoKEM$ we use the following generic cryptographic primitives. We
describe their security requirements and instantiations with NIST-approved
cryptographic primitives. In what follows, we use
$\SHAKE128/256$ to denote the use of either $\SHAKE128$ or $\SHAKE256$;
which one is used with which parameter set for $\FrodoKEM$ is indicated in \autoref{tab:parameters-all}.

\begin{itemize}

\item $\Frodo.\gen$ in $\FrodoKEM.\KeyGen$: The security requirement on
  $\Frodo.\gen$ is that it is a public function that generates pseudorandom
  matrices $\bfA$. $\Frodo.\gen$ is instantiated using either \AESOneTwoEight
  (as in \autoref{alg:genA_AES}) or $\SHAKE128$ (as in
  \autoref{alg:genA_SHAKE}).

\item $G_1$, $G_2$, and $F$ in transform $\FOnotperpprime$: these are
  modeled as independent random oracles.  We instantiate these using
  $\SHAKE128/256$; see below for an explanation of domain separation
  to achieve independence.
\end{itemize}

Overall, $\FrodoKEM$ has the following uses of $\SHAKE$:

\begin{enumerate}
\item $\Frodo.\gen$	using $\SHAKE128$, line 3: $\SHAKE128(\bfb, \dots)$, input $16+\lengthseedA$ bits
\item $\FrodoKEM.\KeyGen$, line 2: $\SHAKE(\bfz, \dots)$, input $\lengthz$ bits
\item $\FrodoKEM.\KeyGen$, line 4: $\SHAKE(\mathtt{0x5F}\|\seedSE, \dots)$, input $8+\lengthseedSE$ bits
\item $\FrodoKEM.\KeyGen$, line 9: $\SHAKE(\seedA \| \bfb, \dots)$, input $\lengthseedA+D\cdot n \cdot \nbar$ bits
\item $\FrodoKEM.\Encaps$, line 2: same as $\FrodoKEM.\KeyGen$, line 9
\item $\FrodoKEM.\Encaps$, line 3: $\SHAKE(\pkh\|\mu{\color{red}\|\salt}, \dots)$, input length $\lengthpkhash+\lengthm{\color{red}+\lengthsalt}$ bits
\item $\FrodoKEM.\Encaps$, line 4: $\SHAKE(\mathtt{0x96}\|\seedSE, \dots)$, input length $8+\lengthseedSE$ bits
\item $\FrodoKEM.\Encaps$, line 15: $\SHAKE(\bfc_1\|\bfc_2{\color{red}\|\salt}\|\bfk, \dots)$, input length $(\mbar\cdot n+\mbar\cdot\nbar)D {\color{red}+\lengthsalt} + \lengthK$ bits
\item $\FrodoKEM.\Decaps$, line 6: same as $\FrodoKEM.\Encaps$, line 3
\item $\FrodoKEM.\Decaps$, line 7: same as $\FrodoKEM.\Encaps$, line 4
\item $\FrodoKEM.\Decaps$, line 17: same as $\FrodoKEM.\Encaps$, line 15
\end{enumerate}

\paragraph{Domain separation.}
Each distinct use of $\SHAKE$ in the list above should be cryptographically independent, which is achieved via one of two forms of domain separation.  

$\SHAKE$, and the underlying Keccak operation, employ padding to pad input strings to a multiple of the rate.  The specific padding used is appending the string $\mathtt{10^*1}$.  Thus, inputs of different lengths yield different padded strings.  

For uses of $\SHAKE$ where the inputs are of different lengths (entries 1, 2, 4, 6, and 8 in the list above), we rely on Keccak's padding for domain separation.

For uses of $\SHAKE$ where the inputs are of the same length (entries 3 and 7 in the list above), we prepend distinct bytes as domain separators.  These domain separators have bit patterns ($\mathtt{0x5F}=\mathtt{01011111}, \mathtt{0x96}=\mathtt{10010110}$) that were chosen to make it hard to use individual or consecutive bit flipping attacks to turn one into the other.

\section{Parameters}\label{sec:params}

\ifshoworiginal
This section outlines our methodology for choosing tunable parameters of the proposed algorithms. 

\subsection{High-level overview}

Recall the main $\FrodoPKE$ parameters defined in
\autoref{sec:algs}:
\begin{itemize}
  \item $\chi$, a probability distribution on $\bbZ$;
  \item $q=2^D$, a power-of-two integer modulus with exponent $D \leq 16$;
  \item $n,\mbar,\nbar$, integer matrix dimensions with $n \equiv 0 \pmod 8$;
  \item $B\leq D$, the number of bits encoded in each matrix entry;
  \item $\ell=B\cdot \mbar\cdot\nbar$ the length of bit strings to be encoded in an $\mbar$-by-$\nbar$ matrix.
\end{itemize}

The task of parameter selection is framed as a combinatorial
optimization problem, where the objective function is the ciphertext's
size, and the constraints are dictated by the target security level,
probability of decryption failure, and computational efficiency. The
optimization problem is solved by sweeping the parameter space,
subject to simple pruning techniques.  We perform this sweep of the
parameter space using the Python scripts that accompany the
submission, in the folder
\texttt{Additional\_Implementations/Parameter\_Search\_Scripts}.

\else

Recall the main \FrodoPKE parameters defined in \autoref{sec:algs}.
The task of parameter selection is framed as a combinatorial
optimization problem, where the objective function is the ciphertext's
size, and the constraints are dictated by the target security level,
probability of decryption failure, and computational efficiency. The
optimization problem is solved by sweeping the parameter space,
subject to simple pruning techniques.  We perform this sweep of the
parameter space using the Python scripts that accompany the
submission: \patrick{LINK TO BE ADDED}.
\fi

\subsection{Parameter constraints}\label{sec:constraints}

Implementation considerations limit $q$ to be at most $2^{16}$ and $n$
to be a multiple of 16. Our cost function is the sum of the bit lengths of
$\FrodoPKE$'s ciphertext and its public key, which is $D\cdot (n\cdot (\mbar\ + \nbar)+\mbar\ \nbar)+\lengthseedA$.

The standard deviation~$\sigma$ of the Gaussian error distribution is
taken to exceed the ``smoothing parameter'' of the
integers~$\mathbb{Z}$, for a very small error parameter $\eps >
0$. The specific values of~$\sigma$ are chosen following the
methodology in \autoref{sec:strength:lattice}, which demonstrates that
our choices conform to a nontrivial reduction from the worst-case
\BDDwDGS problem to the corresponding average-case LWE decision
problem.

The complexity of the error-sampling algorithm
(\autoref{sec:sampling}) depends on the support of the distribution
and the number of uniformly random bits per sample. We bound the
number of bits per sample by 16. Since the distribution is symmetric,
the sample's sign ($\bfr_0$ in \autoref{alg:samplechi}) can be chosen
independently from its magnitude~$e$, which leaves 15 bits for
sampling from the non-negative part of the support. For each setting
of the variance $\sigma^2$ we find a discrete distribution subject to
the above constraints that minimizes its \renyi divergence (for
several integral orders) from the target ``ideal'' distribution, which
is the rounded Gaussian~$\Psi_{\sigma \sqrt{2\pi}}$.

We estimate the concrete security of parameters for our scheme based
on cryptanalytic attacks (\autoref{sec:attack:cryptanalytic}),
accounting for the loss due to substitution of a rounded Gaussian with
its discrete approximation (\autoref{sec:renyi_loss}).  The
probability of decryption failure is computed according to the
procedure outlined in \autoref{sec:cpa-pke}.

In case of ties, i.e., when different parameter sets result in
identical ciphertext sizes (i.e., the same $q$ and~$n$), we chose the
smaller~$\sigma$ for \FrodoKEMLOne and \FrodoKEMLFive (minimizing the probability of
decryption failure), and the larger~$\sigma$ for \FrodoKEMLThree
(prioritizing security).

\subsection{Selected parameter sets}\label{sec:params:sets}

We present three core parameter sets for \FrodoKEM:
\begin{itemize}
\item \FrodoLOne, matching or exceeding the brute-force security of AES-128,
\item \FrodoLThree, matching or exceeding the brute-force security of AES-192, and
\item \FrodoLFive, matching or exceeding the brute-force security of AES-256,
\end{itemize}
\noindent which target Levels 1, 3 and 5, respectively,
in the NIST call for proposals~\cite{}.

We parameterize each core set by the PRG that is used for the generation
of matrix $\bfA$. 
As described in~\autoref{sec:genA}, \FrodoKEM allows two options for the PRG:
AES128 and SHAKE128. 
In addition, \FrodoKEM consists of two main variants: a ``standard'' variant
(simply called \FrodoKEM) that does not impose any restriction on the reuse of key pairs,
and an ``ephemeral'' variant (referred to as \eFrodoKEM) that is intended for applications
in which the number of ciphertexts produced relative to any single public key is small.
More specifically, to address certain multi-ciphertext attacks, \eFrodoKEM doubles
the length of the $\seedSE$ value, and incorporates a public random salt value into encapsulation.

Thus, in total, we propose twelve parameter sets. The variant \FrodoKEM includes the
parameter sets \FrodoKEMLOneAES, \FrodoKEMLThreeAES, \FrodoKEMLFiveAES,
\FrodoKEMLOneSHAKE, \FrodoKEMLThreeSHAKE and \FrodoKEMLFiveSHAKE, and the variant \eFrodoKEM
includes the parameter sets \eFrodoKEMLOneAES, \eFrodoKEMLThreeAES, \eFrodoKEMLFiveAES,
\eFrodoKEMLOneSHAKE, \eFrodoKEMLThreeSHAKE and \eFrodoKEMLFiveSHAKE.

\autoref{tab:parameters-all} and \autoref{tab:parameters-additional} summarize
the cryptographic parameters for all the parameter sets.
The corresponding error distributions appear in \autoref{tab:distribution}.
\autoref{tab:security} summarizes security claims we can make about \FrodoKEM
and its components. The columns LWE security C, Q and P respectively denote
security, in bits, for classical, quantum, and plausible attacks on $\mbar+\nbar$
instances of the normal-form (decisional) LWE problem with Gaussian error
distribution (\autoref{sec:lwe}) as estimated by the methodology of
\autoref{sec:attack:cryptanalytic}. The column IND-CCA security C denotes IND-CCA
security, in bits, for classical random oracle model attacks according to
\autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}.

\begin{table}[h]
\caption{Cryptographic parameters for $\FrodoKEMLOne$, $\FrodoKEMLThree$, $\FrodoKEMLFive$, and
their corresponding ephemeral variants.
For each set, $\lengthm = \lengths = \lengthK = \lengthpkhash = \lengthss = \ell$.}\label{tab:parameters-all}
\begin{center}
\begin{tabular}{l|r|r|r }
\toprule
& $(\styleScheme{e})\FrodoKEMLOne$ & $(\styleScheme{e})\FrodoKEMLThree$ & $(\styleScheme{e})\FrodoKEMLFive$ \\
\midrule
$D$ & $15$ & $16$ & $16$ \\
$q$ & $32768$ & $65536$ & $65536$ \\
$n$ & $640$ & $976$ & $1344$ \\
$\mbar=\nbar$ & $8$ & $8$ & $8$ \\
$B$ & $2$ & $3$ & $4$ \\
$\lengthseedA$ & $128$ & $128$ & $128$ \\
$\lengthz$ & $128$ & $128$ & $128$ \\
$\ell$ & $128$ & $192$ & $256$ \\
$\lengthchi$ & $16$ & $16$ & $16$ \\
$\chi$ & $\chi_\FrodoLOne$ & $\chi_\FrodoLThree$ & $\chi_\FrodoLFive$ \\
$\SHAKE$ & $\SHAKE128$ & $\SHAKE256$ & $\SHAKE256$ \\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{table}[h]
\caption{Size (in bits) of $\lengthseedSE$ and $\lengthsalt$.}\label{tab:parameters-additional}
\begin{center}
\begin{tabular}{l|r|r|r }
\toprule
& $\FrodoKEMLOne$ & $\FrodoKEMLThree$ & $\FrodoKEMLFive$ \\
\midrule
$\lengthseedSE$ & $256$ & $384$ & $512$ \\
$\lengthsalt$ & $256$ & $384$ & $512$ \\
\toprule
& $\eFrodoKEMLOne$ & $\eFrodoKEMLThree$ & $\eFrodoKEMLFive$ \\
\midrule
$\lengthseedSE$ & $128$ & $192$ & $256$ \\
$\lengthsalt$ & $0$ & $0$ & $0$ \\
\bottomrule
\end{tabular}
\end{center}
\end{table}


\ifshoworiginal
The procedures outlined in this section can be adapted to support
alternative cost functions and constraints. For instance, an objective
function that takes into account computational costs or penalizes the
public key size would lead to a different set of outcomes. For
example, constraints can be also chosen to guarantee error-free
decryption, or to select parameters that allow for a bounded number of
homomorphic operations.

The three parameter sets are given in \autoref{tab:parameters}.  The
corresponding error distributions appear in
\autoref{tab:distribution}. \autoref{tab:security} summarizes security claims we can make about \FrodoKEM and its components. The columns LWE security C, Q and P respectively
denote security, in bits, for classical, quantum, and plausible attacks on $\mbar+\nbar$ instances of the normal-form (decisional) LWE problem with Gaussian error distribution (\autoref{sec:lwe}) as estimated by the methodology of \autoref{sec:attack:cryptanalytic}. The column IND-CCA security C denotes IND-CCA security, in bits, for classical random oracle model attacks according to \autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}.

\begin{table}[h]
	\caption{\textbf{Parameters at a glance}}\label{tab:parameters}
	\begin{center}
		\begin{tabular}{l | c c c c c c c}
			\toprule
			& $n$ & $q$& $\sigma$ & \textbf{support} & $B$ & $\bar{m}\times \bar{n}$ & $c$ \textbf{size} \\
			& & & & \textbf{of} $\chi$ & & & \textbf{(bytes)}\\
			\midrule
			\FrodoLOne & \!\! 640 \!\! & \!\! $2^{15}$ \!\! &2.8 &$[-12\dots 12]$ &\!\!2\!\! & $8\times 8$ & \hphantom{0}9,720 \\
			\FrodoLThree & \!\! 976 \!\! & \!\! $2^{16}$ \!\! &2.3 &$[-10\dots 10]$ &\!\!3\!\! & $8\times 8$ & 15,744 \\
			\FrodoLFive & \!\! 1344 \!\! & \!\! $2^{16}$ \!\! &1.4 &$[-6\dots 6]$ &\!\!4\!\! & $8\times 8$ & 21,632 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}
\fi

\begin{table}[h]
\caption{Error distributions.}\label{tab:distribution}
\begin{center}
\scalebox{0.78}{
\begin{tabular}{l|c| r r r r r r r r r r r r r|c c}
\toprule
 & $\sigma$ & \multicolumn{13}{c|}{\textbf{Probability of (in multiples of $2^{-16}$)}} & \multicolumn{2}{c}{\textbf{\renyi}} \\
             & & 0 &\!\!$\pm 1$\!\!&\!\!$\pm 2$\!\!&\!\!$\pm 3$\!\!&\!\!$\pm 4$\!\!&\!\!$\pm 5$&\!\!$\pm 6$\!\!&\!\!$\pm 7$\!\!&\!\!$\pm 8$\!\!&\!\!$\pm 9$\!\!&\!\!$\pm 10$\!\!&\!\!$\pm 11$\!\!&\!\!$\pm 12$\!\!& \textbf{order} & \textbf{divergence} 
\\ \midrule
$\chi_\FrodoLOne$ & 2.8 &\!\!9288\!\!&\!\!8720\!\!&\!\!7216\!\!&\!\!5264\!\!&\!\!3384\!\!&\!\!1918\!\!&\!\!958\!\!&\!\!422\!\!&\!\!164\!\!&\!\!56\!\!&\!\!17\!\!&\!\!4\!\!&\!\!1\!\!& 200 & $0.324\times 10^{-4}$ \\
$\chi_\FrodoLThree$ & 2.3 &\!\!11278\!\!&\!\!10277\!\!&\!\!7774\!\!&\!\!4882\!\!&\!\!2545\!\!&\!\!1101\!\!&\!\!396\!\!&\!\!118\!\!&\!\!29\!\!&\!\!6\!\!&\!\!1\!\!&&& 500 & $0.140\times 10^{-4}$ \\
$\chi_\FrodoLFive$ & 1.4 &\!\!18286\!\!&\!\!14320\!\!&\!\!6876\!\!&\!\!2023\!\!&\!\!364\!\!&\!\!40\!\!&\!\!2\!\!&&&&&&& 1000 & $0.264\times 10^{-4}$ \\
\bottomrule
\end{tabular}
}
\end{center}
\end{table}

\begin{table}[h]
	\caption{Security bounds.}\label{tab:security}
	\begin{center}
		\begin{tabular}{l | c c | c  c  c | c }
			\toprule
			& \textbf{target level} & \textbf{failure rate} & \multicolumn{3}{c}{\textbf{LWE security}} & \textbf{IND-CCA security}\\
			& &  & \textbf{C} & \textbf{Q} & \textbf{P} & \textbf{C} \\
			\midrule
				\FrodoLOne & 1 & $2^{-138.7}$ & 145 & 132 & 104 & 141 \\
				\FrodoLThree & 3 & $2^{-199.6}$ & 210 & 191 & 150 & 206 \\
				\FrodoLFive & 5 & $2^{-252.5}$ & 275 & 250 & 197 & 268 \\		
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}


\ifshoworiginal
\subsection{Summary of parameters}

\autoref{tab:parameters-all} summarizes all cryptographic parameters for $\FrodoLOne$, $\FrodoLThree$ and $\FrodoLFive$.  $\FrodoKEMLOneAES$, $\FrodoKEMLThreeAES$ and $\FrodoKEMLFiveAES$ use $\AESOneTwoEight$ for generation of $\bfA$; $\FrodoKEMLOneSHAKE$, $\FrodoKEMLThreeSHAKE$ and $\FrodoKEMLFiveSHAKE$ 
use $\SHAKE$ for generation of $\bfA$.

\begin{table}[h]
\caption{\textbf{Cryptographic parameters for $\FrodoLOne$, $\FrodoLThree$, and $\FrodoLFive$}}\label{tab:parameters-all}
\begin{center}
\begin{tabular}{l|r|r|r }
\toprule
& $\FrodoLOne$ & $\FrodoLThree$ & $\FrodoLFive$ \\
\midrule
$D$ & $15$ & $16$ & $16$ \\
$q$ & $32768$ & $65536$ & $65536$ \\
$n$ & $640$ & $976$ & $1344$ \\
$\mbar=\nbar$ & $8$ & $8$ & $8$ \\
$B$ & $2$ & $3$ & $4$ \\
$\lengthseedA$ & $128$ & $128$ & $128$ \\
$\lengthz$ & $128$ & $128$ & $128$ \\
$\lengthm = \ell$ & $128$ & $192$ & $256$ \\
$\lengthseedSE$ & $128$ & $192$ & $256$ \\
$\lengths$ & $128$ & $192$ & $256$ \\
$\lengthK$ & $128$ & $192$ & $256$ \\
$\lengthpkhash$ & $128$ & $192$ & $256$ \\
$\lengthss$ & $128$ & $192$ & $256$ \\
$\lengthchi$ & $16$ & $16$ & $16$ \\
$\chi$ & $\chi_\FrodoLOne$ & $\chi_\FrodoLThree$ & $\chi_\FrodoLFive$ \\
$\SHAKE$ & $\SHAKE128$ & $\SHAKE256$ & $\SHAKE256$ \\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\autoref{tab:size} summarizes the sizes, in bytes, of the different
inputs and outputs required by
$\FrodoKEM$. % and, for comparison, $\FrodoPKE$. The discrepancy between space complexity of the two schemes is due to the transform detailed in~\autoref{sec:spec:algs:cca-transform}.
Note that we also include the size of the public key in the secret key
sizes, in order to comply with NIST's API guidelines.  Specifically,
since NIST's decapsulation API does not include an input for the
public key, it needs to be included as part of the secret key.


\begin{table}[!ht]
\caption{\textbf{Size (in bytes) of inputs and outputs of $\FrodoKEM$.} 
Secret key size is the sum of the sizes of the actual secret value and of the public key (the NIST API does not include the public key as explicit input to decapsulation).} \label{tab:size}
\medskip
\centering
\renewcommand{\tabcolsep}{0.3cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c c c c}
\toprule
\multirow{2}{*}{\textbf{Scheme}} & \textbf{secret key} & \textbf{public key} & \textbf{ciphertext} & \textbf{shared secret} \\
                                 & $\sk$                & $\pk$                & $c$                 & $\ssk$                 \\
\midrule
\FrodoKEMLOne & 19,888 & \hphantom{0}9,616 & \hphantom{0}9,720 & 16 \\ 
& {\scriptsize (10,272 + 9,616)}\\
\FrodoKEMLThree & 31,296 & 15,632 & 15,744 & 24 \\ 
& {\scriptsize (15,664 + 15,632)}\\
\FrodoKEMLFive & 43,088 & 21,520 & 21,632 & 32 \\ 
&{\scriptsize (21,568 + 21,520)}\\
\bottomrule
\end{tabular}
\end{table} 

\subsection{Provenance of constants and tables}\label{sec:constants}

\NISTdescription{To help rule out the existence of possible back-doors in an algorithm, the submitter shall explain the provenance of any constants or tables used in the algorithm.}

Constants used as domain separators in calls to $\SHAKE$ are described in Section~\ref{sec:spec:primitives}.

The constants in \autoref{tab:parameters} and \autoref{tab:distribution} were generated by search scripts following the methodology described in \autoref{sec:spec:params}.
\fi

\autoref{tab:size} summarizes the sizes, in bytes, of the different
inputs and outputs required by \FrodoKEM.
Note that the secret key sizes include the size of the public key,
in order to comply with NIST's API guidelines. Specifically,
since NIST's decapsulation API does not include an input for the
public key, it needs to be included as part of the secret key.


\begin{table}[!ht]
\caption{Size (in bytes) of inputs and outputs of \FrodoKEM and \eFrodoKEM.} \label{tab:size}
\medskip
\centering
\renewcommand{\tabcolsep}{0.3cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c c c c}
\toprule
\multirow{2}{*}{\textbf{Scheme}} & \textbf{secret key} & \textbf{public key} & \textbf{ciphertext} & \textbf{shared secret} \\
                                 & $\sk$                & $\pk$                & $c$                 & $\ssk$               \\
\midrule
\FrodoKEMLOne & 19,888 & \hphantom{0}9,616 & \hphantom{0}9,752 & 16 \\
\FrodoKEMLThree & 31,296 & 15,632 & 15,792 & 24 \\ 
\FrodoKEMLFive & 43,088 & 21,520 & 21,696 & 32 \\ 
\midrule
\eFrodoKEMLOne & 19,888 & 9,616 & 9,720 & 16 \\
\eFrodoKEMLThree & 31,296 & 15,632 & 15,744 & 24 \\ 
\eFrodoKEMLFive & 43,088 & 21,520 & 21,632 & 32 \\ 
\bottomrule
\end{tabular}
\end{table} 

\section{Implementation and performance analysis}\label{sec:performance}

\ifshoworiginal
The submission package includes:
\begin{itemize}
\item a reference implementation written exclusively in Python,
\item a reference implementation written exclusively in portable C,
\item an optimized implementation written exclusively in portable C that includes efficient algorithms to generate the matrix $\bfA$ and to compute the matrix operations $\bfA \bfS + \bfE$ and $\bfS' \bfA + \bfE'$, and
\item an additional, optimized implementation for x64 platforms that exploits Advanced Vector Extensions~2 (AVX2) intrinsic instructions.
\end{itemize}

The implementations in the submission package support all three security levels and both variants of matrix generation:
$\FrodoKEMLOneAES$, $\FrodoKEMLOneSHAKE$, $\FrodoKEMLThreeAES$, $\FrodoKEMLThreeSHAKE$, $\FrodoKEMLFiveAES$, and $\FrodoKEMLFiveSHAKE$. 
The only difference between the reference and the optimized implementation is that the latter includes two efficient functions to generate the public matrix $\bfA$ and to compute the matrix operations $\bfA \bfS + \bfE$ and $\bfS' \bfA + \bfE'$. Similarly, the only difference between the optimized and the additional implementation is that the latter uses AVX2 intrinsic instructions to speed up the implementation of the aforementioned functions. 
Hence, the different implementations share most of their codebase: this illustrates the simplicity of software based on $\FrodoKEM$. 

\else

One of the features of \FrodoKEM is that it is easy to implement and naturally facilitates
writing implementations that are compact and run in constant-time.
This latter feature aids to avoid common cryptographic implementation mistakes which can lead
to key-extraction based on, for instance, timing differences when executing the code\footnote{Nonetheless,
care must be taken to avoid timing leaks. In 2020, Guo, Johansson, and Nilsson~\cite{}
demonstrated a key-recovery attack on the reference implementation in the Round 2 submission of \FrodoKEM
by exploiting branching in the computation of $\ssk$ in \FrodoKEM.\Decaps. This attack can be avoided
by ensuring the implementation reads both $\bfk'$ and $\bfs$, compares $\bfB' \| \bfC$ and $\bfB'' \| \bfC'$
in a constant-time way that avoids early termination, and sets $\overline{\bfk}$ using data-independent evaluation.}.

Our compact implementation of the \FrodoKEM scheme consists of slightly more than 250 lines of plain C code.
This same code is used for all three security levels to implement \FrodoKEMLOne, \FrodoKEMLThree, and \FrodoKEMLFive,
with parameters changed by a small number of macros at compile-time.
Moreover, most of the code is either shared or reused for our implementation of the \eFrodoKEM scheme.
We remark that the separation in two implementations, one for \FrodoKEM and one for \eFrodoKEM, is only
done to provide a simpler and cleaner codebase supporting each API. 
In particular, the API for \eFrodoKEM has been customized to perform a single key generation
per encapsulation execution.    

Computing on matrices---the basic operation in \FrodoKEM---allows for easy scaling to different dimensions $n$.
In addition, \FrodoKEM uses a modulus $q$ that is always equal or less than $2^{16}$. These two combined
aspects allow for the full reuse of the matrix functions for the different security levels by instantiating them
with the right parameters at build time. Since the modulus $q$ used is always a power of two, implementing
arithmetic modulo $q$ is simple, efficient and easy to do in constant-time in modern computer architectures:
for instance, computing modulo $2^{16}$ comes for free when using 16-bit data-types. Moreover, the dimension
values were chosen to be divisible by 16 in order to facilitate vectorization optimizations and to simplify the
use of AES128 for the generation of the matrix $\bfA$.

Also the error sampling is designed to be simple and facilitates code reuse: for any security level, \FrodoKEM
requires 16 bits per sample, and the tables $T_\chi$ corresponding to the discrete cumulative density functions
always consist of values that are less than $2^{15}$. Hence, a simple function applying inversion sampling
(see~\autoref{alg:samplechi}) can be instantiated using different precomputed tables $T_\chi$. Moreover, due to
the small sizes of these pre-computed tables constant-time table lookups, needed to protect against attacks
based on timing differences, can be implemented almost for free in terms of effort and performance impact.
\fi

All our implementations avoid the use of secret address accesses and secret branches and, hence,
are protected against timing and cache attacks.


\subsubsection{Performance analysis on x64 Intel}\label{sec:results_x64}

\ifshoworiginal
In this section, we summarize the results of our performance evaluation using a machine equipped with a 3.4GHz Intel Core i7-6700 (Skylake) processor and running Ubuntu 16.04.3 LTS. As standard practice, TurboBoost was disabled during the tests. For compilation we used GNU GCC version 7.2.0 with the command {\tt gcc -O3 -march=native}. 
The generation of the matrix $\bfA$ is the most expensive part of the computation. As described in \autoref{sec:spec:genA}, we support two ways of generating $\bfA$: one using $\AESOneTwoEight$ and one using $\SHAKE128$.


\subsubsection{Performance using AES128}\label{sec:results_aes}

\autoref{tab:results_x64_aes} details the performance of the optimized implementations and the additional x64 implementations when using $\AESOneTwoEight$ for the generation of the matrix $\bfA$. The top two sets of results correspond to performance when using OpenSSL's AES implementation\footnote{Note that in order to enable AES-NI instructions in OpenSSL, we use the \texttt{EVP\_aes\_128\_ecb} interface in OpenSSL.} and the bottom set presents the results when using a standalone AES implementation using Intel's Advanced Encryption Standard New Instructions (AES-NI).

As can be observed, the different implementation variants have similar performance, even when using hand-optimized AVX2 intrinsic instructions. This illustrates that $\FrodoKEM$'s algorithms, which are mainly based on matrix operations, facilitate automatic parallelization using vector instructions. Hence, the compiler is able to achieve close to ``optimal'' performance with little intervention from the programmer.
The best results for $\FrodoKEMLOneAES$, $\FrodoKEMLThreeAES$ and $\FrodoKEMLFiveAES$ (i.e., 0.93~ms, 1.75~ms and 2.91~ms, respectively, obtained by adding the times for encapsulation and decapsulation) are achieved by the additional implementation using AVX2 intrinsics. However, the difference in performance between the different implementations reported in \autoref{tab:results_x64_aes} is, in all the cases, less than~0.5\%.

We note that the performance of $\FrodoKEM$ using AES on Intel platforms greatly depends on AES-NI instructions. For example, when turning off the use of these instructions the computing cost of the optimized implementation of $\FrodoKEMLOneAES$ (resp.,~$\FrodoKEMLThreeAES$) is 26.4~ms (resp.,~60.9~ms), which is roughly a 28-fold (resp.,~35-fold) degradation in performance.


\begin{table}[t]
\caption{\textbf{Performance (in thousands of cycles) of $\FrodoKEM$ on a 3.4GHz Intel Core i7-6700 (Skylake) processor with matrix $\bfA$ generated using $\AESOneTwoEight$.} Results are reported using OpenSSL's AES implementation and using a standalone AES implementation, all of which exploit AES-NI instructions. Cycle counts are rounded to the nearest $10^3$ cycles.
\patrick{POSSIBLY, UPDATE RESULTS.}}\label{tab:results_x64_aes}
\medskip
\centering
\renewcommand{\tabcolsep}{0.4cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c c c|c}
\toprule
\multirow{2}{*}{\textbf{Scheme}}     &     \multirow{2}{*}{\textbf{KeyGen}}      &    \multirow{2}{*}{\textbf{Encaps}}   &    \multirow{2}{*}{\textbf{Decaps}}   &    \textbf{Total}        \\ 
                                                       &                                                            &                                                         &                                                       &    \textbf{(Encaps + Decaps)}   \\
\midrule
\multicolumn{5}{l}{\bf Optimized Implementation (AES from OpenSSL)} \\
\midrule
$\FrodoKEMLOneAES$                               &            1,389                &            1,637                   &                 1,534         &                3,171             \\
$\FrodoKEMLThreeAES$                             &            2,831                &            3,047                   &                 2,904       &                5,951             \\
$\FrodoKEMLFiveAES$                             &            4,775                &            5,063                   &                 4,840       &                 9,903             \\
\midrule
\multicolumn{5}{l}{\bf Additional implementation using AVX2 intrinsic instructions (AES from OpenSSL)} \\
\midrule
$\FrodoKEMLOneAES$                               &            1,387                &            1,634                   &                 1,531       &                3,165             \\
$\FrodoKEMLThreeAES$                             &            2,846                &            3,047                   &                2,894       &                5,941             \\
$\FrodoKEMLFiveAES$                             &            4,779                &            5,051                   &                 4,849       &                 9,900             \\
\midrule
\multicolumn{5}{l}{\bf Additional implementation using AVX2 intrinsic instructions (standalone AES)} \\
\midrule
$\FrodoKEMLOneAES$                               &            1,398                &            1,644                   &                 1,540       &                3,184             \\
$\FrodoKEMLThreeAES$                             &            2,874                &            3,054                   &                 2,908       &                5,962             \\
$\FrodoKEMLFiveAES$                             &            4,765                &            5,069                   &                 4,867       &                9,936             \\
\bottomrule
\end{tabular}
\end{table}


\subsubsection{Performance using SHAKE128}\label{sec:results_shake}

\autoref{tab:results_x64_shake} outlines the performance figures of the optimized implementations and the additional x64 implementations when using $\SHAKE128$ for the generation of the matrix $\bfA$. 
The top set of results shows the performance of the optimized implementation written in C only, while the bottom set presents the results when using a 4-way implementation of SHAKE using AVX2 instructions (``SHAKE4x using AVX2'').
Note that the use of such a vectorized implementation of SHAKE is necessary to boost the practical performance. In our use-case, it results in a two-fold speedup when compared to the version using a SHAKE implementation written in plain C.

Comparing \autoref{tab:results_x64_aes} and \autoref{tab:results_x64_shake}, $\FrodoKEM$ using AES, when implemented with AES-NI instructions, is around 2.6--3.1$\times$ faster than the vectorized SHAKE implementation. Nevertheless, this comparative result could change drastically if hardware-accelerated instructions such as AES-NI are not available on the targeted platform, or if support for hardware-accelerated instructions for SHA-3 is added in the future. 


\begin{table}[t]
\caption{\textbf{Performance (in thousands of cycles) of $\FrodoKEM$ on a 3.4GHz Intel Core i7-6700 (Skylake) processor with matrix $\bfA$ generated using $\SHAKE128$.} Results are reported for two test cases: (i) using a SHAKE implementation written in plain C and, (ii) using a 4-way implementation of SHAKE using AVX2 instructions. Cycle counts are rounded to the nearest $10^3$ cycles.}\label{tab:results_x64_shake}
\medskip
\centering
\renewcommand{\tabcolsep}{0.4cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c c c|c}
\toprule
\multirow{2}{*}{\textbf{Scheme}} & \multirow{2}{*}{\textbf{KeyGen}} & \multirow{2}{*}{\textbf{Encaps}} & \multirow{2}{*}{\textbf{Decaps}} & \textbf{Total}             \\ 
                                 &                                  &                                  &                                  & \textbf{(Encaps + Decaps)} \\ 
\midrule
\multicolumn{5}{l}{\bf Optimized Implementation (plain C SHAKE)} \\
\midrule
$\FrodoKEMLOneSHAKE$            &           7,649                  &           7,847                  &                7,743             &              15,590        \\
$\FrodoKEMLThreeSHAKE$          &          16,874                  &          17,101                  &               16,971           &              34,072        \\
$\FrodoKEMLFiveSHAKE$          &          30,465                  &          30,626                  &               30,451             &              61,077        \\
\midrule
\multicolumn{5}{l}{\bf Additional implementation using AVX2 intrinsics (SHAKE4x using AVX2)} \\
\midrule
$\FrodoKEMLOneSHAKE$            &           4,031                  &           4,218                  &                4,116             &               8,334        \\
$\FrodoKEMLThreeSHAKE$          &           8,599                  &           8,799                  &                8,659             &              17,458        \\
$\FrodoKEMLFiveSHAKE$          &          15,067                  &          15,338                  &               15,170             &              30,508        \\
\bottomrule
\end{tabular}
\end{table}
\fi

\autoref{tab:results_x64} summarizes the results of our performance evaluation using a machine equipped
with a 3.4GHz Intel Core i7-6700 (Skylake) processor and running Ubuntu 16.04.3 LTS. Following standard practice,
TurboBoost was disabled during the tests. For compilation we used GNU GCC version 7.2.0 with the command
{\tt gcc -O3 -march=native}. 
%The generation of the matrix $\bfA$ is the most expensive part of the computation. As described in
%\autoref{sec:spec:genA}, we support two ways of generating $\bfA$: one using $\AESOneTwoEight$ and
%one using $\SHAKE128$.

For the case of generating the matrix $\bfA$ using $\AES128$, we present the results when using
OpenSSL's AES implementation, which exploits AES-NI instructions.
The corresponding running times for $\FrodoKEMLOneAES$, $\FrodoKEMLThreeAES$ and $\FrodoKEMLFiveAES$ are
0.93~ms, 1.75~ms and 2.91~ms, respectively, obtained by adding the times for encapsulation and decapsulation.
This performance is expected to be typical in static key exchange applications where the cost of key generation
is amortized across many key encapsulation executions. 
For the full KEM, the running times are 1.34~ms, 2.58~ms and 4.32~ms, respectively. This corresponds to the
expected cost of \eFrodoKEM in an ephemeral setting.

Our implementation also includes the optional use of AVX2 intrinsic instructions. In our experiments, we observed that
this optimization offers a very small performance improvement compared to the C implementation. 
This illustrates that $\FrodoKEM$'s algorithms, which are mainly based on matrix operations, facilitate
automatic parallelization using vector instructions. Hence, the compiler is able to achieve close to ``optimal''
performance with little intervention from the programmer.

We note that the performance of $\FrodoKEM$ using AES on Intel platforms greatly depends on AES-NI instructions.
For example, when turning off the use of these instructions the computing cost of the optimized implementation
of $\FrodoKEMLOneAES$ (resp.,~$\FrodoKEMLThreeAES$) is 26.4~ms (resp.,~60.9~ms), which is roughly a 28-fold
(resp.,~35-fold) degradation in performance.

\autoref{tab:results_x64} also outlines the performance figures of our implementation when using $\SHAKE128$
for the generation of the matrix $\bfA$. 
The middle set of results shows the performance of the implementation written in C only, while the bottom
set presents the results when using a 4-way implementation of SHAKE using AVX2 instructions.
Note that the use of such a vectorized implementation of SHAKE is necessary to boost the practical performance.
In our use-case, it results in a two-fold speedup when compared to the version using a SHAKE implementation
written in plain C.

Comparing the use of AES128 and SHAKE128, $\FrodoKEM$ using AES, when implemented with AES-NI instructions,
is around 2.6--3.1$\times$ faster than the vectorized SHAKE implementation. Nevertheless, this comparative
result could change drastically if hardware-accelerated instructions such as AES-NI are not available on the
targeted platform, or if support for hardware-accelerated instructions for SHA-3 is added in the future. 

\begin{table}[t]
\caption{Performance (in thousands of cycles) of $\FrodoKEM$ on a 3.4GHz Intel Core i7-6700 (Skylake) processor.
For the variants using AES128, results are reported using OpenSSL's AES implementation, which exploits AES-NI instructions. 
For the variants using SHAKE128, results are reported using a plain C implementation of SHAKE and a 4-way vectorized
implementation of SHAKE using AVX2 instructions.
Cycle counts are rounded to the nearest $10^3$ cycles.}\label{tab:results_x64}
\medskip
\centering
\renewcommand{\tabcolsep}{0.25cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c c c|c}
\toprule
\multirow{2}{*}{\textbf{Scheme}}     &     \multirow{2}{*}{\textbf{KeyGen}}      &    \multirow{2}{*}{\textbf{Encaps}}   &    \multirow{2}{*}{\textbf{Decaps}}   &    \textbf{Total}        \\ 
                                   &                                             &                                       &
                                   &    \textbf{(Encaps + Decaps)}   \\
\midrule
\multicolumn{5}{l}{\bf AES from OpenSSL} \\
\midrule
$\FrodoKEMLOneAES$                               &            1,389                &            1,637                   &                 1,534         &                3,171             \\
$\FrodoKEMLThreeAES$                             &            2,831                &            3,047                   &                 2,904       &                5,951             \\
$\FrodoKEMLFiveAES$                             &            4,775                &            5,063                   &                 4,840       &                 9,903             \\
\midrule
\multicolumn{5}{l}{\bf Plain C SHAKE} \\
\midrule
$\FrodoKEMLOneSHAKE$            &           7,649                  &           7,847                  &                7,743             &              15,590        \\
$\FrodoKEMLThreeSHAKE$          &          16,874                  &          17,101                  &               16,971           &              34,072        \\
$\FrodoKEMLFiveSHAKE$          &          30,465                  &          30,626                  &               30,451             &              61,077        \\
\midrule
\multicolumn{5}{l}{\bf Vectorized SHAKE using AVX2} \\
\midrule
$\FrodoKEMLOneSHAKE$            &           4,031                  &           4,218                  &                4,116             &               8,334        \\
$\FrodoKEMLThreeSHAKE$          &           8,599                  &           8,799                  &                8,659             &              17,458        \\
$\FrodoKEMLFiveSHAKE$          &          15,067                  &          15,338                  &               15,170             &              30,508        \\
\bottomrule
\end{tabular}
\end{table}


\subsubsection{Performance analysis on ARM}\label{sec:results_arm}

\ifshoworiginal
In this section, we summarize the results of our performance evaluation using a device powered by a 1.992GHz 64-bit ARM Cortex-A72 (ARMv8) processor and running Ubuntu 16.04.2 LTS. For compilation we used GNU GCC version 5.4.0 with the command {\tt gcc -O3 -march=native}. 

\autoref{tab:results_arm} details the performance of the optimized implementations when using $\AESOneTwoEight$ and $\SHAKE128$. Similar to the case of the x64 Intel platform, the overall performance of $\FrodoKEM$ is highly dependent on the performance of the primitive that is used for the generation of the matrix $\bfA$. Hence, the best performance in this case is achieved when using OpenSSL's AES implementation, which exploits the efficient NEON engine. On the other hand, $\SHAKE$ performs significantly better when there is no support for specialized instructions in the targeted platform: using a plain C version of $\SHAKE$ is more than 3 times faster than using a plain C version of AES.

\else

\autoref{tab:results_arm} details the performance of the optimized implementations when using
$\AESOneTwoEight$ and $\SHAKE128$ on a device powered by a 1.992GHz 64-bit ARM Cortex-A72 (ARMv8)
processor and running Ubuntu 16.04.2 LTS. 
For compilation we used GNU GCC version 5.4.0 with the command {\tt gcc -O3 -march=native}. 
Similar to the case of the x64 Intel platform, the overall performance of $\FrodoKEM$ is highly
dependent on the performance of the primitive that is used for the generation of the matrix $\bfA$.
Hence, the best performance in this case is achieved when using OpenSSL's AES implementation, which
exploits the efficient NEON engine. On the other hand, $\SHAKE$ performs significantly better when
there is no support for specialized instructions in the targeted platform: using a plain C version
of $\SHAKE$ is more than 3 times faster than using a plain C version of AES.
\fi

\begin{table}[t]
\caption{Performance (in thousands of cycles) of the optimized implementations of $\FrodoKEM$ on a 1.992GHz 64-bit ARM Cortex-A72 (ARMv8) processor. Results are reported for three test cases: (i) using OpenSSL's AES implementation, (ii) using an AES implementation written in plain C, and (iii) using a $\SHAKE$ implementation written in plain C. Results have been scaled to cycles using the nominal processor frequency. Cycle counts are rounded to the nearest $10^3$ cycles.}\label{tab:results_arm}
\medskip
\centering
\renewcommand{\tabcolsep}{0.25cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c c c|c}
\toprule
\multirow{2}{*}{\textbf{Scheme}}     &     \multirow{2}{*}{\textbf{KeyGen}}      &    \multirow{2}{*}{\textbf{Encaps}}   &    \multirow{2}{*}{\textbf{Decaps}}   &    \textbf{Total}        \\ 
                                                       &                                                            &                                                         &                                                       &    (Encaps + Decaps)   \\
\midrule
\multicolumn{5}{l}{\bf AES from OpenSSL} \\
\midrule
$\FrodoKEMLOneAES$                               &            3,470                &            4,057                   &                 3,969         &                8,026             \\
$\FrodoKEMLThreeAES$                             &            7,219                &            8,530                   &                8,014       &                16,544             \\
$\FrodoKEMLFiveAES$                             &            12,789                &            14,854                   &                14,635       &                29,489             \\
\midrule
\multicolumn{5}{l}{\bf Plain C AES} \\
\midrule
$\FrodoKEMLOneAES$                               &            44,354                &           44,766                   &               44,765       &              89,531             \\
$\FrodoKEMLThreeAES$                             &         101,540                &         102,551                   &             102,460       &               205,011             \\
$\FrodoKEMLFiveAES$                             &            191,359                &           193,123                   &                192,458       &               385,581             \\
\midrule
\multicolumn{5}{l}{\bf Plain C SHAKE} \\
\midrule
$\FrodoKEMLOneSHAKE$                               &            11,278                &           12,411                   &               12,311       &               24,722             \\
$\FrodoKEMLThreeSHAKE$                             &            24,844                &           27,033                   &               26,936       &               53,969             \\
$\FrodoKEMLFiveSHAKE$                             &            44,573                &            48,554                   &                48,449       &                97,003             \\
\bottomrule
\end{tabular}
\end{table}




\section{Bibliography}
%Citing papers is done in the usual way using BibTeX or \texttt{biblatex}
%commands. For example: the RSA paper~\cite{RSA78}.

%It is highly encouraged to use CryptoBib from \url{https://cryptobib.di.ens.fr}

% This sample uses bibtex rather than biblatex.
\bibliography{./cryptobib/abbrev1,./cryptobib/crypto,refs}

% NOTES
% - Download abbrev3.bib and crypto.bib from https://cryptobib.di.ens.fr/
% - Use bilbio.bib for additional references not in the cryptobib database.
%   If possible, take them from DBLP.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

\section{Justification of security strength}
\label{sec:strength:justification}

The security of $\FrodoKEM$ is supported both by security reductions
and by analysis of the best known cryptanalytic attacks.  A summary of the bit-security estimates based on these two methodologies is shown in \autoref{tab:security}.

\subsection{Security reductions}
\label{sec:strength:reductions}

A summary of the reductions supporting the security of $\FrodoKEM$ is
as follows:

\begin{enumerate}
\item $\FrodoKEM$, using the concrete error distributions
  $\chi_\Frodo$ specified in \autoref{tab:distribution}, is an
  \INDCCA-secure KEM against classical attacks in the classical random
  oracle model, under the assumption that $\FrodoPKE$ using a rounded
  Gaussian error distribution is an \INDCPA-secure public-key
  encryption scheme against classical attacks.  This is
  \autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}, and the
  reduction is tight.  The argument combines results
  of~\cite{TCC:HofHovKil17} on the modular FO transform with results
  of~\cite{EC:LanSteSte14} on \renyi divergence. We also note that the
  same conclusion follows from the assumption that $\FrodoPKE$ using
  the distributions~$\chi_{\Frodo}$ is \INDCPA secure, using the same
  proof but without any analysis of \renyi divergence.

\item $\FrodoKEM$, using any error distribution, is an \INDCCA-secure
  KEM against quantum attackers in the quantum random oracle model,
  under the assumption that $\FrodoPKE$ using the same error
  distribution is an \OWCPA-secure public-key encryption scheme
  against quantum attackers.  This is
  \autoref{thm:cca-kem-to-cpa-pke-qrom}, and the reduction is
  non-tight.  We view this theorem as giving support for the security
  of general constructions of LWE-based KEMs in the style of FrodoKEM
  against quantum adversaries, but it does not concretely support the
  bit-security of the six FrodoKEM instantiations in this document,
  which is why we omit the corresponding column from
  \autoref{tab:security}.

\item Changing the distribution of matrix $\bfA$ from a truly uniform
  distribution to one generated from a public random seed in a
  pseudorandom fashion does not affect the security of $\FrodoKEM$ or
  $\FrodoPKE$, provided that the pseudorandom generator is modeled
  either as an ideal cipher (when using $\AESOneTwoEight$) or a random
  oracle (when using $\SHAKE128$). This is shown in
  \autoref{sec:strength:pseudorandom-A}.

\item $\FrodoPKE$, using any error distribution and a uniformly random
  $\bfA$, is an \INDCPA-secure public-key encryption scheme under the
  assumption that the uniform-secret learning with errors decision
  problem is hard for the same parameters (except for a small additive
  loss in the number of samples), for either classical or quantum
  adversaries.  This is a consequence of
  \autoref{thm:cpa-pke-to-nf-dlwe} and \autoref{thm:nf-dlwe-to-dlwe},
  and the result is tight.

\item The uniform-secret learning with errors decision problem, using
  a rounded Gaussian distribution with parameter $\sigma$ from
  \autoref{tab:distribution} and an appropriate bound on the number of
  samples, is hard under the assumption that the \emph{worst-case}
  bounded-distance decoding with discrete Gaussian samples problem
  (\BDDwDGS, \autoref{def:BDDwDGS}) is hard for related parameters.
  \autoref{thm:bddwdgs-to-dlwe} gives a non-tight classical reduction
  against classical or quantum adversaries (in the standard model).
\end{enumerate}

\subsubsection{\INDCCA security in the classical random oracle model}\label{sec:strength:cca-kem} \label{sec:renyi_loss}

The following theorem says that the transformation $\FOnotperpprime$,
which we use to construct \FrodoKEM from \FrodoPKE, generically yields
an \INDCCA-secure KEM (in the classical random oracle model) from an
\INDCPA-secure public-key encryption scheme, even if the KEM and PKE
are parameterized by different distributions, provided that those
distributions are sufficiently close in terms of \renyi divergence.

\begin{theorem}[\INDCPA PKE $\implies$ \INDCCA KEM in classical ROM,
  with distribution switch]\label{thm:cca-kem-to-cpa-pke-rom-parameterized}
  \ \newline
  Let $\PKE_X = (\KeyGen,\Enc,\Dec)$ be a $\delta$-correct public-key
  encryption scheme with message space $\MsgSp$ that is parameterized
  by a distribution~$X$, and let $s$ be an upper bound on the total
  number of samples drawn from~$X$ by $\KeyGen$ and $\Enc$ combined.
  Let $G_1$, $G_2$ and $F$ be independent random oracles, and let
  $\KEMnotperpprime_X=\FOnotperpprime[\PKE_X,G_1,G_2,F]$ be the KEM
  obtained by applying the $\FOnotperpprime$ transform from
  \autoref{def:qfo} to $\PKE_{X}$. Let $P,Q$ be any discrete
  distributions. There exists a classical algorithm (a reduction)
  $\Bdversary$ against the \INDCPA security of $\PKE_Q$, which uses as
  a ``black box'' subroutine any $\Adversary$ against the \INDCCA
  security of $\KEMnotperpprime_P$ that makes at most $\qro$ oracle
  queries, for which
  \begin{equation}
    \label{eq:cca-to-cpa-renyi-bound}
    \Adv{\indcca}{\KEMnotperpprime_P}(\Adversary) \leq
    \frac{\qro}{|\MsgSp|} + \left( \left(
        \frac{2\cdot\qro+1}{|\MsgSp|}
        + \qro \cdot \delta
        + 3 \cdot\Adv{\indcpa}{\PKE_Q}(\Bdversary) \right)
      \cdot \exp(s \cdot \RD_\alpha(P \| Q)) \right)^{1-1/\alpha}
  \end{equation}
  for any $\alpha > 1$, where the \renyi divergence $\RD_\alpha$ is
  defined in \autoref{def:renyi}. The total running time of
  $\Bdversary$ is about that of $\Adversary$ plus the time needed to
  simulate the random oracles.
\end{theorem}

We point out that when $P=Q$ are the same distribution, we have
$\exp(s \cdot \RD_{\alpha}(P \| Q)) = 1$ for any $\alpha > 1$ and
hence can take~$\alpha$ to be arbitrarily large, making the exponent
$1-1/\alpha$ approach~$1$ in the limit. This special case is a main
theorem from~\cite{TCC:HofHovKil17}, and it relates the \INDCCA
security of $\FrodoKEM$ to the \INDCPA security of $\FrodoPKE$ when
they use the same error distribution, e.g., ~$\chi_{\Frodo}$.

The proof of \autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}
combines components from two separate works: the modular analysis of
the Fujisaki--Okamoto transform by HHK~\cite{TCC:HofHovKil17}, and the
work of Langlois, Stehl{\' e}, and Steinfeld relating the security of
search problems when one distribution is substituted by another via
analysis of the \renyi divergence~\cite{EC:LanSteSte14}.  More
specifically, the proof of the theorem proceeds in the following
steps:
\begin{enumerate}
\item We apply HHK's Theorem 3.2, which shows that their $\T$
  transform converts an \INDCPA-secure public-key encryption scheme
  $\PKE_{Q}$ into an \OWPCA-secure public-key encryption scheme with
  deterministic encryption (in the random oracle model).
\item Next, we apply distribution substitution for the \OWPCA security
  experiment (which represents a search problem), to switch from
  distribution~$Q$ to~$P$.
\item Finally, we apply HHK's Theorem 3.4, which shows that their
  $\Unotperp$ transform converts an \OWPCA-secure public-key
  encryption scheme into an \INDCCA-secure KEM (in the random oracle
  model).
\end{enumerate}

HHK denote the composition of the $\T$ and $\Unotperp$ transforms as
the $\FOnotperp$ transform.  As described in
\autoref{sec:cca-transform}, we use a slight variant of this
transform called $\FOnotperpprime$, which differs from
$\FOnotperpprime$ as follows:
\begin{itemize}
\item $\FOnotperpprime$ uses a single hash function (with longer
  output) to compute $r$ and $K$, whereas $\FOnotperp$ uses two
  separate functions, but these are equivalent when the hash functions
  are modeled as independent random oracles and have appropriate
  output lengths.
\item The~$\FOnotperpprime$ computation of $r$ and $K$ also takes the
  hash $G_1(\pk)$ of the public key $\pk$ as input,
  whereas~$\FOnotperp$ does not; this change preserves the relevant
  theorems (with trivial changes to the proofs), and has the potential
  to provide stronger multi-target security.
\end{itemize}

\paragraph{Step 1: \INDCPA $\PKE$ to \OWPCA deterministic $\PKEOne$.}

For completeness, we recall the definition of \OWPCA, following the
presentation of Hofheinz et al.~\cite{TCC:HofHovKil17}.

\begin{definition}[\OWPCA for PKE~\cite{RSA:OkaPoi01}]
  \label{def:OW-CPA}
  Let \PKE be a public-key encryption scheme with message space
  $\MsgSp$ and let~$\Adversary$ be an algorithm.  The \OWPCA security
  experiment for $\Adversary$ attacking \PKE is
  $\Exp{\owpca}{\PKE}(\Adversary)$ from \autoref{fig:owpca}.  The
  advantage of~$\Adversary$ in the experiment is
  \[
    \Adv{\owpca}{\PKE}(\Adversary) := \Pr\left[
      \Exp{\owpca}{\PKE}(\Adversary) \Rightarrow 1 \right].
  \]
\end{definition}

\begin{figure}[h]
	\centering
	\fbox{
		\begin{minipage}[t]{0.4\textwidth}
			\underline{Experiment $\Exp{\owpca}{\PKE}(\Adversary)$:}
			\vspace{-1em}
			\begin{algorithmic}[1]
				\STATE $(\pk, \sk) \gets \PKE.\KeyGen()$
				\STATE $m\getsr \MsgSp$
				\STATE $c^* \gets \PKE.\Enc(m, \pk)$
				\STATE $m' \gets
                                \Adversary^{\OPco(\cdot, \cdot)}(\pk, c^*)$
				\RETURN $\OPco(m', c^*)$
			\end{algorithmic}
		\end{minipage}
		~
		\begin{minipage}[t]{0.4\textwidth}
			\underline{Oracle $\OPco(m, c)$:}
			\vspace{-1em}
			\begin{algorithmic}[1]
				\IF {$\PKE.\Dec(\sk, c)=m$}
				\RETURN 1
				\ELSE
				\RETURN 0
				\ENDIF
			\end{algorithmic}
		\end{minipage}
%		~
%\begin{minipage}[t]{0.31\textwidth}
%	\underline{Oracle $\OCvo(c)$:}
%	\vspace{-1em}
%	\begin{algorithmic}[1]
%		\IF {$c=c^*$}
%		\RETURN $\bot$
%		\ENDIF
%		\IF {$\PKE.\Dec(\sk, c)\in \MsgSp$}
%		\RETURN 1
%		\ELSE
%		\RETURN 0
%		\ENDIF
%	\end{algorithmic}
%\end{minipage}
	}
	\caption{Security experiment for \OWPCA.}
	\label{fig:owpca}
\end{figure}

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.35\textwidth}
\underline{$\PKEOne.\KeyGen()$:}
\vspace{-1em}
\begin{algorithmic}[1]
\RETURN $\PKE.\KeyGen()$
\end{algorithmic}

\medskip

\underline{$\PKEOne.\Enc(\mu, \pk)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $r \gets G_2(\mu)$
\STATE $c \gets \PKE.\Enc(\mu, \pk; r)$
\RETURN $c$
\end{algorithmic}
\end{minipage}
~
\begin{minipage}[t]{0.6\textwidth}
\underline{$\PKEOne.\Dec(c, \sk)$:}
%\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu' \gets \PKE.\Dec(c, \sk)$
\IF {$\mu' = \bot$ or $c \ne \PKE.\Enc(\mu', \pk; G_2(\mu'))$}
  \RETURN $\bot$
\ELSE
  \RETURN $\mu'$
\ENDIF
\end{algorithmic}
\end{minipage}
}
\caption{Construction of deterministic public-key encryption scheme $\PKEOne=\T[\PKE, G_2]$ from a public-key encryption scheme $\PKE$ and hash function $G_2$.}
\label{fig:T}
\end{figure}

The $\T$ transform of HHK converts a public-key encryption scheme
$\PKE$ to a deterministic public-key encryption scheme $\PKEOne$; see
\autoref{fig:T}.  HHK's Theorem~3.2 tightly establishes the
$\OWPCVA$-security of $\PKEOne$ under, among others, the assumption
that $\PKE$ is \INDCPA secure and $\gamma$-spread. (In the \OWPCVA
security game, the attacker additionally has a ciphertext-validity
oracle, which checks whether a queried ciphertext has a valid
decryption.)  However, they note that $\OWPCA$ security follows
(tightly) \emph{without} the $\gamma$-spread assumption, because in
the security bounds $\gamma$-spreadness is relevant only to
ciphertext-validity queries.  We state that adapted version here.

\begin{lemma}[\cite{TCC:HofHovKil17}, Theorem~3.2, $\OWPCA$ version]
  \label{lem:T}
  Let $\PKE$ be a $\delta$-correct public-key encryption scheme with
  message space $\MsgSp$. For any $\OWPCA$ adversary $\Adversary$ that
  issues at most~$q_G$ queries to the random oracle~$G_2$ and~$q_P$
  queries to the plaintext-checking oracle, there exists an $\INDCPA$
  adversary $\Bdversary$ such that
  \[
  \Adv{\owpca}{\PKEOne}(\Adversary) \leq q_G \cdot \delta + \frac{2 q_G
    + 1}{|\MsgSp|} + 3 \cdot \Adv{\indcpa}{\PKE}(\Bdversary) \enspace
  ,
  \]
  and the running time of $\Bdversary$ is about that of $\Adversary$
  plus the time needed to simulate the random oracle.
\end{lemma}

\noindent It is straightforward to verify from the proof that
$\Bdversary$ uses $\Adversary$ solely as a ``black box'' subroutine.

\paragraph{Step 2: Approximating the error distribution.}

The rounded Gaussian distribution (\autoref{def:rounded-gaussian}),
which is important to the worst-case-to-average-case reduction, is
difficult to sample on a finite computer (and impossible to sample in
constant time). Following Langlois et al.~\cite{EC:LanSteSte14}, we
replace this infinite-precision distribution with a finite
approximation, and quantify the $\OWPCA$ security loss using their
\renyi divergence.

\begin{definition}[\renyi divergence]
  \label{def:renyi}
  The \renyi divergence of positive order $\alpha \neq 1$ of a
  discrete distribution~$P$ from a distribution~$Q$ is defined as
  \[
    \RD_\alpha(P\|Q)=\frac1{\alpha-1}\ln \parens*{
    \sum_{x\in\mathop{\mathrm{supp}} P} P(x)\left(
      \frac{P(x)}{Q(x)}\right)^{\alpha-1}} \enspace .
  \]
\end{definition}

Note that our definition differs from that of~\cite{EC:LanSteSte14} in
that we take the logarithm of the sum, and that \renyi divergence is
not symmetric.  The following result relates probabilities of a
certain event occurring under two distributions as a function of their
\renyi divergence.

\begin{lemma}[{{\cite[Lemma 4.1]{EC:LanSteSte14}}}]
  \label{lem:renyi}
  Let $S$ be an event defined in a probabilistic experiment $G_Q$ in
  which~$s$ samples are drawn from distribution $Q$. Then the
  probability that $S$ occurs in the same experiment but with~$Q$
  replaced by~$P$ is bounded as follows:
  \begin{equation}
    \label{eqn:renyi_loss}
    \Pr[G_P(S)] \leq \left( \Pr[G_Q(S)] \cdot \exp(s \cdot
      \RD_\alpha(P\|Q)) \right)^{1-1/\alpha}.
  \end{equation}
\end{lemma}

It immediately follows that reductions from any \emph{search} problem,
such as the one represented by the $\OWPCA$ game, are preserved up to
the relaxation in \eqref{eqn:renyi_loss}. For any given security
relationship, and any concrete choice of the two distributions~$P$
and~$Q$, the loss can be minimized by choosing an optimal value of the
order~$\alpha$.

\begin{corollary}[Distribution substitution for \OWPCA]
  \label{cor:sbst-owpca}
  Let $\PKE_X$ be a public-key encryption scheme that is parameterized
  by a distribution~$X$, and let~$s$ be an upper bound on the total
  number of samples drawn from~$X$ by $\PKE_X.\Enc$ and
  $\PKE_X.\KeyGen$ combined. Let $\Adversary$ be an \OWPCA adversary
  against $\PKE_X$, and let~$P$ and~$Q$ be discrete
  distributions. Then for any $\alpha > 1$,
  \[
    \Adv{\owpca}{\PKE_P}(\Adversary) \leq
    \left( \Adv{\owpca}{\PKE_Q}(\Adversary)\cdot
      \exp(s \cdot \RD_\alpha(P \| Q)) \right)^{1-1/\alpha} \enspace .
  \]
\end{corollary}

\begin{proof}
  This follows immediately from \autoref{lem:renyi}, with $S$ being
  the event that~$\Adversary$ ``wins'' the \OWPCA experiment from
  \autoref{fig:owpca}, i.e., causes it to output~$1$.
\end{proof}

We use \autoref{cor:sbst-owpca} to relate the \OWPCA security of
$\T[\FrodoPKE_{P},G_{2}]$ to the \OWPCA security of
$\T[\FrodoPKERGauss,G_{2}]$ where $\FrodoPKERGauss$ is the same as
$\FrodoPKE$ but with the error distribution $P=\chi_{\Frodo}$ replaced
by a rounded Gaussian distribution~$Q=\Psi$
(see~\autoref{def:rounded-gaussian}).

\paragraph{Step 3: \OWPCA deterministic $\PKEOne$ to \INDCCA KEM.}

HHK define the $\Unotperp$ transform from a deterministic public-key
encryption scheme $\PKEOne$ to a key encapsulation mechanism
$\KEMnotperp$; see \autoref{fig:Unotperp}.  HHK's Theorem~3.4 shows
the \INDCCA security of $\KEMnotperp = \Unotperp[\PKEOne,F]$ assuming
the \OWPCA security of the underlying $\PKEOne$. Their result is
stated below in \autoref{lem:Unotperp}.

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.4\textwidth}
\underline{$\KEMnotperp.\KeyGen()$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $(\pk, \sk) \getsr \PKEOne.\KeyGen()$
\STATE $s \getsr \MsgSp$
\STATE $\sk' \gets (\sk, s)$
\RETURN $(\pk, \sk')$
\end{algorithmic}

\medskip

\underline{$\KEMnotperp.\Encaps(\pk)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu \getsr \MsgSp$
\STATE $c \gets \PKEOne.\Enc(\mu, \pk)$
\STATE $ss \gets F(\mu, c)$
\RETURN $(c, ss)$
\end{algorithmic}
\end{minipage}
~
\begin{minipage}[t]{0.5\textwidth}
\underline{$\KEMnotperp.\Decaps(c, (\sk, s))$:}
%\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu' \gets \PKE.\Dec(c, \sk)$
\IF {$\mu' \ne \bot$}
  \RETURN $ss' \gets F(\mu', c)$
\ELSE
  \RETURN $ss' \gets F(s, c)$
\ENDIF
\end{algorithmic}
\end{minipage}
}
\caption{Construction of key encapsulation mechanism $\KEMnotperp=\Unotperp[\PKEOne, F]$ from a deterministic public-key encryption scheme $\PKEOne$ and hash function $F$.}
\label{fig:Unotperp}
\end{figure}

\begin{lemma}[{{\cite[Theorem~3.4]{TCC:HofHovKil17}}}]
  \label{lem:Unotperp}
  Model~$F$ as a random oracle.  Then if $\PKEOne$ is
  $\delta_1$-correct, so is $\KEMnotperp$.  For any $\INDCCA$
  adversary $\Adversary$ against $\KEMnotperp$ issuing at
  most $q_F$ queries to~$F$, there exists an $\OWPCA$ adversary
  $\Bdversary$ against $\PKEOne$ that makes at most $q_F$ queries to
  its plaintext-checking oracle, and for which
  \[
    \Adv{\indcca}{\KEMnotperp}(\Adversary) \leq \frac{q_F}{|\MsgSp|} +
    \Adv{\owpca}{\PKEOne}(\Bdversary) \enspace ,
  \]
  where the running time of $\Bdversary$ is about that of
  $\Adversary$, plus the time to simulate the random oracle and
  decapsulation queries.
\end{lemma}

It is straightforward to verify from the proof that $\Bdversary$ uses
$\Adversary$ solely as a ``black box'' subroutine.  Together,
\autoref{lem:T}, \autoref{cor:sbst-owpca}, and \autoref{lem:Unotperp}
establish \autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}.

\paragraph{Applying \autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}.}

For an application of
\autoref{thm:cca-kem-to-cpa-pke-rom-parameterized} to our schemes,
consider the relation between the $\INDCCA$ security of \FrodoKEMLOne
and the $\INDCPA$ security of $\FrodoPKELOne_\Psi$, where the error
distribution of the latter is taken to be the rounded Gaussian
$\Psi_{2.8\cdot\sqrt{2\pi}}$ as defined in \autoref{sec:gaussians}.

To extract exact bounds on the \INDCCA security (in the classical ROM)
of \FrodoKEMLOne, we make a number of assumptions about the underlying
cost model. Specifically,
\begin{itemize}
\item We ignore the overhead of running the reduction
  of~\autoref{thm:cca-kem-to-cpa-pke-rom-parameterized}, including the
  cost of simulating random oracles.
\item The cost to the adversary of \emph{making} an oracle query is
  $2^{18}$ classical gates. This bound is based on the NIST Call for
  Proposals, Section 4.A.5, which estimates the cost of finding collisions
  in SHA-3 at all security levels. (Here we
  ignore the small performance differences between $\SHAKE128$,
  $\SHAKE256$, and SHA3-256.)
\item We interpret ``$b$ bits of
  classical security'' as a statement that the advantage in the
  corresponding game of a uniform $t$-gate classical adversary is
  bounded by $t/2^b$. For some tasks, such as collision finding,
  this upper bound can be quite loose for smaller values
  of~$t$ (and thus beneficial to the adversary).
\item The \INDCPA security of $\FrodoPKELOne_\Psi$ is given by the
  smaller of the costs of the primal and dual attacks on the LWE
  problem (\autoref{tab:attacks}), discounted by the reduction factor
  of $\nbar + \mbar=16$ (\autoref{thm:cpa-pke-to-nf-dlwe}),
  yielding~$2^{-145.6}$.
\end{itemize}

Under these assumptions, if an adversary $\Bdversary$ has uniform gate
complexity $t$, then it has advantage
$\Adv{\indcpa}{\FrodoPKELOne_\Psi}(\Bdversary)$ bounded
by~$t\cdot 2^{-145.6}$.

The \renyi divergence of $\chi_\FrodoLOne$ from the rounded Gaussian
is $\RD_\alpha(\chi_\FrodoLOne\| \Psi_{2.8\cdot \sqrt{2\pi}}) \leq
0.0000324$ for $\alpha=200$ (\autoref{tab:distribution}). The number of
samples drawn from the error distribution by $\FrodoPKE.\KeyGen$ is
$2n\nbar$, and by $\FrodoPKE.\Enc$ is $2\mbar n+\mbar \nbar$, which
for $n=640$ and $\mbar=\nbar=8$ totals
$s=2\times(8 + 8)\times 640+64=20544$.

Substituting $\qro < t\cdot 2^{-18}$, $|\MsgSp|=2^{128}$ and
$\delta<2^{-138.7}$ into~\eqref{eq:cca-to-cpa-renyi-bound}, we can
bound the advantage in $\Exp{\indcca}{\FrodoKEMLOne}$ for an adversary
$\Adversary$ with gate count~$t \geq 1$ as follows:
\begin{align*}
  \Adv{\indcca}{\FrodoKEMLOne}(\Adversary)
  &< 2^{-146} \cdot t + \left((2.01 \cdot 2^{-146} + 3 \cdot
    2^{-145.6}) \cdot t \cdot \exp(20544\cdot 0.0000324)\right)^{0.995} \\
  &< 2^{-141.6} \cdot t \enspace .
\end{align*}
Similarly computed bounds on the advantage of a classical \INDCCA
adversary for other parameter settings appear
in~\autoref{tab:security}.

\subsubsection{\INDCCA security in the quantum random oracle model}
\label{sec:strength:cca-kem-qrom}

Jiang et al.~\cite{C:JZCWM18} show that the $\FOnotperp$ transform
yields an \INDCCA-secure KEM from an \OWCPA-secure public-key
encryption scheme, in the \emph{quantum} random oracle model.  As
noted above, we apply a slight variant~$\FOnotperpprime$ of
the~$\FOnotperp$ transform, which does not affect Jiang et al.'s
results.

\begin{theorem}[$\OWCPA$ PKE $\implies$ $\INDCCA$ KEM in quantum ROM;
  {\cite[Theorem 1]{C:JZCWM18}}]
  \label{thm:cca-kem-to-cpa-pke-qrom}
  Let $\PKE = (\KeyGen,\Enc,\Dec)$ be a $\delta$-correct public-key
  encryption scheme with message space $\MsgSp$.  Let~$G_2$ and~$F$ be
  independent random oracles.  Let
  $\KEMnotperp=\FOnotperp[\PKE,G_2,F]$ be the KEM obtained by applying
  the $\FOnotperp=\Unotperp \circ \T$ transform to~$\PKE$.  For any
  quantum algorithm $\Adversary$ against the \INDCCA security of
  $\KEMnotperp$ that makes~$q_F$ quantum oracle queries to~$F$
  and~$q_G$ quantum oracle queries to~$G_2$, there exists a quantum
  algorithm $\Bdversary$ against the \OWCPA security of $\PKE$ such
  that
  \[ \Adv{\indcca}{\KEMnotperp}(\Adversary) \leq
    \frac{2 q_F}{\sqrt{|\MsgSp|}} + 4 q_G \sqrt{\delta} + 2(q_G + q_F)
    \sqrt{\Adv{\owcpa}{\PKE}(\Bdversary)}.\] Moreover, the running
  time of $\Bdversary$ is about that of $\Adversary$.
\end{theorem}

Note that \autoref{thm:cca-kem-to-cpa-pke-qrom} is not tight due to
the square-root on the size of the message space $\MsgSp$, the
square-root on the correctness error $\delta$, the multiplicative
factors from the number of hash function queries, and the square-root
on the $\Adv{\owcpa}{\PKE}(\Bdversary)$ term.  In our parameter
selection, we ignore the tightness gap arising from
\autoref{thm:cca-kem-to-cpa-pke-qrom}.

In an eprint posted in February 2019, Jiang, Zhang, and Ma
\cite[Theorem~3]{EPRINT:JiaZhaMa19} give a tighter proof of the QROM
security of the $\FOnotperp$ transform, with a bound of
\[
\Adv{ind-cca}{\KEMnotperp}(\Adversary) 
\le
\frac{2 q_F}{\sqrt{|\MsgSp|}}
+ 4 q_G \sqrt{\delta}
+ 2 \sqrt{
	\qro \cdot \Adv{ind-cpa}{\PKE}(\Bdversary)
	+ \frac{2 (\qro + 1)^2}{|\MsgSp|}
}
\textrm{ where }\qro=q_F+q_G \enspace.
\]
This theorem also applies to our $\KEMnotperpprime$.

\subsubsection{Deterministic generation of $\bfA$}\label{sec:strength:pseudorandom-A}

\newcommand{\idx}{\ensuremath{\mathsf{idx}}}
\newcommand{\Idx}{\ensuremath{\mathrm{Idx}}}
\newcommand{\IC}{\ensuremath{\mathrm{IC}}}

The matrix $\bfA$ in $\FrodoKEM$ and $\FrodoPKE$ is  deterministically expanded from a short random seed in the function $\Frodo.\gen$ either using $\AESOneTwoEight$ or $\SHAKE128$. In order to
relate $\FrodoKEM$ and $\FrodoPKE$'s security to the hardness of the learning with errors
problem, we argue that we can replace a uniformly sampled $\bfA\in
\bbZ_q^{n\times n}$ with matrices sampled according to
$\Frodo.\gen$. Although the matrix appears pseudorandom under standard security assumptions to an adversary without access to the seed, we argue security of this step against a stronger (and more realistic) adversary via the indifferentiability framework
\cite{TCC:MauRenHol04, C:CDMP05}.

Informally, a construction $\calC$ with
access to an ideal primitive $\calG$ is said to be $\eps$-indifferentiable
from an ideal primitive $\calF$ if there exists a simulator $\calS$ such that
for any polynomial time distinguisher $\calD$ it holds that $\left| \Pr\left[
\calD^{\calC, \calG} = 1  \right] - \Pr\left[\calD^{\calF, \calS} = 1
\right] \right|< \eps$. An
indifferentiability argument implies that any cryptosystem secure in the
$\calF$-model remains secure (in a tight sense) in the $\calG$-model with
$\calF$ instantiated as $\calC^\calG$ \cite{TCC:MauRenHol04}. In what follows, we consider the ideal
primitive $\calF$ to be an ideal ``domain expansion'' function expanding a small
seed to a matrix $\bfA$. Critically, the security of the step depends on the properties of $\calG$ rather than randomness of the seed. The construction $\calC$ and primitive
$\calG$ depend on whether we use $\AESOneTwoEight$ or $\SHAKE128$, modeled below as an ideal cipher and an ideal extendable-output function (XOF) respectively.

\paragraph{Using AES128 to generate $\bfA$.}
\autoref{alg:genA_AES} generates the entries of $\bfA$ as $16$-bit values and then reduces each one modulo $q$. For simplicity, we assume that $\bfA$ consists of  $N=16n^2$ bits 
and we set $M = N/128$. This means that $\bfA$ consists of $M$ $128$-bit
$\AESOneTwoEight$ blocks. The pseudorandom bits in the $i$th block are
generated by encrypting a fixed index $\idx_i$ with a uniformly random $\seedA\in \{0,1\}^{128}$ as the key. Throughout, we refer to the set $\Idx := \left\{\idx_1,\ldots, \idx_M\right\}$ as the set of indices used in the pseudorandom generation of $\bfA$.

The ideal domain expansion primitive $\calF$ expands a uniformly random seed
$\seedA \in \{0,1\}^{128}$ to a larger bit string $s_1 \| s_2 \| \cdots \|
s_M \in \{0, 1\}^{128M}$ subject to the condition that $s_i \neq s_j$ for any
distinct pair of $i$, $j$. Observe that a uniformly sampled $\bfA$ satisfies
this condition with probability at least $1-M^2/2^{128}$. In our security
reductions, the matrix $\bfA$ is constructed through $m = n$ calls to the LWE
oracle (\autoref{def:dlweproblem}). By increasing the number of calls to this
oracle marginally, by setting $m = 1.01n > n \cdot (1-M^2/2^{128})^{-1}$, we
can construct an LWE matrix $\bfA$ sampled from the same distribution as the
output of $\calF$ with overwhelming probability without affecting its
underlying security.
\medskip

When $\Frodo.\gen$ uses $\AESOneTwoEight$, we consider a construction
$\calC^\calG$
in the Ideal Cipher model implementing $\calF$ as $\AESOneTwoEight_{\seedA}(\idx_1) \| \cdots \| \AESOneTwoEight_{\seedA}(\idx_M)$. We show that
$\calC^\calG$ is indifferentiable from $\calF$ as follows. Consider the two
worlds with which $\calD$ interacts to make queries on the construction
$\calC$ and $\calG$:
\begin{itemize}
	\item \textbf{REAL.} In the real world, upon query $\calC(k)$, $\calD$
	receives $\AESOneTwoEight_k(\idx_1) \| \cdots \| \AESOneTwoEight_k(\idx_M)$. 
      Queries to $\calG$ are answered naturally with
	$\AESOneTwoEight_{(\cdot)}(\cdot)$ or $\AESOneTwoEight^{-1}_{(\cdot)}(\cdot)$ as
	required.
	\item \textbf{IDEAL.} In the ideal world, upon query $\calC(k)$, the
	simulator $\calS$ simulates $\calF$ as follows. $\calS$ samples $M$
	uniformly random strings $s_1, \ldots, s_M$ subject to no collisions and outputs
	$\calF(k) = s_1 \| \cdots \| s_M$. It additionally stores a mapping $M_k$
	from $\{\idx_1, \ldots, \idx_M\}$ to $S = \{s_1, \ldots, s_M\}$. These
	will be used to answer $\calG$ queries. Without loss of generality, we
	assume that whenever $\calG$ is queried on a key $k$, $\calS$ pretends
	that $\calC(k)$ has been queried and sets up $M_k$.
	
	$\calD$ can now effectively simulate an ideal cipher $\calG$ as follows.
	For forward queries with an input in $\Idx$ or backward queries with
	an input in $S_k$, $\calS$ uses the mapping $M_k$ to answer the query in a
	manner consistent with $\calC(\cdot)$ simulation. For all other queries, the simulator maintains an
	on-the-fly table to simulate an ideal cipher. It samples independent
	uniformly random responses for each input query (forward or backward) subject to
	the fact that the resulting table of input/output pairs $(x, y)$ combined
	with $(\idx_i, s_i)$ pairs remains a permutation
	over $\{0, 1\}^{128}$ for every key $k$.
\end{itemize}

It is easy to see that the simulator is efficient. Indifferentiability of the
two worlds follows by construction as $\AESOneTwoEight(\cdot, \cdot)$ is
modeled as an ideal cipher. Thus, in generating $\bfA$ starting with a seed
$\seedA$ using $\AESOneTwoEight$, we can effectively replace the ideal
domain extension primitive $\calF$ with our construction in the ideal cipher
model.

\paragraph{Using $\SHAKE128$ to generate $\bfA$.} An argument in using
$\SHAKE128$ to expand $\seedA$ to the matrix~$\bfA$ is significantly
simpler. In the random oracle model, $\SHAKE128$ is an ideal XOF
\cite{dworkin2015sha}. In fact, for every distinct prefix $str$, we can
model $\SHAKE128(str \| \cdot, \ell)$ as an independent hash function mapping
$\{0, 1\}^{128}$ to $\{0, 1\}^\ell$. 

The domain expansion step is constructed
by computing $\SHAKE128(\inner{i} \| \seedA, 16n)$ for $1 \leq i \leq n$
where $\inner{i} \in \bit^{16}$; each step fills up the $i$th row of the matrix $\bfA$. As each row is
independently constructed via an ideal hash function, this construction maps
a uniformly random seed $\seedA$ to a much larger uniformly random matrix $\bfA$
thereby implementing the ideal functionality $\calF$ perfectly.

\paragraph{Reusing $\bfA$.}

Finally, we point out that generating~$\bfA$ from
$\seedA$ can be a significant computational burden, but this
cost can be amortized by relaxing the requirement that a fresh
$\seedA$ be used for every instance of key encapsulation, e.g., by
caching and reusing~$\bfA$ for a small period of time. In this case,
we observe that the cost of generating~$\bfA$ represents roughly 40\% of the cost
of encapsulation and decapsulation on the targeted x64 Intel machine used in 
\autoref{sec:performance}. 
A straightforward argument shows that the amortization above is compatible with all the security
reductions in this section.  But importantly, it now allows for an
all-for-the-price-of-one attack against those key encapsulations that share
the same~$\bfA$. This can be mitigated by making sure that we cache and
reuse~$\bfA$ only for a small number of uses, but we need to do this
in a very careful manner.

\paragraph{Generating $\bfA$ from joint randomness.}
It is also possible to generate $\bfA$ from joint randomness or using protocol
random nonces.  For example, when integrating \FrodoKEM into the TLS protocol,
$\bfA$ could be generated from a seed consisting of the random nonces \texttt{client\_random}
and \texttt{server\_random} sent by the client and server in their
\texttt{ClientHello} and \texttt{ServerHello} messages in the TLS handshake protocol.  
This functionality does not match the standard
description of a KEM and the API provided by NIST, but is possible in general.
A design with both parties contributing entropy to the seed might better
protect against all-for-the-price-of-one attacks by being more robust to
faulty
random number generation at one of the parties.

\subsubsection{\INDCPA security}\label{sec:strength:cpa-pke}

In this section we show that $\FrodoPKE$, using any error distribution
$\chi$ and uniformly random $\bfA$, is an \INDCPA-secure public-key
encryption scheme based on the hardness of the learning with errors
decision problem with the same error distribution. We first tightly
relate the \INDCPA security of $\FrodoPKE$ to the normal-form DLWE
problem, where the secret coordinates have the same distribution as
the errors.

\begin{theorem}[normal-form DLWE $\implies$ $\INDCPA$ security of
  $\FrodoPKE$]
  \label{thm:cpa-pke-to-nf-dlwe}
  Let $n, q, \mbar, \nbar$ be positive integers, and $\chi$ be a
  probability distribution on $\bbZ$. There exist classical algorithms
  $\Bdversary_{1}, \Bdversary_{2}$ that use as a ``black box''
  subroutine any (quantum or classical) algorithm $\Adversary$ against
  the $\INDCPA$ security of $\FrodoPKE$ (with a uniformly random
  $\bfA$), for which
  \[ \Adv{\indcpa}{\FrodoKEM}(\Adversary) \leq \nbar \cdot
    \Adv{\nfdlwe}{n,n,q,\chi}(\Bdversary_1) + \mbar \cdot
    \Adv{\nfdlwe}{n,n+\nbar,q,\chi}(\Bdversary_2) \enspace . \] The
  running times of $\Bdversary_1$ and $\Bdversary_2$ are approximately
  that of $\Adversary$.
\end{theorem}
The proof of \autoref{thm:cpa-pke-to-nf-dlwe} is the same as that of
\cite[Theorem~3.2]{RSA:LinPei11} or \cite[Theorem~5.1]{CCS:BCDMNN16}.

The following theorem relates the LWE decision problem in its normal
form to one where the secret is \emph{uniformly random} over
$\bbZ_{q}$. We need this only for connecting the latter variant, which
arises in the reduction from worst-case lattice problems described in
the next subsection, to the normal form as used in $\FrodoPKE$. (In
particular, our cryptanalysis and concrete security bounds are for the
normal form.) The theorem is specialized to power-of-two modulus~$q$
(our case of interest), and the stated bounds in the advantage and
number of LWE samples are more precise than those given in the
original work. These bounds follow from the fact that, by a
straightforward calculation, a uniformly random $n$-by-$(n+k)$ matrix
over~$\bbZ_{q}$ has an invertible $n$-by-$n$ submatrix except with
probability at most~$2^{-k}$.

\begin{theorem}[uniform-secret DLWE $\implies$ normal-form DLWE; \cite{C:ACPS09}, Lemma~2]
  \label{thm:nf-dlwe-to-dlwe}
  Let $n, m, k, q$ be positive integers with $q \geq 2$ a power of
  two, and let $\chi$ be a probability distribution on $\bbZ$. There
  exists a classical algorithm~$\Bdversary$ that uses as a ``black
  box'' subroutine any (quantum or classical) algorithm $\Adversary$
  against the normal-form LWE decision problem, for which
  \[ \Adv{\nfdlwe}{n,m,q,\chi}(\Adversary) \leq \Adv{\dlwe}{n,m + n +
      k,q,\chi}(\Bdversary) + 2^{-k} \enspace . \] The running time of
  $\Bdversary$ is approximately that of $\Adversary$.
\end{theorem}

\subsubsection{Reductions from worst-case lattice problems}
\label{sec:strength:lattice}

When choosing parameters for LWE, one needs to choose an error
distribution, and in particular its ``width.''  Certain choices (e.g.,
sufficiently wide Gaussians) are supported by \emph{reductions} from
worst-case lattice problems to LWE; see,
e.g.,~\cite{Reg09,STOC:Peikert09,STOC:BLPRS13,STOC:PeiRegSte17}.  At a
high level, such a reduction transforms any algorithm that solves LWE
\emph{on the average}---i.e., for random instances sampled according
to the prescribed distribution---into an algorithm of related
efficiency that solves \emph{any instance} of certain lattice problems
(not just random instances).

% In this section we recall and slightly improve the most recent
% reduction, from~\cite{STOC:PeiRegSte17}.

%  For the (quantum) reduction from the worst-case approximate
%   $\SIVP$ and $\GapSVP$ problems, we improve the constant factor in
%   the lower bound~$c \sqrt{n}$ on the width of the LWE error, from~$2$
%   to~\cpnote{new constant.}.

The original work of~\cite{Reg09} and a follow-up
work~\cite{STOC:PeiRegSte17} gave quantum polynomial-time reductions,
from the worst-case $\GapSVP_\gamma$ (\autoref{def:GapSVP}),
$\SIVP_\gamma$ (\autoref{def:SIVP}), and $\DGS_{\varphi}$
(\autoref{def:DGS}) problems on $n$-dimensional lattices, to
$n$-dimensional LWE (for an unbounded polynomial $m=\text{poly}(n)$
number of samples) with Gaussian error of standard deviation
$\sigma \geq c\sqrt{n}$.  The constant factor~$c$ was originally
stated as $c=\sqrt{2/\pi}$, but can easily be improved to any
$c > 1/(2\pi)$ via a tighter analysis of essentially the same
proof.\footnote{The approximation factor~$\gamma$ for $\GapSVP$ and
  $\SIVP$ is $\tilde{O}(qn/\sigma) = (qn/\sigma) \log^{O(1)} n$, and
  the parameter~$\varphi$ for $\DGS$ is $\Theta(q\sqrt{n}/\sigma)$
  times the ``smoothing parameter'' of the lattice.} However, for
efficiency reasons our choices of~$\sigma$ (see
\autoref{tab:distribution}) are somewhat smaller than required by these
reductions.

Instead, following~\cite[Section~1.1]{Reg09}, below we obtain an
alternative \emph{classical} (i.e., non-quantum) reduction from a
variant of the worst-case bounded-distance decoding~($\BDD$) problem
to our LWE parameterizations. In contrast to the quantum reductions
described above, which requires Gaussian error of standard deviation
$\sigma \geq c \sqrt{n}$, the alternative reduction supports a
smaller error width---as small as the ``smoothing
parameter''~\cite{DBLP:journals/siamcomp/MicciancioR07} of the lattice
of integers~$\ZZ$.  For the $\BDD$ variant we consider, which we call
``BDD with Discrete Gaussian Samples'' ($\BDDwDGS$), the input
additionally includes discrete Gaussian samples over the dual lattice,
but having a larger width than known algorithms are able to
exploit~\cite{DBLP:conf/approx/LiuLM06,DBLP:conf/coco/DadushRS14}. Details
follow.

% \cpnote{New theorem stating quantum reduction with best known
%   constant?}

\paragraph{Bounded-distance decoding with discrete Gaussian samples.}
%\label{sec:strength:lattice:bdd}

% \cpnote{Should this be a paragraph header, rather than a new
%   subsubsection (which separates it from the previous one, on
%   worst-case reductions?)}

We first define a variant of the bounded-distance decoding problem,
which is implicit in prior works that consider ``$\BDD$ with
preprocessing,''~\cite{DBLP:journals/jacm/AharonovR05,DBLP:conf/approx/LiuLM06,DBLP:conf/coco/DadushRS14}
and recall the relevant aspects of known algorithms for the problem.

\begin{definition}[Bounded-distance decoding with discrete Gaussian samples]
  \label{def:BDDwDGS}
  For a lattice~$\calL \subset \RR^{n}$ and positive reals
  $d < \lambda_{1}(\calL)/2$ and $r > 0$, an instance of the
  \emph{bounded-distance decoding with discrete Gaussian samples}
  problem $\BDDwDGS_{\calL,d,r}$ is a point $\bft \in \RR^{n}$ such that
  $\dist(\bft,\calL) \leq d$, and access to an oracle that samples from
  $D_{\calL^{*},s}$ for any (adaptively) queried $s \geq r$. The goal is
  to output the (unique) lattice point $\bfv \in \calL$ closest to~$\bft$.
\end{definition}

\begin{remark}
  \label{rem:BDDwDGS-param}
  For a given distance bound~$d$, known $\BDDwDGS$ algorithms use
  discrete Gaussian samples that all have the same width
  parameter~$s$. However, the reduction to LWE will use the ability to
  vary~$s$. Alternatively, we mention that when
  $r \geq \eta_{\eps}(\calL^{*})$ for some very
  small~$\eps > 0$ (which will always be the case in our setting),
  we can replace the variable-width DGS oracle from
  \autoref{def:BDDwDGS} with a fixed-width one that samples from
  $D_{\bfw+\calL^{*},r}$ for any queried coset $\bfw+\calL^{*}$,
  always for the same width~$r$.  This is because we can use the
  latter oracle to implement the former one (up to statistical
  distance $8\eps$), by sampling~$\bfe$ from the continuous
  Gaussian of parameter $\sqrt{s^{2}-r^{2}}$ and then adding a sample
  from $D_{\calL^{*}-\bfe,r}$. See~\cite[Theorem~3.1]{C:Peikert10} for
  further details.
\end{remark}

The state-of-the-art algorithms for solving
$\BDDwDGS$~\cite{DBLP:journals/jacm/AharonovR05,DBLP:conf/approx/LiuLM06,DBLP:conf/coco/DadushRS14}
employ a certain $\calL$-periodic function
$f_{\calL,1/r} \colon \RR^{n} \to [0,1]$, defined as
\begin{equation}
  \label{eq:f_L}
  f_{\calL,1/r}(\bfx) := \frac{\rho_{1/r}(\bfx+\calL)}{\rho_{1/r}(\calL)} =
  \E_{\bfw \sim D_{\calL^{*},r}}[\cos(2\pi \inner{\bfw, \bfx})] \enspace ,
\end{equation}
where the equality on the right follows from the Fourier series of
$f_{\calL,1/r}$ (see~\cite{DBLP:journals/jacm/AharonovR05}).  To solve
$\BDDwDGS$ for a target point~$\bft$, the algorithms use several
discrete Gaussian samples $\bfw_{i} \sim D_{\calL^{*},r}$ to estimate
the value of~$f_{\calL,1/r}$ at~$\bft$ and nearby points via
Equation~\eqref{eq:f_L}, to ``hill climb'' from~$\bft$ to the nearest
lattice point.  For the relevant points~$\bft$ we have the (very
sharp) approximation
\[ f_{\calL,1/r}(\bft) \approx \exp(-\pi r^{2} \cdot
  \dist(\bft,\calL)^{2}) \enspace , \] so by the Chernoff-Hoeffding
bound, approximating $f_{\calL,1/r}(\bft)$ to within (say) a factor of
two uses at least
\[ \frac{1}{f_{\calL,1/r}(\bft)^{2}} \approx \exp(2\pi r^{2} \cdot
  \dist(\bft,\calL)^{2}) \] samples.\footnote{In fact, the algorithms
  need approximation factors much better than two, so the required
  number of samples is even larger by a sizable constant
  factor. However, the above crude bound will be sufficient for our
  purposes.}  Note that without enough samples, the ``signal'' of
$f_{\calL,1/r}(\bft)$ is overwhelmed by measurement ``noise,'' which
prevents the hill-climbing from making progress toward the answer.

In summary, when limited to~$N$ discrete Gaussian samples, the known
approaches to solving $\BDDwDGS$ are limited to distance
\begin{equation}
  \label{eq:dist-given-samples}
  \dist(\bft, \calL) \leq r^{-1} \sqrt{\ln(N)/(2\pi)} \enspace .
\end{equation}
Having such samples does not appear to provide any speedup in
decoding at distances that are larger than this bound by some constant factor
greater than one.  In particular, if
$d \cdot r \geq \omega(\sqrt{\log n})$ (which is the smoothing
parameter of the integer lattice~$\bbZ$ for negligible error~$\eps$),
then having $N=\text{poly}(n)$ samples does not seem to provide any
help in solving $\BDDwDGS_{\calL,d,r}$ (versus having no samples at
all).

% CJP: don't need this because maximizing the decoding *distance* is
% not relevant to the reduction to LWE (the BDD distance we use in the
% reducing is much smaller than what can be decoded in principle).
% Instead, the *sample complexity* of the BDD algorithms (vs the
% reduction) is our main concern.

% The state of the art for solving $\BDDwDGS$ is~\cite{DRS}, which
% obtains a very sharp (non-asymptotic) bound on the decoding distance,
% along with a sufficiently tight lower bound on the number of discrete
% Gaussian samples used.

% \begin{theorem}[{{\cite[Theorem~3.1, generalized]{DRS}}}]
%   \label{thm:DRS-BDDwDGS}
%   Fix a lattice $\calL \subset \RR^{n}$ and some positive
%   $\eps < 1/200$, and let
%   $d_{\eps} = \sqrt{\ln(2(1+1/\eps))/\pi}$ and
%   $\delta_{\max} = \tfrac12 - \tfrac{2}{\pi d_{\eps}^{2}}$.  Then
%   for any $r \geq \eta_{\eps}(\calL^{*})$, there is an algorithm that
%   solves $\BDDwDGS_{\calL,d,r}$ for distance bound
%   $d = \delta_{\max} d_{\eps} / r$, using
%   $N > \ln (1/\eps)/\sqrt{\eps}$ samples from $D_{\calL^{*},r}$.
% \end{theorem}

% \begin{remark}
%   \label{rem:DRS-BDDwDGS}
%   The above statement generalizes the equality
%   $r = \eta_{\eps}(\calL^{*})$ in~\cite{DRS} to a lower bound, which
%   simply replaces $\eta_{\eps}(\calL^{*})$ with~$r$ in the denominator
%   of the distance bound~$d$. \cpnote{More about why this change is
%     justified.  The decoding distance comes from the analysis of
%     gradient ascent on $f_{\calL}$ itself, ignoring its approximation via
%     samples.  The number of samples comes from the approximation of
%     $f_{\calL}$ and its gradient: DGS shows that
%     $f_{\calL}(\bft) \approx \eps^{1/4}$ for $\bft$ within the
%     distance bound, hence $1/\sqrt{\eps}$ samples are needed for
%     the approximation, by Chernoff.}
% \end{remark}

% For example, if we let $\eps = 2^{-256}$ so that the algorithm
% needs $N > 2^{128}$ discrete Gaussian samples and hence steps of
% computation (even ignoring the second-order terms), then the decoding
% radius $d < 3.681/r$.  This suggests the following:

% \begin{conjecture}
%   \label{con:BDDwDGS-hard}
%   $\BDDwDGS_{\calL,d,r}$ is concretely infeasible in the worst case for
%   any $d \geq 4/r$ and any not-too-large
%   $r \geq \eta_{2^{-256}}(\calL^{*})$.\footnote{The ``not too large''
%     qualifier is needed here because $\BDD$ is easy for the very small
%     distance bound $2^{-n} \cdot \lambda_{1}(\calL)$, using LLL.}
% \end{conjecture}



\paragraph{Reduction from \BDDwDGS to LWE.}

We now recall the following result from~\cite{STOC:PeiRegSte17},
which generalizes a key theorem from~\cite{Reg09} to give a reduction
from $\BDDwDGS$ to the LWE decision problem.

\begin{theorem}[{{$\BDDwDGS$ hard $\implies$ decision-LWE hard
      \cite[Lemma~5.4]{STOC:PeiRegSte17}}}]
  \label{thm:bddwdgs-to-dlwe}
  Let $\eps = \eps(n)$ be a negligible function and let
  $m=\text{poly}(n)$ and $C=C(n) > 1$ be arbitrary.  There is a
  probabilistic polynomial-time (classical) algorithm that, given
  access to an oracle that solves $\DLWE_{n,m,q,\alpha}$ with
  non-negligible advantage and input a number $\alpha \in (0,1)$, an
  integer $q \geq 2$, a lattice $\calL \subset \RR^{n}$, and a
  parameter $r \geq C q \cdot \eta_{\eps}(\calL^{*})$, solves
  $\BDDwDGS_{\calL,d,r}$ using $N=m \cdot \text{poly}(n)$ samples,
  where $d = \sqrt{1-1/C^{2}} \cdot \alpha q/r$.
\end{theorem}

\begin{remark}
  \label{rem:PRS-generalized}
  The above statement generalizes the fixed choice of $C=\sqrt{2}$ in
  the original statement (inherited from~\cite[Section~3.2.1]{Reg09}),
  using~\cite[Corollary~3.10]{Reg09}. In particular, for any constant
  $\delta > 0$ there is a constant $C > 1$ such that
  $d = (1-\delta) \cdot \alpha q / r$.
\end{remark}
% justification: the inner product of the discrete Gaussian with the
% BDD error has param \sqrt{1-1/C^2} alpha q, so we need to add
% (alpha q/C) "smoothing" error. This corresponds to adding a
% continuous Gaussian with param
% alpha q/(C d) = r / (C sqrt(1-1/C^2)) = r / sqrt(C^2-1)
% to the discrete Gaussian of param r \geq C q eta.
% This works out with the harmonic mean requirement on the
% discrete+continuous lemma (Claim 3.9 of Regev).


In particular, by Equation~\eqref{eq:dist-given-samples}, if the
Gaussian parameter $\alpha q$ of the LWE error sufficiently exceeds
$\sqrt{\ln(N)/(2\pi)}$ (e.g., by a constant factor greater than one),
then the $\BDDwDGS_{\calL,d,r}$ problem is plausibly hard (in the
worst case), hence so is the corresponding LWE problem from
\autoref{thm:bddwdgs-to-dlwe} (on the average).  An interesting
direction is to obtain a more precise bound on, and improve, the
``sample overhead'' of the reduction, i.e., the $\text{poly}(n)$
factor connecting the number of LWE samples~$m$ and the number of DGS
samples~$N$.

\paragraph{Concrete parameters.}

Concretely, for the extremely large bound $N = 2^{256}$ on the
number of discrete Gaussian samples, the threshold for Gaussian
parameters~$\alpha q$ that conform to \autoref{thm:bddwdgs-to-dlwe} is
$\sqrt{\ln(N)/(2\pi)} \approx 5.314$, which corresponds to a standard
deviation threshold of $\sqrt{\ln(N)}/(2\pi) \approx 2.120$.  Our
$\FrodoPKE$ parameters for security Levels~1 and 3, which use standard
deviation $\sigma \geq 2.3$ (see \autoref{tab:distribution}), exceed
this threshold by a comfortable margin.  (Indeed, $\sigma = 2.3$
corresponds to $N \approx 2^{300}$.) For efficiency reasons, our
parameters for security Level~5 use a somewhat smaller standard
deviation of $\sigma = 1.4$; this corresponds to the very large bound
$N \approx 2^{111}$. While this~$N$ is smaller than the running time
for the Level 5 brute-force security level, we stress that these two
quantities are not comparable; $N$ is merely a bound on the
\emph{number of samples} provided in a $\BDDwDGS$ input, and it
controls the decoding distance for known efficient algorithms. 

\subsection{Cryptanalytic attacks}\label{sec:attack:cryptanalytic}

\NISTdescription{The submission package shall include a statement that summarizes the known cryptanalytic attacks on the scheme, and provides estimates of the complexity of these attacks.}

\NISTdescription{The submitter shall provide a list of references to any published materials describing or analyzing the security of the submitted algorithm or cryptosystem. When possible, the submission of copies of these materials (accompanied by a waiver of copyright or permission from the copyright holder for public evaluation purposes) is encouraged.}

In this section, we explain our methodology to estimate the security
level of our proposed parameters. The methodology is similar to the
one proposed in~\cite{USENIX:ADPS16}, with slight modifications taking
into account the fact that some quasi-linear
accelerations~\cite{AFRICACRYPT:Schneider13,BNP_IJAC16} over sieving
algorithms~\cite{SODA:BDGL16,LaarhovenThesis} are not available
without the ring structure.

We also remark that this methodology is significantly more
conservative than what is usually used in the
literature~\cite{albrecht15:_concrete_lwe}, at least since
recently. Indeed, we must acknowledge that lattice cryptanalysis is
far less mature than that for factoring and computing discrete
logarithms, for which the best-known attacks can more safely be
considered best-possible attacks.

\subsubsection{Methodology: the core-SVP hardness}
\label{subsec:coreSVPharness}

In this section, let $\numsamp$ denote the number of LWE samples
available to the attacker. Due to the small number of samples (i.e., $\numsamp \approx n$
in our schemes) we are not concerned with either BKW types of
attacks~\cite{C:KirFou15} or linearization attacks~\cite{ICALP:AroGe11}. This essentially leaves us with two BKZ~\cite{AC:CheNgu11} attacks, usually referred to as primal and dual attacks that we will briefly recall below.

Formally, BKZ with block-size~$b$ requires up to polynomially many
calls to an SVP oracle in dimension~$b$, but some heuristics allow to
decrease the number of calls to be essentially
linear~\cite{ChenThesis}. To account for further improvement, we shall
count only the cost of one such call to the SVP oracle: the core-SVP
hardness. Such precaution is motivated by the fact that there are ways
to amortize the cost of SVP calls inside BKZ, especially when sieving
is to be used as the SVP oracle. Such a strategy was suggested in a
talk, but has so far not been experimentally tested, as more
implementation effort is required to integrate sieving within BKZ.

Even evaluating the concrete cost of one SVP oracle call in
dimension~$b$ is difficult, because the numerically optimized pruned
enumeration strategy does not yield a closed
formula~\cite{EC:GamNguReg10,AC:CheNgu11}. Yet, asymptotically,
enumeration is super-exponential (even with pruning), while sieving
algorithms are exponential $2^{cb + o(b)}$ with a well understood
constant $c$ in the exponent. A sound and simple strategy is therefore
to give a lower bound for the cost of an attack by $2^{cb}$ vector
operations (i.e., about $b 2^{cb}$ CPU cycles\footnote{Because of the
  additional ring-structure,~\cite{USENIX:ADPS16} chooses to ignore
  this factor $b$ to the advantage of the adversary, assuming the
  techniques of~\cite{AFRICACRYPT:Schneider13,BNP_IJAC16} can be
  adapted to more advanced sieve algorithms \cite{USENIX:ADPS16}. But
  for plain LWE, we can safely include this factor.}), and to make
sure that the block-size~$b$ is in a range where enumeration costs
more than~$2^{cb}$. From the estimates of~\cite{AC:CheNgu11}, it is
argued in~\cite{USENIX:ADPS16} that this is the case both classically
and quantumly whenever $b \geq 200$.

The best known constant in the exponent for classical algorithms is
$c_{\text{C}} = \log_2 \sqrt{3/2} \approx 0.292$, as provided by the
sieve algorithm of~\cite{SODA:BDGL16}.  For quantum algorithms it is
$c_{\text{Q}} = \log_2 \sqrt{13/9} \approx
0.265$~\cite[Sec. 14.2.10]{LaarhovenThesis}. Because all variants of
the sieve algorithm require building a list of $\sqrt{4/3}^b$ many
vectors, the constant
$c_{\text{P}} = \log_2 \sqrt{4/3} \approx {.2075}$ can plausibly serve
as a ``worst-possible'' lower bound for sieving algorithms.

\paragraph{Conservatism: lower bounds vs. experiments.}

These estimates are very conservative compared to the state of the art
implementation of~\cite{mariano2017parallel}, which has practical
complexity of about $2^{0.405 b + 11}$ cycles in the range
$b=60 \dots 80$. The classical lower bound of $2^{0.292b}$ corresponds
to a margin factor of $2^{20}$ at blocksize $b=80$, and this margin
should continue increasing with the blocksize (abusing the linear fit
suggests a margin of $2^{45}$ at blocksize $b=300$).

\paragraph{Conservatism: future improvements.}

Of course, one could assume further improvements on known techniques.
At least asymptotically, it may be reasonable to assume that
$2^{0.292 b + o(b)}$ is optimal for SVP considering that the
underlying technique of~\cite{SODA:BDGL16} has been shown to reach
lower bounds for the generic nearest-neighbor search
problem~\cite{SODA:ALRW17}.  As for concrete improvements, we note
that this algorithm has already been subject to some fine-tuning
in~\cite{mariano2017parallel}, so we may conclude that there is not
much more to be gained without introducing new ideas. We therefore
consider our margin sufficient to absorb such future improvements.

\paragraph{Conservatism: cost models.}

The NIST call for proposals suggested a particular cost model,
inspired by the estimates of a Grover search attack on AES,
essentially accounting for the quantum gate count. In comparison, the
literature on sieving algorithms mostly focuses on analysis in the RAM
model and quantumly accessible RAM models, and considers the amount of
memory they use. Their cost in the area-time model should be higher by
polynomial, if not exponential, factors.

Firstly, our model accounts for arithmetic operations rather than
gates (used to compute inner products and evaluate norms of
vectors). The conversion to gate count may not be trivial as it is
unclear how many bits of precision are required.

Secondly, even in the classical setting, the cost of sieving in large
dimensions may not be accurately captured by the count of elementary
operations in the RAM model, as those algorithms use an exponential
amount of memory. Admittedly, the most basic sieve algorithm (with
theoretical complexity $2^{0.415b + o(b)}$) has sequential memory
access, and can therefore be efficiently implemented by a large
circuit without memory access delays. But more advanced
ones~\cite{SODA:BDGL16} have much less predictable memory access
patterns, and memory complexities as large as time complexities
($2^{0.292 b + o(b)}$). It is unclear if they can be adapted to reach
a complexity $2^{0.292 b + o(b)}$ in the area-time model; one might
expect extra polynomial factors to appear. (Following an idea
of~\cite{EPRINT:BecGamJou15}, Becker et al.~\cite{SODA:BDGL16} also
claim a version that only requires $2^{0.2015b + o(b)}$ memory, but
we suspect this would come at some hidden cost on the running time.)

Moreover, the quantum versions of all sieving algorithms work in the
quantumly accessible RAM model~\cite{LMP15}. Again, the conversion to
an efficient quantum circuit will induce extra costs---at least
polynomial ones.

\subsubsection{Primal attack}

The primal attack consists of constructing a unique-SVP instance from
the LWE problem and solving it using BKZ. We examine how large the
block dimension $b$ is required to be for BKZ to find the unique
solution. Given the matrix LWE instance
$( \bfA,\bfb = \bfA \bfs + \bfe)$ one builds the lattice
$\Lambda = \{ \bfx \in \mathbb Z^{m+n+1} : ( \bfA | \bfI_m | - \bfb)
\bfx = 0 \bmod q \}$ of dimension $d = m + n + 1$, volume $q^m$, and
with a unique-SVP solution $\bfv = (\bfs, \bfe, 1 )$ of norm
$\lambda \approx \sigma \sqrt{n+m}$. The number of used samples $m$
may be chosen between $0$ and $\numsamp$, and we numerically optimize
this choice.

Using the typical models of BKZ (geometric series assumption, Gaussian
heuristic~\cite{ChenThesis,albrecht15:_concrete_lwe}) one concludes
that the primal attack is successful if and only if
\begin{equation}
  \label{eqn:primal_attack_cond}
  \sigma \sqrt b \leq \delta^{2b-d -1} \cdot q^{m/d} \quad \text{ where } \delta = ((\pi b)^{1/b} \cdot b/(2\pi e))^{1/(2b-2)} \enspace .
\end{equation}

We note that this condition, introduced in~\cite{USENIX:ADPS16}, is
substantially different from the one suggested in~\cite{EC:GamNgu08}
and used in many previous security analyses, such
as~\cite{albrecht15:_concrete_lwe}. The recent study~\cite{AC:AGVW17}
showed that this new condition predicts significantly smaller security
levels than the older, and is corroborated by extensive experiments.

\subsubsection{Dual attack}
\label{sec:dual-attack}

The dual attack searches for a short nonzero vector in the lattice
$\hat \Lambda = \{ (\bfv, \bfw) \in \mathbb{Z}^{n + m} : \bfv^{t} =
\bfw^{t} \bfA \pmod q\}$ of dimension $d=n+m$ and volume~$q^{n}$,
which is generated by the rows of the basis matrix
\[ \bfB =
  \begin{pmatrix}
    q \bfI_{n} & \\ \bar \bfA & \bfI_{m}
  \end{pmatrix}  \in \mathbb{Z}^{(n+m) \times (n+m)} ,
\]
where each entry of~$\bar \bfA$ is an arbitrary mod-$q$ integer
representative of the corresponding entry of~$\bfA$.  As above, the
BKZ algorithm with block size~$b$ will output such a vector of length
$\ell \approx \delta^{d-1} q^{n/d}$. The dual attack then uses this
vector as a distinguisher for LWE, as described next.

For convenience we actually analyze the attack against a
\emph{continuous} form of LWE, with Gaussian~$\bfs, \bfe$ over the
reals~$\mathbb{R}$. An instance of this problem has the form
$(\bfA, \bfb)$, where $\bfb \in (\mathbb{R}/q\mathbb{Z})^{n + m}$
either is uniformly random and independent of~$\bfA$, or has the form
\[
  \bfb =
  \begin{pmatrix}
    \bfb_{1} \\ \bfb_{2}
  \end{pmatrix}
  = \bfB \cdot
  \begin{pmatrix}
    \bfs \\ \bfe
  \end{pmatrix} =
  \begin{pmatrix}
    q \cdot \bfs \\ \bar \bfA \bfs + \bfe
  \end{pmatrix}
  \bmod q \mathbb{Z}^{n + m} , \] where the entries of
$(\bfs, \bfe) \in \mathbb{R}^{n + m}$ are independent continuous
Gaussians of standard deviation~$\sigma$. Because there is a trivial
reduction from this LWE decision problem to the discrete one of
interest that has \emph{rounded Gaussian}~$\bfs, \bfe$
(over~$\mathbb{Z}$), the latter problem is no easier than the
former.\footnote{The reduction just replaces $\bfb$ with
  $\round{\bfb_{2} - \bar \bfA (\bfb_{1}/q \bmod \mathbb{Z}^{n})} \in
  \mathbb{Z}_{q}^{m}$, where the $\bmod$ operation returns the unique
  representative (i.e., fractional part) in $[-1/2, 1/2)^{n}$, and
  $\round{\cdot}$ rounds to the nearest integer by subtracting the
  fractional part. This reduction maps the (continuous) uniform
  distribution to the (discrete) uniform distribution, and in the LWE
  case, subtracts $\bar \bfA$ times the fractional part of~$\bfs$ and
  rounds away the fractional part of~$\bfe$, yielding
  $\bar \bfA \round{\bfs} + \round{\bfe} \bmod q\bbZ^{m}$.}

Having found some $(\bfv,\bfw) \in \hat\Lambda$ of length $\ell$, the
attacker computes
\[ z = (\bfv^{t}, \bfw^{t}) \cdot \bfB^{-1} \cdot \bfb = q^{-1}
  (\bfv^{t} - \bfw^{t} \bar \bfA) \cdot \bfb_{1} + \bfw^{t} \cdot
  \bfb_{2} \bmod q , \] and attempts to distinguish it from uniformly
random over $\mathbb{R}/q\mathbb{Z}$. Its advantage in doing so can be
bounded as follows. First, suppose that $\bfb = \bfB \cdot \left(
  \begin{smallmatrix}
    \bfs \\ \bfe
  \end{smallmatrix}
\right)$ is from a continuous LWE instance as defined above. Then
\[ z = (\bfv^{t}, \bfw^{t}) \cdot
  \begin{pmatrix}
    \bfs \\ \bfe
  \end{pmatrix} \bmod q \] is distributed as a Gaussian of standard
deviation $\ell \sigma$, modulo~$q$. On the other hand, if~$\bfb$ is
uniformly random, then~$z$ is uniformly random
in~$\mathbb{R}/q\mathbb{Z}$. By the results
of~\cite{DBLP:journals/siamcomp/MicciancioR07}, these two
distributions have statistical distance at most $\eps = 2\delta$ for
$\delta = \exp(-2\pi^2 \tau^2) < 1/8$ where $\tau = \ell \sigma / q$,
so this~$\eps$ bounds the distinguishing advantage.

Because the value~$\mu$ encrypted by the underlying $\FrodoPKE$ (using
LWE) actually serves as a seed to pseudorandomly generate the
$\FrodoKEM$ KEM key $\ssk$ (see \autoref{alg:KEM:Encaps}), a small
advantage~$\eps$---say, below $1/2$---in distinguishing~$\mu$ from a
uniform random string does not significantly decrease the brute-force
search space.
% Note that small advantages~$\eps$ are not meaningful to attack a KEM:
% \cpnote{I'm not sure this argument holds much water, since with
%   FrodoKEM one would just directly use the KEM key it produces. Maybe
%   we should make the argument that for distinguishing problems, we
%   need a $1/\eps^{2}$ factor to measure bit security?}
% \dsnote{This paragraph is also a bit confusing to me.  The security notion we have to meet for the KEM is IND, and distinguishing the LWE instance with advantage $\epsilon$ basically means distinguishing KEM keys with advantage $\epsilon$.  This paragraph more seems to be arguing IND isn't the right notion, since we're going to compose the KEM key with a symmetric encryption scheme, and so you really need session key recovery (one way ness, OW) in order to break the symmetric encryption scheme.  There is something to that argument, but OW is not what we were asked to provide, IND is.  I don't really understand the last part about the $2^{.2075b}$ vectors and how that fits in, so I don't have a comment on that.}
% because the
% agreed-upon key is to be used as a symmetric cipher key, any advantage
% below $1/2$ does not significantly decrease the brute-force search
% space. (To make this more formal, one may simply hash the agreed-upon
% key with a random oracle before using it for any other purpose.)
%
We therefore require the attacker to amplify its distinguishing
advantage by obtaining about $1/\eps^2$ short lattice vectors, which
we can model (most favorably to the attacker) as being Gaussian
distributed and independent.
%
% \cpnote{This amplification argument is not satisfactory
%   either, because we lack \emph{independence} due to the fixed choice
%   of $\bfe$. If we model the sieve algorithms as producing independent
%   Gaussian-distributed vectors then the inner products are
%   independent. But I don't know if this is a legitimate model, or if
%   we even would want to use it. Just using a $1/\eps^{2}$ factor for
%   bit security in distinguishing problems seems like the better way to
%   go.}
Because the lattice-sieve algorithms provide about $2^{.2075 b}$
vectors, the dual attack must be repeated at least
$R = \max(1, 1/(2^{.2075 b} \eps^2))$ times. (This view is also
favorable to the attacker, as the other vectors output by the sieving
algorithm are a bit larger than the shortest one.)

Primal and dual attacks for our suggested parameters are given in
\autoref{tab:attacks}.  The costs are listed for a single instance of
the LWE problem. (Our ultimate security claims, such as those listed
in \autoref{tab:security}, result from a series of reductions and thus
are weaker.)

\begin{table}
\begin{center}
\caption{\textbf{Primal and dual attacks on a single instance of an LWE problem.} Attack costs are given as the base-$2$ logarithm.}\label{tab:attacks}
\medskip
\centering
\renewcommand{\tabcolsep}{0.3cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c|ccc}
\toprule
Scheme & Attack Mode & Classical & Quantum & Plausible \\
\midrule
\multirow{2}{*}{\FrodoLOne} & Primal & 150.8 & 137.6 & 109.6 \\
& Dual & 149.6 & 136.5 & 108.7 \\
\midrule
\multirow{2}{*}{\FrodoLThree} & Primal & 216.0 & 196.7 & 156.0 \\
& Dual & 214.5 & 195.4 & 154.9 \\
\midrule
\multirow{2}{*}{\FrodoLFive} & Primal & 281.6 & 256.3 & 202.6 \\
& Dual & 279.8 & 254.7 & 201.4 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}


\subsubsection{Beyond Core-SVP Hardness}
\label{sec:beyond-core}

At the time the core-SVP hardness measure was introduced by~\cite{USENIX:ADPS16}, the best implementations of sieving~\cite{SODA:BDGL16,mariano2017parallel} had performance significantly worse than the $2^{.292b}$ CPU cycles proposed as a conservative estimate by this methodology. This was due to substantial polynomial, or even sub-exponential, overheads hidden in the $2^{.292b + o(b)}$ complexity given in the analysis of~\cite{SODA:BDGL16}. Before~\cite{USENIX:ADPS16}, security estimates of lattice schemes were typically based on the cost of solving SVP via enumeration as given in~\cite{AC:CheNgu11,albrecht15:_concrete_lwe}, leading to much more aggressive parameters. Beyond affecting the cost of SVP-calls, this methodology also introduced a different prediction of when BKZ solves LWE which was later confirmed by~\cite{AC:AGVW17} and refined in~\cite{dachman2020lwe}.

While doubts were expressed to whether enumeration~\cite{AC:CheNgu11} with its super-exponential, yet practically smaller, costs would ever be outperformed by sieving for relevant cryptographic dimensions, significant progress on sieving algorithms~\cite{ducas2018shortest,albrecht2019general} has brought the cross-over point down to dimension about $b = 80$. In fact, the current SVP records are now held by algorithms that employ sieving.\footnote{\url{https://www.latticechallenge.org/svp-challenge/}} These developments mandate a revision and refinement of security estimates for the \FrodoKEM parameters, especially regarding classical attacks. In particular, while experiments indicated that, before those improvements were made, the costs hidden in the $o(b)$ were positive both in practice and asymptotically, the dimensions-for-free technique of~\cite{ducas2018shortest} offers a sub-exponential speed-up, making it a priori unclear whether the total $o(b)$ term is positive or negative, both asymptotically and concretely.

We follow the same methodology as the one detailed in the Round-3 specification document of the Kyber key encapsulation mechanism \cite{EuroSP:Kyber} to count the number of gates required to solve the LWE problem. This analysis refines the core-SVP methodology in the following ways:
\begin{itemize}
	\item It uses the probabilistic simulation of~\cite{dachman2020lwe} rather than the GSA-intersect model of~\cite{USENIX:ADPS16,AC:AGVW17} to determine the BKZ blocksize $b$ for a successful attack. The required blocksize is somewhat larger (by an added term between $10$ and $25$ for our parameters), because of a ``tail'' phenomenon~\cite{yu2017second}.
	\item It accounts for the ``few dimensions for free'' introduced in~\cite{ducas2018shortest}, which permits to solve SVP in dimension $b$ while running sieving in a somewhat smaller dimension $b' = b-o(b)$.
	\item It relies on the concrete estimation for the gate cost of sieving from~\cite{albrecht2019estimating}.
	\item It accounts for the number of calls to the SVP oracle.
	\item It dismisses the dual attack as realistically more expensive than the primal one, noting that the analysis of~\cite{USENIX:ADPS16} (also used here) assumes that the sieve provides $2^{.208b}$ many vectors as short as the shortest one. But first, most of those vectors are larger by a factor of $\sqrt{4/3}$, and second, the trick of exploiting all of those vectors is not compatible with the ``dimension-for-free'' trick of~\cite{ducas2018shortest}.
\end{itemize}
The scripts for these refined estimates are provided in a git branch of the leaky-LWE-estimator of~\cite{dachman2020lwe},\footnote{\url{https://github.com/lducas/leaky-LWE-Estimator/tree/NIST-round3}} and lead to the estimates given in Table~\ref{tab:refined_LWE}. We refer to the Kyber Round-3 specification document for the details of this analysis. We point out that it is paired with a detailed discussion of the ``known unknowns'', providing a plausible confidence interval for these estimates. For the classical hardness of the LWE problem at Levels 1 and 2, it is estimated in the Kyber Round-3 document that the true cost is no more than $16$ bits away from this estimate, in either direction. 

We also note that a similarly refined count of quantum gates seems to be essentially irrelevant: the work of \cite{albrecht2019estimating} concluded that obtaining a quantum speed-up for sieving is rather tenuous, while the quantum security target for each level is significantly lower than the classical target. 


\begin{table}[H]
\begin{center}
\caption{Refined estimates for the LWE hardness, where $n$ is the optimal lattice dimension for the attack,  
$b$ the BKZ blocksize and $b'$ the sieving dimension accounting for ``dimensions for free''}\label{tab:refined_LWE}
\medskip
\centering
\renewcommand{\tabcolsep}{0.3cm}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|c|c|c|c|c}
\toprule
             & $n$    &  $b$  & $b'$  & $\log_2(\text{gates})$   & $\log_2(\text{memory in bits})$ \\ 
\midrule
\FrodoLOne 	& 1297	& 496	& 453	& 175.1 	& 110.4 \\
\FrodoLThree 	& 1969	& 724	& 668	& 240.0 	& 155.8 \\
\FrodoLFive 	& 2634	& 957	& 888	& 305.4 	& 202.1 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}

The refined analysis above covers recent improvements for solving the SVP and models the current state of the art. The resulting gate counts show that the \FrodoKEM parameter sets comfortably match their respective target security levels with a large margin. While these numbers might encourage parameter modifications to more closely match security targets and improve performance and bandwidth, we prefer to leave parameter sets unchanged. This aligns with \FrodoKEM's conservative design approach and hedges against improvements for cryptanalytic algorithms solving general lattice problems. 


\subsubsection{Decryption failures}\label{sec:failures}

The concrete $\FrodoPKE$ parameters induce a tiny probability of
incorrect decryption (see \autoref{tab:security}), for honestly
generated keys and ciphertexts. This is because a ciphertext may
decrypt to a different message than the encrypted one, if the
combination of the short error matrices in the key and the ciphertext
is too large (see \autoref{sec:cpa-pke-correctness}).  This
aspect of the scheme carries over to the transformed, CCA-targeting
$\FrodoKEM$, where incorrect decryption in the underlying PKE
typically causes a decryption failure.

It has long been well understood that the ability to induce incorrect
decryption or decryption failure in LWE-based schemes can leak
information about the secret key, up to and including full key
recovery (with sufficiently many failures). In brief, this is because
such failures indicate some correlation between the secret key and the
encryption randomness.

In the context of chosen-ciphertext attacks on $\FrodoKEM$ and
similarly transformed schemes, the attacker can attempt to create
ciphertexts whose underlying error matrices---which are derived
pseudorandomly using an attacker-chosen seed---are atypically
large. Such ``weak'' ciphertexts have an increased probability of
inducing decryption failures when submitted to a decryption
oracle. The process of searching for such ciphertexts, which can be
done offline (without using a decryption oracle), is known as
``failure boosting.''

Recently, D'Anvers et al.~\cite{PKC:DGJNVV19} performed a detailed study of
the complexity of failure-boosting attacks (in both the classical and
quantum setting) against a variety of NIST candidates, including
$\FrodoKEM$. In summary, they found that our original Level 3
parameterization $\FrodoLThree$ suffered \emph{no loss} in our
claimed security (either classical or quantum) under such
attacks. This is essentially because the cost of finding weak
ciphertexts exceeds the benefit obtained from the corresponding
increase in decryption failure probability.

Subsequently, we ran the scripts from~\cite{PKC:DGJNVV19} on the
parameters for $\FrodoLOne$ (updated), $\FrodoLThree$, and $\FrodoLFive$, and
confirmed that applying the failure-boosting attack does not violate security
Levels 1, 3, and 5, respectively. (Note that for $\FrodoLFive$,
failure boosting did not provide any improvement over the intrinsic
failure probability of $2^{-252.5}$. We consider this to be consistent
with the Level 5 requirement of 256 bits of brute-force security, because the overhead in using
decryption failures to win the CCA security game exceeds 3.5 bits.)


\color{red}
\subsubsection{Multi-target and multi-ciphertext security}\label{sec:multi-attacks}

\paragraph{Multi-target security.}

Multi-target attacks aim to break security against one of~$N$ public keys.
$\FrodoKEM$'s primary security target of $\INDCCA$ security considers only a single public key, hence multi-target attacks fall outside of its scope (though multi-target security provably follows by a routine hybrid argument, with looseness linear in the number of keys).
However, multi-target security can be a desirable feature in some settings.
The security analysis in \autoref{sec:strength:reductions} does not formally cover security in the multi-target setting.
However, in order to reduce the risk of batch attacks targeting multiple keys, $\FrodoKEM$ includes the hashed value of the public key $\pkh$ in the computation of the random bit strings $\bfr$ (\autoref{alg:KEM:Encaps}, line 3).

\paragraph{Multi-ciphertext security.}

Multi-ciphertext attacks target a single public key, but aim to break one of~$N$ ciphertexts produced under that key.
$\FrodoKEM$'s primary security target of $\INDCCA$ security considers only a single challenge ciphertext, hence multi-ciphertext attacks fall outside of its scope (though multi-ciphertext security provably follows by a routine hybrid argument, with looseness linear in the number of ciphertexts).
However, multi-ciphertext security can be a desirable feature in some settings.

A multi-ciphertext attack was identified against earlier versions of $\FrodoKEM$, which we summarize here.%
\footnote{Thanks to Ray Perlner of NIST for pointing out this attack and suggesting the salt-based countermeasure (personal communication, August 2021).}
The pseudorandom values $\seedSE$ and $\bfk$ computed on line 3 of $\FrodoKEM.\Encaps$ (\autoref{alg:KEM:Encaps}) were determined entirely by the public key hash $\pkh$ and seed value (message)~$\mu$.
Consequently, the encapsulation secret key $\bfS'$ and $\bfE'$ were also determined entirely by $\pkh$ and~$\mu$ (lines 4--6 of \autoref{alg:KEM:Encaps}).
Since~$\mu$ is from a space having bit length $\lengthm$, an adversary could run a multi-ciphertext attack for a specific public key via a brute-force search on this space.

More specifically, an attacker could collect~$N$ challenge ciphertexts encrypted under a given public key, and do a brute-force search through~$M$ different values of~$\mu$, seeking a match with one of the ciphertexts.
This would reveal the corresponding shared secret of the ciphertext.
For each of the~$N$ challenge ciphertexts, there is approximately an $M/2^{\lengthm}$ probability that this ciphertext used the same seed~$\mu$ as one of the~$M$ the attacker generated.
Therefore, with work proportional to roughly $M+N$, the attacker succeeds in breaking at least one of the challenge ciphertexts with probability roughly $M N /2^{\lengthm}$ (when $M N \leq 2^{\lengthm}$, as is typical).
For, e.g., the Level-1 value $\lengthm = 128$ and large but technologically feasible values of~$N$ and~$M$, this probability may be considered unacceptably large.

% The bit security of FrodoKEM is thus limited to $\lengthm+\delta$, where $\delta$ represents the cost of the computations that are required to run the attack, including multiple hashing and vector/matrix operations.
% The NIST security levels are phrased in terms of the cost of breaking AES via a brute-force search, and thus are also of the form $\lengthm+\delta_\mathsf{AES}$, where $\lengthm$ is set as the key length of the corresponding AES parameterization, and $\delta_{\mathsf{AES}}$ represents the (amortized) cost of an iteration of the brute-force AES key-search attack.
% An iteration of the above multi-ciphertext attack includes multiple hashing and vector/matrix operations, so~$\delta$ should be close to $\delta_{\mathsf{AES}}$ (and likely slightly larger).

While none of the above breaks $\FrodoKEM$ at any of the targeted NIST security levels, it comes closer to those levels than the LWE security estimates given in \autoref{sec:beyond-core} (\autoref{tab:refined_LWE}).

To mitigate the risk of multi-ciphertext attacks, we revised $\FrodoKEM$ to concatenate a fresh, uniformly random, public value $\salt$ of bit length $\ell=\lengthsalt$ to the message $\mu$ (\autoref{alg:KEM:Encaps}, line 3).
The $\salt$ value is made public as part of the ciphertext output by encapsulation.
This change has negligible effect on performance (about 1\% or less overhead in runtime and ciphertext size).
\color{black}

\section{Security analysis}\label{sec:security}

Since $\eFrodoKEM$ is identical to the NIST Round 3 version of $\FrodoKEM$, the analysis given in the $\FrodoKEM$ NIST Round 3 specification document continues to apply for $\eFrodoKEM$.

The new version $\FrodoKEM$ requires additional analysis.
$\FrodoKEM$ is constructed from the $\INDCPA$-secure $\FrodoPKE$ public key encryption scheme by applying a variant of the Fujisaji--Okamoto transform.
The NIST Round 3 version of $\FrodoKEM$ used a variant of the $\FOnotperp$ transform by Hofheinz, H{\" o}velmanns, and Kiltz (HHK)~\cite{TCC:HofHovKil17}.
The new version of $\FrodoKEM$ can be viewed as being constructed from a ``salted'' version of the previously used transform.
\autoref{sec:security:FO} presents this modification to the FO transform, and \autoref{sec:security:ROM} and \autoref{sec:security:QROM} describe how the relevant security theorems from~\cite{TCC:HofHovKil17,C:JZCWM18} adapt to the salted version.
$\FrodoKEM$ continues to use the same LWE parameters as before, so the analysis of the lattice attacks given in the $\FrodoKEM$ NIST Round 3 specification document continues to apply.

Our analysis shows that the salted version of the FO transform yields $\INDCCA$ security, just as in the previous version of $\FrodoKEM$, and with the same concrete security bounds.
We caution, however, that we have not \emph{proved} that the salted version achieves \emph{stronger} security against multi-ciphertext attacks than the unsalted version, even though the salted version appears to thwart the specific multi-ciphertext attack described in \autoref{sec:multi-attacks}.
Obtaining a (tighter) proof of multi-ciphertext security seems to require adapting the results of~\cite{TCC:HofHovKil17} to the multi-ciphertext setting, which looks non-trivial.
In summary, while the results in \autoref{sec:security:ROM} do not prove any stronger $\INDCCA$ security against multi-ciphertext attacks, they at least show that the salted version maintains the prior level of $\INDCCA$ security in the single-ciphertext setting.

\subsection{Salted FO transform}\label{sec:security:FO}

\autoref{fig:kem-qfo} shows the ``salted'' version of the FO transform, which we denote $\FOnotperpprime$, {\color{red}highlighting in red} the changes compared to the version of the transform used in the $\FrodoKEM$ NIST Round 3 specification.

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.35\textwidth}
\underline{$\KEMnotperpprime.\KeyGen()$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $(\pk, \sk) \getsr \PKE.\KeyGen()$
\STATE $\bfs \getsr \{0,1\}^\lengths$
\STATE $\pkh \gets G_1(\pk)$
\STATE $\sk' \gets (\sk, \bfs, \pk, \pkh)$
\RETURN $(\pk, \sk')$
\end{algorithmic}

\medskip

\underline{$\KEMnotperpprime.\Encaps(\pk)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu \getsr \MsgSp$, {\color{red} $\salt \getsr \{0,1\}^{\lengthsalt}$}
\STATE $(\bfr, \bfk) \gets G_2(G_1(\pk) \| \mu {\color{red} \| \salt})$
\STATE $c \gets \PKE.\Enc(\mu, \pk; \bfr)$
\STATE $\ssk \gets F(c {\color{red} \| \salt} \| \bfk)$
\RETURN $(c {\color{red} \| \salt}, \ssk)$
\end{algorithmic}
\end{minipage}
~
\begin{minipage}[t]{0.55\textwidth}
\underline{$\KEMnotperpprime.\Decaps(c {\color{red} \| \salt}, (\sk, \bfs, \pk, \pkh))$:}
%\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu' \gets \PKE.\Dec(c, \sk)$
\STATE $(\bfr', \bfk') \gets G_2(\pkh \| \mu' {\color{red} \| \salt})$
\STATE $\ssk_0' \gets F(c {\color{red} \| \salt} \| \bfk')$
\STATE $\ssk_1' \gets F(c {\color{red} \| \salt} \| \bfs)$
\STATE (in constant time) $\ssk' \gets \ssk_0'$ if $c = \PKE.\Enc(\mu', \pk; \bfr')$ else $\ssk' \gets \ssk_1'$
\RETURN $\ssk'$
\end{algorithmic}
\end{minipage}
}
\caption{Salted version $\FOnotperpprime$ of the FO transform.}
\label{fig:kem-qfo}
\end{figure}

Hofheinz, H{\" o}velmanns, and Kiltz \cite{TCC:HofHovKil17} show how to obtain the $\FOnotperp$ transform in a modular way as the composition of two transforms, $\FOnotperp = \Unotperp \circ \T$.
The $\T$ transform converts an $\INDCPA$-secure public-key encryption scheme into an $\OWPCA$-secure PKE, and the $\Unotperp$ transform converts an $\OWPCA$-secure PKE into an $\INDCCA$-secure KEM.\@
We define the analogous ``salted'' transform $\FOnotperpprime$ from \autoref{fig:kem-qfo} as $\FOnotperpprime = \Unotperp \circ \T'$, where~$\T'$ is a salted version of the~$\T$ transform as defined in \autoref{fig:T'}.
We show in the subsequent section that $\T'$ similarly converts an $\INDCPA$-secure public key encryption scheme into an $\OWPCA$-secure PKE (with the same tight security bounds as for the~$\T$ transform), allowing us to rely on existing results from HHK to complete the $\INDCCA$ security analysis.

\begin{figure}[h]
\centering
\fbox{
\begin{minipage}[t]{0.32\textwidth}
\underline{$\PKEOne.\KeyGen()$:}
\vspace{-1em}
\begin{algorithmic}[1]
\RETURN $\PKE.\KeyGen()$
\end{algorithmic}

\medskip

\underline{$\PKEOne.\Enc(\mu, \pk)$:}
\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\salt \getsr U(\{0,1\}^\lengthsalt)$
\STATE $r \gets G_2(\mu \| \salt)$
\STATE $c \gets \PKE.\Enc(\mu, \pk; r)$
\RETURN $c \| \salt$
\end{algorithmic}
\end{minipage}
~
\begin{minipage}[t]{0.62\textwidth}
\underline{$\PKEOne.\Dec(c \| \salt, \sk)$:}
%\vspace{-1em}
\begin{algorithmic}[1]
\STATE $\mu' \gets \PKE.\Dec(c, \sk)$
\IF {$\mu' = \bot$ or $c \ne \PKE.\Enc(\mu', \pk; G_2(\mu' \| \salt))$}
  \RETURN $\bot$
\ELSE
  \RETURN $\mu'$
\ENDIF
\end{algorithmic}
\end{minipage}
}
\caption{Salted $\T'$ construction of a public-key encryption scheme $\PKEOne=\T'[\PKE, G_2]$ from a public-key encryption scheme $\PKE$ and hash function~$G_2$.}
\label{fig:T'}
\end{figure}

\subsection{$\INDCCA$ security of $\FOnotperpprime$ in the classical random-oracle model}\label{sec:security:ROM}

Our main goal here is to give a slight extension of HHK's Theorem 3.2, showing that the ``salted'' version of their~$\T$ transform, which we call~$\T'$, converts the \INDCPA-secure public-key encryption scheme $\PKE_{Q}$ into an \OWPCA-secure public-key encryption scheme (in the random-oracle model).

To complete the $\INDCCA$ analysis, we then apply the remaining steps exactly as in Section 5.1.1 of the $\FrodoKEM$ NIST Round 3 specification:
\begin{enumerate}
\setcounter{enumi}{1}
\item We apply distribution substitution for the \OWPCA security experiment (which represents a search problem), to switch from distribution~$Q$ to~$P$.
\item Finally, we apply HHK's Theorem 3.4, which shows that their $\Unotperp$ transform converts the \OWPCA-secure public-key encryption scheme from the previous step into an \INDCCA-secure KEM (in the random-oracle model).
\end{enumerate}

\paragraph{Step 1: \INDCPA $\PKE$ to \OWPCA $\PKEOne$.}

For self-containment, we recall the definition of \OWPCA, following the
presentation of Hofheinz et al.~\cite{TCC:HofHovKil17}.

\begin{definition}[\OWPCA for PKE~\cite{RSA:OkaPoi01}]
  \label{def:OW-CPA}
  Let \PKE be a public-key encryption scheme with message space
  $\MsgSp$ and let~$\Adversary$ be an algorithm.  The \OWPCA security
  experiment for $\Adversary$ attacking \PKE is
  $\Exp{\owpca}{\PKE}(\Adversary)$ from \autoref{fig:owpca}.  The
  advantage of~$\Adversary$ in the experiment is
  \[
    \Adv{\owpca}{\PKE}(\Adversary) := \Pr\left[
      \Exp{\owpca}{\PKE}(\Adversary) \Rightarrow 1 \right].
  \]
\end{definition}

\begin{figure}[h]
	\centering
	\fbox{
		\begin{minipage}[t]{0.4\textwidth}
			\underline{Experiment $\Exp{\owpca}{\PKE}(\Adversary)$:}
			\vspace{-1em}
			\begin{algorithmic}[1]
				\STATE $(\pk, \sk) \gets \PKE.\KeyGen()$
				\STATE $m\getsr \MsgSp$
				\STATE $c^* \gets \PKE.\Enc(m, \pk)$
				\STATE $m' \gets
                                \Adversary^{\OPco(\cdot, \cdot)}(\pk, c^*)$
				\RETURN $\OPco(m', c^*)$
			\end{algorithmic}
		\end{minipage}
		~
		\begin{minipage}[t]{0.4\textwidth}
			\underline{Oracle $\OPco(m, c)$:}
			\vspace{-1em}
			\begin{algorithmic}[1]
				\IF {$\PKE.\Dec(c, \sk)=m$}
				\RETURN 1
				\ELSE
				\RETURN 0
				\ENDIF
			\end{algorithmic}
		\end{minipage}
%		~
%\begin{minipage}[t]{0.31\textwidth}
%	\underline{Oracle $\OCvo(c)$:}
%	\vspace{-1em}
%	\begin{algorithmic}[1]
%		\IF {$c=c^*$}
%		\RETURN $\bot$
%		\ENDIF
%		\IF {$\PKE.\Dec(\sk, c)\in \MsgSp$}
%		\RETURN 1
%		\ELSE
%		\RETURN 0
%		\ENDIF
%	\end{algorithmic}
%\end{minipage}
	}
	\caption{Security experiment for \OWPCA.}
	\label{fig:owpca}
\end{figure}



The $\T$ transform of HHK converts a public-key encryption scheme $\PKE$ to a (deterministic) public-key encryption scheme. \autoref{fig:T'} defines a slight extension of this transform, called~$\T'$, which includes a random public ``salt'' in the ciphertext and hash input.%
\footnote{The~$\T'$ transform specializes to the~$\T$ transform simply by taking $\lengthsalt = 0$.
  Unlike the~$\T$ transform, the~$\T'$ transform does not yield a \emph{deterministic} encryption algorithm.
  However, this has no effect on the cited security theorems.}
HHK's Theorem~3.2 tightly establishes the $\OWPCVA$-security of $\T[\PKE, G_{2}]$ under, among others, the assumption that $\PKE$ is \INDCPA secure and $\gamma$-spread.
(In the \OWPCVA security game, the attacker additionally has a ciphertext-validity oracle, which checks whether a queried ciphertext has a valid decryption.)
However, they note that $\OWPCA$ security follows (tightly) \emph{without} the $\gamma$-spread assumption, because in the security bounds $\gamma$-spreadness is relevant only to ciphertext-validity queries.
We observe that these claims also hold (with the same security bounds) for the ``salted'' version $\PKEOne = \T'[\PKE, G_{2}]$, by straightforward adaptation of the proof; see \autoref{sec:proofs-salted-fo} for details.
The formal statement is as follows.

\begin{lemma}[\cite{TCC:HofHovKil17}, Theorem~3.2; salted, $\OWPCA$ version]
  \label{lem:T'}
  Let $\PKE$ be a $\delta$-correct public-key encryption scheme with
  message space $\MsgSp$. For any $\OWPCA$ adversary $\Adversary$ that
  issues at most~$q_G$ queries to the random oracle~$G_2$ and~$q_P$
  queries to the plaintext-checking oracle, there exists an $\INDCPA$
  adversary $\Bdversary$ such that
  \[
  \Adv{\owpca}{\PKEOne}(\Adversary) \leq q_G \cdot \delta + \frac{2 q_G
    + 1}{|\MsgSp|} + 3 \cdot \Adv{\indcpa}{\PKE}(\Bdversary) \enspace
  ,
  \]
  and the running time of $\Bdversary$ is about that of $\Adversary$
  plus the time needed to simulate the random oracle.
\end{lemma}

\subsection{$\INDCCA$ security of $\FOnotperpprime$ in the quantum random-oracle model}\label{sec:security:QROM}

Jiang et al.~\cite{C:JZCWM18} show that the $\FOnotperp$ transform yields an \INDCCA-secure KEM from an \OWCPA-secure public-key encryption scheme, in the \emph{quantum} random oracle model.
As noted above, we apply a slight (``salted'') variant~$\FOnotperpprime$ of the~$\FOnotperp$ transform.
The relevant security theorem and proof from~\cite{C:JZCWM18} adapts straightforwardly to this variant (with the same, but loose, security bounds); see \autoref{sec:proofs-salted-fo} for details.

\begin{theorem}[{\cite[Theorem 1]{C:JZCWM18}}, salted version]
  \label{thm:cca-kem-to-cpa-pke-qrom}
  Let $\PKE = (\KeyGen,\Enc,\Dec)$ be a $\delta$-correct public-key
  encryption scheme with message space $\MsgSp$.  Let~$G_2$ and~$F$ be
  independent random oracles.  Let
  $\KEMnotperpprime=\FOnotperpprime[\PKE,G_2,F]$ be the KEM obtained by applying
  the $\FOnotperpprime = \Unotperp \circ \T'$ transform to~$\PKE$.  For any
  quantum algorithm $\Adversary$ against the \INDCCA security of
  $\KEMnotperpprime$ that makes~$q_F$ quantum oracle queries to~$F$
  and~$q_G$ quantum oracle queries to~$G_2$, there exists a quantum
  algorithm $\Bdversary$ against the \OWCPA security of $\PKE$ such
  that
  \[ \Adv{\indcca}{\KEMnotperpprime}(\Adversary) \leq
    \frac{2 q_F}{\sqrt{|\MsgSp|}} + 4 q_G \sqrt{\delta} + 2(q_G + q_F)
    \sqrt{\Adv{\owcpa}{\PKE}(\Bdversary)}.\] Moreover, the running
  time of~$\Bdversary$ is about that of~$\Adversary$.
\end{theorem}


\section{Proofs for salted FO transform}\label{sec:proofs-salted-fo}

As noted in \autoref{sec:security}, \autoref{lem:T'} and \autoref{thm:cca-kem-to-cpa-pke-qrom} were respectively proved in~\cite{TCC:HofHovKil17} and~\cite{C:JZCWM18} for the ``unsalted''~$\T$ and $\FOnotperp$ transforms, in the classical and quantum random-oracle models.
Here we show that these results extend to the ``salted'' versions of the transforms (with no changes to the security bounds), via straightforward adaptations of the original proofs.
We describe these changes in a way that is meant to be read alongside the proofs from~\cite{TCC:HofHovKil17,C:JZCWM18}.%
% \footnote{The thesis~\cite{H} also provides more proof details and fixes some small errors in the relevant proofs from~\cite{TCC:HofHovKil17}.}

\subsection{Salted $\T'$ transform in the ROM}\label{sec:salted-T'}

\newcommand{\G}{\styleAlgorithm{G}}

The proof of \autoref{lem:T'} for the (salted)~$\T'$ transform (in the random-oracle model) closely follows that of~\cite[Theorems~3.1 and~3.2]{TCC:HofHovKil17} for the (unsalted)~$\T$ transform, with the following mechanical, purely syntactic changes.

First, the attack games $G_{0}$ through $G_{3}$ are modified in the following way.
In summary, every input to the random oracle~$\G$ is of the form $m \| \salt$ (instead of just~$m$), and every ciphertext of the transformed scheme (i.e., challenge ciphertext or adversarially generated oracle query) is of the form $c \| \salt$ (instead of just~$c$), where~$c$ is a ciphertext of the underlying encryption scheme.
In detail:
\begin{itemize}
\item Following the definition of the~$\T'$ transform (\autoref{fig:T'}), along with~$m^{*}$, a $\salt^{*} \in \mathcal{S}$ (the salt domain) is chosen independently and uniformly at random, and $r^{*} = \G(m^{*} \| \salt^{*})$ is used as the random coins for $c^{*} = \styleAlgorithm{Enc}(pk, m^{*}; r^{*})$.
  The adversary is given the challenge ciphertext $c^{*} \| \salt^{*}$ (instead of just~$c^{*}$).

\item Every input to~$\G$ is of the form $m \| \salt$ (instead of just~$m$), where the two components are unambiguously parseable and $\salt \in \mathcal{S}$; similarly, $\mathcal{L}_{\G}$ is a growing set of input-output pairs $(m \| \salt, r)$ for~$\G$.

\item In game $G_{3}$, on query $\G(m \| \salt)$, the test ``if $m=m^{*}$'' on line 08 (that conditionally triggers the QUERY event, and termination of the game) is replaced with the test ``if $m \| \salt = m^{*} \| \salt^{*}$''.

\item PCO inputs (i.e., plaintext-checking queries) are of the form $(m, c \| \salt)$, and the inputs for the induced calls to~$\G$ are augmented with $\salt$.

\item CVO inputs (i.e., ciphertext-validity queries) are of the form $c \| \salt \neq c^{*} \| \salt^{*}$, and the inputs for the induced calls to~$G$ and the inspected pairs in~$\mathcal{L}_{\G}$ are augmented with $\salt$.
\end{itemize}

The analysis of the games proceeds essentially identically, with only mechanical syntactic changes.
Each occurrence of a message~$m$ (respectively,~$c$) associated with a query to any of the oracles is replaced by $m \| \salt$ (resp., $c \| \salt$) for the value of $\salt$ from the query.
Similarly, each occurrence of~$m^{*}$ is replaced by $m^{*} \| \salt^{*}$ (where recall that $\salt^{*}$ is chosen at random alongside~$m^{*}$), and likewise for $m^{*}_{0}, m^{*}_{1}$ in the tight $\INDCPA$ analysis.
Finally, in place of $\mathcal{L}_{\G}(m)$, the set $\mathcal{L}_{\G}(m \| \salt)$ is defined and used in the natural way.

With these changes, all the same probabilistic analyses and bounds apply to the modified games, mutatis mutandis.
In particular, the games $G_{2}$ and $G_{3}$ are identical until and unless the event QUERY occurs, i.e., the query $\G(m^{*} \| \salt^{*})$ is made.
This enables reductions based on the $\OWCPA$ or $\INDCPA$ security of the underlying encryption scheme.
\autoref{lem:T'} therefore follows.

\subsection{Salted $\FOnotperpprime$ transform in the QROM}\label{sec:salted-FO}

The proof of \autoref{thm:cca-kem-to-cpa-pke-qrom} for the (salted) $\FOnotperpprime$ transform (in the quantum random-oracle model) closely follows that of~\cite[Theorem~1]{C:JZCWM18} for the (unsalted) $\FOnotperp$ transform, with the following mechanical, purely syntactic changes.
The attack games all are modified in essentially the same way as above.
In particular, a $\salt^{*} \in \mathcal{S}$ is chosen independently and uniformly at random, and used in the challenge ciphertext; every input to the random oracle~$\G$ is of the form $m \| \salt$ (instead of just~$m$), and in particular $m^{*} \| \salt^{*}$ takes the place of the challenge message~$m^{*}$ throughout; every ciphertext of the transformed scheme is of the form $c \| \salt$ (instead of just~$c$); and the entire $c \| \salt$ is hashed when deriving the shared secret.

With these changes, all the same probabilistic and quantum analyses apply to the modified games, mutatis mutandis.
\autoref{thm:cca-kem-to-cpa-pke-qrom} therefore follows.

\end{document}
